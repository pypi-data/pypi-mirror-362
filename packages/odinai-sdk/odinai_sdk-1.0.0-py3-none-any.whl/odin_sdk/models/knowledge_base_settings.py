# coding: utf-8

"""
    API Docs

    API Documentation to interact with

    The version of the OpenAPI document: 0.1.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from typing import Optional, Set
from typing_extensions import Self

class KnowledgeBaseSettings(BaseModel):
    """
    KnowledgeBaseSettings
    """ # noqa: E501
    project_id: StrictStr
    chunking_strategy: StrictStr = Field(description="Chunking strategy to use. Options: sentence (spaCy sentence tokenizer), token (tiktoken), markdown (preserves markdown), json (for JSON data), character (character count based)")
    embedding_model: Optional[StrictStr] = Field(default='BAAI/bge-small-en-v1.5', description="Embedding model to use. Options: BAAI/bge-small-en-v1.5 (384d), neuralmind/bert-base-portuguese-cased (768d), BAAI/bge-multilingual-gemma2 (3584d), Alibaba-NLP/gte-Qwen2-1.5B-instruct (1536d), Snowflake/snowflake-arctic-embed-m-v1.5, openai-ada (1536d)")
    chunk_size: Optional[Annotated[int, Field(strict=True, ge=1)]] = Field(default=64, description="Size of chunks in tokens or characters depending on the strategy")
    chunk_overlap: Optional[Annotated[int, Field(strict=True, ge=0)]] = Field(default=6, description="Number of overlapping tokens or characters between chunks")
    extraction_techniques: Optional[Dict[str, Any]] = Field(default=None, description="Extraction techniques for different file types")
    __properties: ClassVar[List[str]] = ["project_id", "chunking_strategy", "embedding_model", "chunk_size", "chunk_overlap", "extraction_techniques"]

    @field_validator('chunking_strategy')
    def chunking_strategy_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(['sentence', 'token', 'markdown', 'json', 'character']):
            raise ValueError("must be one of enum values ('sentence', 'token', 'markdown', 'json', 'character')")
        return value

    @field_validator('embedding_model')
    def embedding_model_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['BAAI/bge-small-en-v1.5', 'neuralmind/bert-base-portuguese-cased', 'BAAI/bge-multilingual-gemma2', 'Alibaba-NLP/gte-Qwen2-1.5B-instruct', 'Snowflake/snowflake-arctic-embed-m-v1.5', 'openai-ada']):
            raise ValueError("must be one of enum values ('BAAI/bge-small-en-v1.5', 'neuralmind/bert-base-portuguese-cased', 'BAAI/bge-multilingual-gemma2', 'Alibaba-NLP/gte-Qwen2-1.5B-instruct', 'Snowflake/snowflake-arctic-embed-m-v1.5', 'openai-ada')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of KnowledgeBaseSettings from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of KnowledgeBaseSettings from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "project_id": obj.get("project_id"),
            "chunking_strategy": obj.get("chunking_strategy"),
            "embedding_model": obj.get("embedding_model") if obj.get("embedding_model") is not None else 'BAAI/bge-small-en-v1.5',
            "chunk_size": obj.get("chunk_size") if obj.get("chunk_size") is not None else 64,
            "chunk_overlap": obj.get("chunk_overlap") if obj.get("chunk_overlap") is not None else 6,
            "extraction_techniques": obj.get("extraction_techniques")
        })
        return _obj


