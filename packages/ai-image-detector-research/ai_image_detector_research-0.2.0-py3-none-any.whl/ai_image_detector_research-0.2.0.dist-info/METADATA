Metadata-Version: 2.3
Name: ai-image-detector-research
Version: 0.2.0
Summary: 
Author: ycalk
Author-email: alosev752@gmail.com
Requires-Python: >=3.11
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: ipywidgets (>=8.1.7,<9.0.0)
Requires-Dist: kagglehub (>=0.3.12,<0.4.0)
Requires-Dist: matplotlib (>=3.10.3,<4.0.0)
Requires-Dist: opencv-python (>=4.12.0.88,<5.0.0.0)
Requires-Dist: pandas (>=2.3.1,<3.0.0)
Requires-Dist: python-dotenv (>=1.1.1,<2.0.0)
Requires-Dist: scikit-learn (>=1.7.0,<2.0.0)
Requires-Dist: seaborn (>=0.13.2,<0.14.0)
Requires-Dist: torch (>=2.7.1,<3.0.0)
Requires-Dist: torchaudio (>=2.7.1,<3.0.0)
Requires-Dist: torchvision (>=0.22.1,<0.23.0)
Requires-Dist: tqdm (>=4.67.1,<5.0.0)
Description-Content-Type: text/markdown

# Создание CNN для распознавания сгенерированных изображений 

## Цель

Цель исследования с нуля обучить CNN распознавать сгенерированные изображения.


## Результаты

### Первые результаты

Для первого обучения были выбраны такие гиперпараметры:

|Параметр|Значение|
|--------|--------|
|Количество conv блоков|4|
|Количество слоев классификатора|2|
|Размер датасета|1000|
|train / val|0.5|
|Эпох|30|

Результат:

|Результат|Значение|
|---------|--------|
|Train Accuracy|0.64|
|Validation Accuracy|0.62|

Точность на обучении и валидации остается ниже ```65%```, что близко к случайному угадыванию (```50%```). Присутствует нестабильность, особенно на валидации, возможно, переобучение на шум или нерегулярные признаки. Также модель не переобучается сильно, но и не обучается хорошо.

Анализируя Confusion Matrix, можно сказать, что настоящие изображения распознается лучше, чем сгенерированные. Модель очень часто принимает сгенерированное изображение за реальное (126 раз предсказано реальное, но являлось сгенерированным)

Модель пока не уверенно распознает сгенерированные изображения.

На следующем цикле обучения стоит попробовать увеличить датасет (1000 изображений, которые использовались в этом цикле, довольно мало). Также попробовать добавить больше conv блоков, слоев классификатора и увеличить число базовых каналов до 128 (кажется, что у модели мало параметров и она довольно узкая чтобы распознавать сгенерированные изображения).

### Вторая итерация

Гиперпараметры:

|Параметр|Значение|
|--------|--------|
|Количество conv блоков|6|
|Количество слоев классификатора|2|
|Размер датасета|5000|
|train / val|0.7|
|Эпох|30|

Результат:

|Результат|Значение|
|---------|--------|
|Train Accuracy|0.50|
|Validation Accuracy|0.50|

Получился ужасный результат, модель абсолютно случайно делает предсказания и не обучается вообще. Проблема скорее всего в том что модель слишком большая для малого датасета.

Confusion Matrix выглядят очень странно, особенно на валидации ```1500 / 1500``` раз модель предсказала изображение как сгенерированное. Почему так произошло - не понятно, возможно, это также связано с тем что размер модели и кол-во данных подобраны не верно.

В этом исследование [DeepGuardNet: A Novel CNN Architecture for DeepFake Image Detection](https://www.sciencedirect.com/science/article/pii/S1877050925014152) обучали модель с очень похожей на мою архитектуру, но заточенную под обнаружение DeepFake в нем они использовали ```140002``` изображений для обучения модели из 5 conv блоков, в каждом из которых не больше 16 каналов + 1 слой классификатора.

Прошлое предположение:

> Также попробовать добавить больше conv блоков, слоев классификатора и увеличить число базовых каналов до 128

Было неверным, нужно оставить предыдущую архитектуру и увеличить кол-во данных. В используемом датасете есть 2.5 млн картинок около 900 тыс настоящие, остальные - сгенерированные ИИ. Для следующего обучения стоит попробовать взять хотя бы 200 000 изображений.
