{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated model training simulation and upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation of the federated training and evaluation procedure for a Federated Model. Once the model completes successfully its simulation it is uploaded to a local model catalogue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An environment with python3.11.* is needed for this simulation, provided with some other packages.\n",
    "\n",
    "If the virtual environment is not ready yet with the dependencies needed for the simulation and for the used model, the following cell will install in the current environment all the necessary packages.\n",
    "\n",
    "For any doubts on the requirement or on how to create a federated model, see the Github repository of the FedModelKit package [here](https://github.com/synthema-project/app-model_store-interface/tree/dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flwr[simulation]==1.9\n",
    "# !pip install 'flwr[simulation]==1.9' # for Mac users\n",
    "!pip install FedModelKit\n",
    "!pip install mlflow\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is used to initialize the directory to upload a model to the platform. In this case the additional argument \"app\" is used to create also the server and client scripts that will be used for the simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fmk init app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Learner Definition\n",
    "\n",
    "The following cell defines a function `create_local_learner` that sets up the local learner for the federated learning process, and a function `create_aggregator` that defines the federated aggregation strategy. The local learner includes the definition of a simple logistic regression model (`SimpleLR`) and its associated methods for data preparation, training, evaluation, and parameter management. The `SimpleLR` class handles the following tasks:\n",
    "\n",
    "- **Data Preparation**: Splits the data into training and validation sets, encodes categorical variables, and scales numerical variables.\n",
    "- **Training**: Trains the logistic regression model on the prepared training data.\n",
    "- **Evaluation**: Evaluates the model on the validation data and returns accuracy metrics.\n",
    "- **Parameter Management**: Includes methods to set and get model parameters, which are essential for the federated learning process where model parameters are shared and aggregated across multiple clients.\n",
    "\n",
    "These functions are crucial for the federated learning simulation as they provide the local model that each client will train and evaluate during the federated learning rounds and the aggregation strategy performed by the central node on model's parameters and metrics coming from the clients.\n",
    "\n",
    "`%%writefile model_example.py` this line produces a model_example.py script where the content of the cell is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`THE MODEL CAN BE MODIFIED WITH WHATEVER MODEL THE USER WANTS TO TEST`\n",
    "\n",
    "The model must be created according to the protocols explained in the Github repository of the FedModelKit package [here](https://github.com/synthema-project/app-model_store-interface/tree/dev)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model_example.py\n",
    "import FedModelKit as fmk\n",
    "\n",
    "# Function defining the local learner\n",
    "def create_local_learner():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "    import flwr\n",
    "    from collections import OrderedDict\n",
    "    import pickle\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Define the local learner class\n",
    "    class SimpleLR:\n",
    "        def __init__(self,\n",
    "                     test_size=0.2, \n",
    "                     random_state=42) -> None:\n",
    "            # Initialize the SimpleLR class with test size and random state\n",
    "            self.test_size = test_size\n",
    "            self.random_state = random_state\n",
    "            self.model = LogisticRegression(warm_start=True)\n",
    "\n",
    "        def prepare_data(self, data: pd.DataFrame) -> None:\n",
    "            # Divide numerical and categorical columns\n",
    "            categorical_cols = ['Gender', 'perf_status', 'secondary', 'ahd', 'eln_2017']\n",
    "            numerical_cols = data.columns.difference(categorical_cols).drop(\"OS_Status\")\n",
    "\n",
    "            # Encode categorical data using pre-trained OneHotEncoder\n",
    "            with open(Path(__file__).parent/\"src\"/\"one_hot_encoder.pkl\", 'rb') as f:\n",
    "                one_hot_encoder = pickle.load(f)\n",
    "            categorical_data = one_hot_encoder.transform(data[categorical_cols])\n",
    "            \n",
    "            # Scale numerical data\n",
    "            scaler = StandardScaler()\n",
    "            numerical_data = scaler.fit_transform(data[numerical_cols])\n",
    "\n",
    "            # Get data and labels dataframes\n",
    "            labels = data['OS_Status']\n",
    "            data = pd.DataFrame(np.hstack([categorical_data, numerical_data]))\n",
    "\n",
    "            # Split data into training and validation sets\n",
    "            self.train_data, self.val_data, self.train_labels, self.val_labels = train_test_split(data, labels, test_size=self.test_size, random_state=self.random_state)\n",
    "\n",
    "        def _parameters_to_dict(self, params_record: flwr.common.ParametersRecord) -> OrderedDict:\n",
    "            # Convert ParametersRecord to an OrderedDict\n",
    "            state_dict = OrderedDict()\n",
    "            for k, v in params_record.items():\n",
    "                state_dict[k] = self._basic_array_deserialisation(v)\n",
    "            return state_dict\n",
    "\n",
    "        def _dict_to_parameter_record(self, \n",
    "            parameters: OrderedDict[\"str\", flwr.common.NDArray],\n",
    "        ) -> flwr.common.ParametersRecord:\n",
    "            # Convert OrderedDict to ParametersRecord\n",
    "            state_dict = OrderedDict()\n",
    "            for k, v in parameters.items():\n",
    "                state_dict[k] = self._ndarray_to_array(v)\n",
    "\n",
    "            return flwr.common.ParametersRecord(state_dict)\n",
    "\n",
    "        def _ndarray_to_array(self, ndarray: flwr.common.NDArray) -> flwr.common.Array:\n",
    "            \"\"\"Represent NumPy ndarray as Array.\"\"\"\n",
    "            return flwr.common.Array(\n",
    "                data=ndarray.tobytes(),\n",
    "                dtype=str(ndarray.dtype),\n",
    "                stype=\"numpy.ndarray.tobytes\",\n",
    "                shape=list(ndarray.shape),\n",
    "            )\n",
    "\n",
    "        def _basic_array_deserialisation(self, array: flwr.common.Array) -> flwr.common.NDArray:\n",
    "            # Deserialize Array to NumPy ndarray\n",
    "            return np.frombuffer(buffer=array.data, dtype=array.dtype).reshape(array.shape)\n",
    "\n",
    "        def train_round(self) -> flwr.common.MetricsRecord:\n",
    "            # Train the model on the training data\n",
    "            self.model.fit(self.train_data, self.train_labels)\n",
    "            predictions = self.model.predict(self.train_data)\n",
    "            loss = np.mean(predictions != self.train_labels)\n",
    "\n",
    "            # Create a MetricsRecord for training loss\n",
    "            return flwr.common.MetricsRecord({\"loss\": loss})\n",
    "\n",
    "        def evaluate(self) -> flwr.common.MetricsRecord:\n",
    "            # Evaluate the model on the validation data\n",
    "            predictions = self.model.predict(self.val_data)\n",
    "            accuracy = float(accuracy_score(self.val_labels, predictions))\n",
    "\n",
    "            # Return a MetricsRecord for accuracy\n",
    "            return flwr.common.MetricsRecord({\"accuracy\": accuracy}) \n",
    "\n",
    "        def _set_initial_parameters(self) -> None:\n",
    "            # Initialize model parameters with dummy data\n",
    "            X_dummy = np.zeros((2, 21))  # 21 features, the length of the feature vector\n",
    "            y_dummy = np.array([0, 1])   # Dummy target\n",
    "            # Fit the model once to initialize coef_\n",
    "            self.model.fit(X_dummy, y_dummy)\n",
    "\n",
    "        def set_parameters(self, parameters: flwr.common.ParametersRecord):\n",
    "            # Convert the ParametersRecord back into an OrderedDict.\n",
    "            state_dict = self._parameters_to_dict(parameters)\n",
    "            \n",
    "            # Set the model's parameters.\n",
    "            if not hasattr(self.model, \"coef_\"):\n",
    "                self._set_initial_parameters()\n",
    "            self.model.coef_ = state_dict[\"coef_\"]\n",
    "            self.model.intercept_ = state_dict[\"intercept_\"]\n",
    "\n",
    "        def get_parameters(self) -> flwr.common.ParametersRecord:\n",
    "            # Get the model's parameters as a ParametersRecord\n",
    "            if not hasattr(self.model, \"coef_\"):\n",
    "                self._set_initial_parameters()\n",
    "            param_dict = {}\n",
    "            param_dict[\"coef_\"] = np.array(self.model.coef_)\n",
    "            param_dict[\"intercept_\"] = np.array(self.model.intercept_)\n",
    "\n",
    "            return self._dict_to_parameter_record(OrderedDict(param_dict))\n",
    "        \n",
    "    return SimpleLR()\n",
    "\n",
    "\n",
    "# Function defining the aggregator\n",
    "def create_aggregator():\n",
    "    from collections import OrderedDict\n",
    "    import numpy as np\n",
    "    import flwr\n",
    "    from typing import Optional\n",
    "\n",
    "    # Define the custom aggregator class\n",
    "    class CustomAggregator:\n",
    "\n",
    "        def _parameters_to_dict(self, params_record: flwr.common.ParametersRecord) -> OrderedDict:\n",
    "            # Convert ParametersRecord to an OrderedDict\n",
    "            state_dict = OrderedDict()\n",
    "            for k, v in params_record.items():\n",
    "                state_dict[k] = self._basic_array_deserialisation(v)\n",
    "            return state_dict\n",
    "\n",
    "        def _dict_to_parameter_record(self, \n",
    "            parameters: OrderedDict[\"str\", flwr.common.NDArray],\n",
    "        ) -> flwr.common.ParametersRecord:\n",
    "            # Convert OrderedDict to ParametersRecord\n",
    "            state_dict = OrderedDict()\n",
    "            for k, v in parameters.items():\n",
    "                state_dict[k] = self._ndarray_to_array(v)\n",
    "\n",
    "            return flwr.common.ParametersRecord(state_dict)\n",
    "\n",
    "        def _ndarray_to_array(self, ndarray: flwr.common.NDArray) -> flwr.common.Array:\n",
    "            \"\"\"Represent NumPy ndarray as Array.\"\"\"\n",
    "            return flwr.common.Array(\n",
    "                data=ndarray.tobytes(),\n",
    "                dtype=str(ndarray.dtype),\n",
    "                stype=\"numpy.ndarray.tobytes\",\n",
    "                shape=list(ndarray.shape),\n",
    "            )\n",
    "\n",
    "        def _basic_array_deserialisation(self, array: flwr.common.Array) -> flwr.common.NDArray:\n",
    "            # Deserialize Array to NumPy ndarray\n",
    "            return np.frombuffer(buffer=array.data, dtype=array.dtype).reshape(array.shape)\n",
    "\n",
    "        def aggregate_parameters(self, results: list[flwr.common.ParametersRecord], config: Optional[flwr.common.ConfigsRecord]=None\n",
    "            ) -> flwr.common.ParametersRecord:\n",
    "                parameters = [self._parameters_to_dict(param) for param in results]\n",
    "                keys = parameters[0].keys()\n",
    "                result = OrderedDict()\n",
    "                for key in keys:\n",
    "                    # Init array\n",
    "                    this_array: np.ndarray = np.zeros_like(parameters[0][key])\n",
    "                    for p in parameters:\n",
    "                        this_array += p[key]\n",
    "                    result[key] = this_array / len(results)\n",
    "                return self._dict_to_parameter_record(result)\n",
    "\n",
    "        def aggregate_metrics(self, results: list[flwr.common.MetricsRecord], config: Optional[flwr.common.ConfigsRecord]=None) -> flwr.common.MetricsRecord:\n",
    "                keys = results[0].keys()\n",
    "                result = OrderedDict()\n",
    "                for key in keys:\n",
    "                    # Init array\n",
    "                    cumsum = 0.0\n",
    "                    for m in results:\n",
    "                        if not isinstance(m[key], (int, float)):\n",
    "                            raise ValueError(\n",
    "                                f\"flwr.common.MetricsRecord value type not supported: {type(m[key])}\"\n",
    "                            )\n",
    "                        cumsum += m[key]  # type: ignore\n",
    "                    result[key] = cumsum / len(results)\n",
    "                return flwr.common.MetricsRecord(result)\n",
    "    \n",
    "    return CustomAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Type-check:` make sure to type-check the function/s you created in the following cell according to the protocols indicated in the package [repository](https://github.com/synthema-project/app-model_store-interface/tree/dev) referenced before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FedModelKit as fmk\n",
    "from model_example import create_local_learner as create_ll_check # Use alias here to avoid name conflict when uploading the model\n",
    "from model_example import create_aggregator as create_agg_check # Use alias here to avoid name conflict when uploading the model\n",
    "\n",
    "fmk.FederatedModel(create_local_learner=create_ll_check, \n",
    "                    model_name='simple_lr',\n",
    "                    create_aggregator=create_agg_check,\n",
    "                    aggregator_name='custom_aggregator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines a function `load_data` that loads and preprocesses the local dataset for each client in the federated learning setup. Here are the key steps and the role of the OneHotEncoder matrix:\n",
    "\n",
    "1. **Load Local Data**: The function loads the dataset from an Excel file and drops the 'Index' column. The dataset used was obtained from a public data repository (Tazi et al. https://github.com/papaemmelab/Tazi_NatureC_AML?tab=readme-ov-file), then reduced and preprocessed.\n",
    "\n",
    "2. **OneHotEncoder for Categorical Variables**:\n",
    "    - The function uses `OneHotEncoder` to encode categorical variables, ensuring consistency across all clients.\n",
    "    - The OneHotEncoder matrix is fitted on the entire dataset, capturing the complete information about the categorical variables.\n",
    "    - This matrix is crucial because each client only has a portion of the dataset, and without the complete information, they would have incomplete or inconsistent encodings.\n",
    "\n",
    "3. **Save OneHotEncoder Matrix**:\n",
    "    - The OneHotEncoder matrix is saved as a pickle file in the `src` directory.\n",
    "    - This directory will be uploaded with the federated model, ensuring that the encoder is available to all clients when they download the model.\n",
    "    - This ensures that the model can correctly encode categorical variables during training and evaluation, maintaining consistency across all clients.\n",
    "\n",
    "4. **Split Data Among Clients**: The dataset is split into portions based on the number of clients, and each client receives its respective portion.\n",
    "\n",
    "This function ensures that all clients have consistent and complete information about the categorical variables, which is essential for the federated learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`THE LOAD_DATA FUNCTION MUST BE ADAPTED TO THE USER'S CUSTOM MODEL`\n",
    "\n",
    "If the local model needs to be preprocessed with information from the whole dataset, such information must be stored inside the 'src' folder. For this simulation the structure-related information about the whole dataset is created and stored in the 'src' folder by each client, while for users who directly want to upload their model the process must be performed just  once, right before the upload.\n",
    "\n",
    "`Careful!:` don't upload to the src folder sensitive information from the dataset, just structure-related information.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile load_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data(num_clients: int, client_id: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and preprocess the local dataset (for this simulation will be a split of the whole dataset) for each client in the \n",
    "    federated learning process. It also stores the OneHotEncoder matrix in a pickle file in the src directory that will be\n",
    "    uploaded with the federated model. It will be used by the model as information to encode the categorical data.\n",
    "\n",
    "    Args:\n",
    "        num_clients (int): The total number of clients participating in the federated learning process.\n",
    "        client_id (int): The unique identifier for the current client.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The portion of the dataset assigned to the current client.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load local data from an Excel file and drop the 'Index' column\n",
    "    data = pd.read_excel('./AML_preprocessed_dataset.xlsx').drop(\"Index\", axis=1) # !!Change the path to the dataset!!\n",
    "\n",
    "    # Get mapping for categorical variables using OneHotEncoder to ensure consistency across clients\n",
    "    categorical_cols = ['Gender', 'perf_status', 'secondary', 'ahd', 'eln_2017']\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    matrix = one_hot_encoder.fit(data[categorical_cols])\n",
    "    \n",
    "    # Store the OneHotEncoder matrix in a pickle file in the src directory \n",
    "    # that will be uploaded with the federated model\n",
    "    if not Path('src').exists():\n",
    "        Path('src').mkdir()\n",
    "    if not Path('src/one_hot_encoder.pkl').exists():\n",
    "        with open('src/one_hot_encoder.pkl', 'wb') as f:\n",
    "            pickle.dump(matrix, f)\n",
    "\n",
    "    # Split the data among clients based on the number of clients specified in the config\n",
    "    data_split = np.array_split(data, num_clients, axis=0) \n",
    "    data = data_split[client_id]\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of Federated Training and Evaluation\n",
    "\n",
    "In this section, we will simulate the federated training and evaluation process using the defined client and server applications. The simulation will involve multiple rounds of training and evaluation, where the global model parameters are updated based on the aggregated results from the clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the apps folder, generated by the initialization process performed before, there is a Python script named `client_app.py` which defines the client processes for the federated learning simulation. Here are the steps involved:\n",
    "\n",
    "1. **Import Necessary Libraries**: The cell imports essential libraries such as `numpy`, `pandas`, `flwr`, `sklearn`, and `FedModelKit`.\n",
    "\n",
    "2. **Define the Flower ClientApp**: An instance of `ClientApp` from Flower is created to handle the client-side operations.\n",
    "\n",
    "3. **Define the `train` Function**:\n",
    "    - **Log Local Context**: Logs the metrics from the previous round if available.\n",
    "    - **Instantiate Model**: Creates an instance of the federated model using the `create_local_learner` function.\n",
    "    - **Set Model Parameters**: Sets the model parameters received from the server.\n",
    "    - **Load Local Data**: Loads the local dataset from an Excel file and preprocesses it.\n",
    "    - **Prepare Data**: Prepares the data by encoding categorical variables and splitting it among clients.\n",
    "    - **Local Training**: Trains the local model and retrieves training metrics.\n",
    "    - **Construct Reply Message**: Constructs a reply message containing updated model parameters and training metrics.\n",
    "\n",
    "4. **Define the `evaluate` Function**:\n",
    "    - **Instantiate Model**: Creates an instance of the federated model using the `create_local_learner` function.\n",
    "    - **Set Model Parameters**: Sets the model parameters received from the server.\n",
    "    - **Load Local Data**: Loads the local dataset from an Excel file and preprocesses it.\n",
    "    - **Prepare Data**: Prepares the data by encoding categorical variables and splitting it among clients.\n",
    "    - **Evaluate Model**: Evaluates the model on the validation data and retrieves evaluation metrics.\n",
    "    - **Construct Reply Message**: Constructs a reply message containing evaluation metrics.\n",
    "\n",
    "\n",
    "These steps collectively define the client-side operations for training and evaluating the model in a federated learning setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`DON'T MODIFY THE CLIENT! AS IT REFLECTS THE STANDARD CLIENT PROCESS` (unless you know what you are doing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the apps folder, generated by the initialization process performed before, there is a Python script named `server_app.py` which defines the server-side operations for the federated learning simulation. Here are the steps involved:\n",
    "\n",
    "1. **Import Necessary Libraries**: The cell imports essential libraries such as `flwr`, `FedModelKit`, and `create_local_learner` from `model_example.py`.\n",
    "\n",
    "2. **Define the Flower ServerApp**: An instance of `ServerApp` from Flower is created to handle the server-side operations.\n",
    "\n",
    "3. **Define the `main` Function**:\n",
    "    - **Initialize Federated Model**: Creates an instance of the federated model using the `create_local_learner` function and sets up the global model and aggregation strategy.\n",
    "    - **Server Rounds**: Iterates through multiple rounds of federated learning.\n",
    "        - **Get Node IDs**: Retrieves the IDs of the participating clients.\n",
    "        - **Create and Send Messages**: Constructs messages containing model parameters and configuration settings, and sends them to the clients.\n",
    "        - **Wait for Client Replies**: Waits for the clients to complete their training and send back their results.\n",
    "        - **Aggregate Parameters**: Aggregates the parameters received from the clients to update the global model.\n",
    "        - **Evaluate the Model**: Sends the updated global model to the clients for evaluation and aggregates the evaluation metrics.\n",
    "\n",
    "These steps collectively define the server-side operations for coordinating the training and evaluation of the model in a federated learning setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`DON'T MODIFY THE SERVER! AS IT REFLECTS THE STANDARD SERVER PROCESS` (unless you know what you are doing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command initiates the federated learning simulation by specifying the client and server applications and the number of supernodes (nodes that simulate multiple clients):\n",
    "\n",
    "\n",
    "- `--client-app=client_app:app`: Specifies the client application script (`client_app.py`) and the application instance (`app`) to be used for the simulation.\n",
    "- `--server-app=server_app:app`: Specifies the server application script (`server_app.py`) and the application instance (`app`) to be used for the simulation.\n",
    "- `--num-supernodes=2`: Defines the number of supernodes to be used in the simulation. Each supernode can simulate multiple clients, allowing for scalable federated learning simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flower-simulation --client-app=apps.client_app:app --server-app=apps.server_app:app --num-supernodes=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the simulation completes successfully with the expected results, the model is ready to be uploaded to the model registry. This allows the model to be utilized in future federated learning tasks, ensuring that it behaves in the expected way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will describe the process of uploading the tested federated model to the model registry. This step ensures that the model is stored securely and can be accessed for future federated learning tasks.\n",
    "\n",
    "A more detailed description of this part is provided at this link: [Github/FedModelKit](https://github.com/synthema-project/app-model_store-interface/tree/dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated model creation with default aggregation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model_example.py # Run the model_example.py file to directly get the functions defining the local learner and aggregator \n",
    "import FedModelKit as fmk\n",
    "\n",
    "# Create an instance of the FederatedModel class from the FedModelKit module.\n",
    "# This class handles the federated learning process, including model creation, training, and aggregation.\n",
    "# The create_local_learner and create_aggregator functions is passed as an argument to define the local learner (model)\n",
    "# for each client. Here the functions used are the ones defined in the model_example.py file.\n",
    "federated_model = fmk.FederatedModel(create_local_learner=create_local_learner, # type: ignore # Make sure you already type-checked the function\n",
    "                                     model_name='simple_lr',\n",
    "                                     create_aggregator=create_aggregator, # type: ignore # Make sure you already type-checked the function\n",
    "                                     aggregator_name='custom_aggregator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local model registry server creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model must be uploaded to a model registry server. For this example's sake a local molflow server is enough. It can be opened running the following command on a dedicated terminal (using the same environment used in this notebook):\n",
    "```bash\n",
    "mlflow server --host 0.0.0.0 --port 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated model upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the federated model to the model registry server using the FedModelKit module.\n",
    "# This function uploads the trained federated model to the specified platform URL.\n",
    "# Parameters:\n",
    "# - model: The federated model instance to be uploaded.\n",
    "# - platform_url: The URL of the model registry server where the model will be uploaded.\n",
    "# - username: The username for authentication (if required).\n",
    "# - password: The password for authentication (if required).\n",
    "# - experiment_name: The name of the experiment under which the model will be registered.\n",
    "# - disease: The disease category associated with the model (e.g., AML for Acute Myeloid Leukemia).\n",
    "# - trained: A boolean flag indicating whether the model has been trained.\n",
    "\n",
    "\n",
    "# HERE you should produce the information about the whole dataset needed by you model and store it in\n",
    "# the src directory, UNLESS you performed the simulation and the clients already stored it.\n",
    "\n",
    "fmk.submit_fl_model(model=federated_model,\n",
    "                    platform_url='http://localhost:5000',  # URL of the local MLflow server\n",
    "                    username='username',  # Username for authentication (If no username is required , put a mock username)\n",
    "                    password='password',  # Password for authentication (if no password is required, put a mock password)\n",
    "                    experiment_name='simulation_experiment',  # Name of the experiment\n",
    "                    disease='AML',  # Disease category associated with the model\n",
    "                    trained=False  # Indicates that the model has been trained\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_upload",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
