# chunkle

**Smart text chunking** that respects both line and token limits while preserving semantic boundaries.

GitHub: [https://github.com/allen2c/chunkle](https://github.com/allen2c/chunkle)
Pypi: [https://pypi.org/project/chunkle/](https://pypi.org/project/chunkle/)

## Install

```bash
pip install chunkle
```

## Quick Start

```python
from chunkle import chunk

# Basic usage
for piece in chunk(text, lines_per_chunk=20, tokens_per_chunk=500):
    print(piece)

# Custom limits
chunks = list(chunk(text, lines_per_chunk=5, tokens_per_chunk=100))
```

## How It Works

```mermaid
flowchart TD
    A["ğŸ“ Start processing text"] --> B["ğŸ“Š Accumulate chars<br/>Count lines & tokens"]
    B --> C{"âœ… Both limits met?<br/>(lines â‰¥ min AND tokens â‰¥ min)"}
    C -->|No| D{"ğŸš¨ Exceeded 2x limits?"}
    C -->|Yes| E{"ğŸ¯ Good break point?<br/>(newline > whitespace)"}

    D -->|No| B
    D -->|Yes| F["ğŸ’¥ Force flush<br/>(semantic boundary ignored)"]

    E -->|No| D
    E -->|Yes| G["âœ‚ï¸ Flush chunk<br/>(clean semantic boundary)"]

    F --> H["ğŸ§½ Absorb whitespace/punctuation<br/>into previous chunk"]
    G --> H
    H --> I{"ğŸ“„ More text?"}
    I -->|Yes| B
    I -->|No| J["ğŸ Done"]
```

### Rules

1. **Dual Requirements**: Chunks must meet BOTH line AND token minimums
2. **Smart Boundaries**: Prefers newlines (best) > whitespace (good) > force split
3. **Force Split**: Splits at 2x limits even if it breaks semantics
4. **Clean Starts**: New chunks begin with meaningful characters

## Examples

**English Text:**

```python
text = "Hello world!\nThis is a test.\nAnother line here."
chunks = list(chunk(text, lines_per_chunk=1, tokens_per_chunk=8))
# Result: ['Hello world!\n', 'This is a test.\n', 'Another line here.']
```

**Chinese Text (force split):**

```python
text = "é€™æ˜¯ä¸€å€‹å¾ˆé•·çš„å¥å­ï¼Œæ²’æœ‰ç©ºæ ¼ï¼Œæœƒè§¸ç™¼å¼·åˆ¶åˆ‡åˆ†æ©Ÿåˆ¶ã€‚"
chunks = list(chunk(text, lines_per_chunk=1, tokens_per_chunk=10))
# May split mid-sentence when no whitespace available
```

## API

```python
def chunk(
    content: str,
    *,
    lines_per_chunk: int = 20,
    tokens_per_chunk: int = 500,
    encoding: tiktoken.Encoding | None = None,
) -> Generator[str, None, None]:
```

**Parameters:**

- `content`: Text to split
- `lines_per_chunk`: Minimum lines per chunk (default: 20)
- `tokens_per_chunk`: Minimum tokens per chunk (default: 500)
- `encoding`: Custom tiktoken encoding (default: gpt-4o-mini)

## License

MIT Â© 2025 Allen Chou
