#!/usr/bin/env python3
"""
Compare bulk vs streaming indicators in a realistic real-time trading scenario.

This simulates a live trading environment where new price ticks arrive continuously,
and we need to calculate indicator values for each new tick.
"""

import numpy as np
import time
from typing import List, Dict, Tuple
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

# Import bulk functions
from ta_numba.trend import sma_numba, ema_numba
from ta_numba.momentum import relative_strength_index_numba
from ta_numba.volatility import average_true_range_numba, bollinger_bands_numba
from ta_numba.volume import on_balance_volume_numba, money_flow_index_numba

# Import streaming classes
from ta_numba.streaming import (
    SMAStreaming, EMAStreaming, RSIStreaming, ATRStreaming,
    BBandsStreaming, OnBalanceVolumeStreaming, MoneyFlowIndexStreaming
)


class RealTimeMarketSimulator:
    """Simulate a real-time market data feed."""
    
    def __init__(self, initial_price: float = 100.0, volatility: float = 0.02):
        self.current_price = initial_price
        self.volatility = volatility
        self.tick_count = 0
        
    def get_next_tick(self) -> Dict[str, float]:
        """Generate next market tick with OHLCV data."""
        # Simulate price movement
        change = np.random.normal(0.0001, self.volatility)
        self.current_price *= (1 + change)
        
        # Generate OHLC
        daily_range = np.random.uniform(0.005, 0.025)
        high = self.current_price * (1 + daily_range * np.random.uniform(0.3, 0.7))
        low = self.current_price * (1 - daily_range * np.random.uniform(0.3, 0.7))
        open_price = self.current_price * np.random.uniform(0.995, 1.005)
        volume = np.random.randint(1000, 10000)
        
        self.tick_count += 1
        
        return {
            'timestamp': datetime.now() + timedelta(seconds=self.tick_count),
            'open': open_price,
            'high': high,
            'low': low,
            'close': self.current_price,
            'volume': float(volume)
        }


def benchmark_realtime_scenario():
    """Benchmark bulk vs streaming in real-time scenario."""
    print("üöÄ REAL-TIME STREAMING COMPARISON")
    print("=" * 60)
    print("Simulating live market data feed with continuous price updates...")
    print()
    
    # Configuration
    WARMUP_TICKS = 100  # Initial data for indicators
    LIVE_TICKS = 10000   # Live trading ticks
    LOOKBACK_WINDOW = 10000  # How much history to keep for bulk calculation
    
    # Initialize market simulator
    market = RealTimeMarketSimulator()
    
    # Generate warmup data
    print(f"üìä Generating {WARMUP_TICKS} warmup ticks...")
    warmup_data = []
    for _ in range(WARMUP_TICKS):
        warmup_data.append(market.get_next_tick())
    
    # Convert to arrays for bulk calculation
    close_warmup = np.array([tick['close'] for tick in warmup_data])
    high_warmup = np.array([tick['high'] for tick in warmup_data])
    low_warmup = np.array([tick['low'] for tick in warmup_data])
    volume_warmup = np.array([tick['volume'] for tick in warmup_data])
    
    # Warm up JIT compilation
    print("üî• Warming up JIT compilation...")
    _ = sma_numba(close_warmup, 20)
    _ = ema_numba(close_warmup, 20)
    _ = relative_strength_index_numba(close_warmup, 14)
    _ = average_true_range_numba(high_warmup, low_warmup, close_warmup, 14)
    _ = bollinger_bands_numba(close_warmup, 20)
    _ = on_balance_volume_numba(close_warmup, volume_warmup)
    _ = money_flow_index_numba(high_warmup, low_warmup, close_warmup, volume_warmup, 14)
    
    # Initialize streaming indicators
    print("üìà Initializing streaming indicators...")
    streaming_indicators = {
        'SMA': SMAStreaming(20),
        'EMA': EMAStreaming(20),
        'RSI': RSIStreaming(14),
        'ATR': ATRStreaming(14),
        'BBands': BBandsStreaming(20),
        'OBV': OnBalanceVolumeStreaming(),
        'MFI': MoneyFlowIndexStreaming(14)
    }
    
    # Warm up streaming indicators with historical data
    for tick in warmup_data:
        streaming_indicators['SMA'].update(tick['close'])
        streaming_indicators['EMA'].update(tick['close'])
        streaming_indicators['RSI'].update(tick['close'])
        streaming_indicators['ATR'].update(tick['high'], tick['low'], tick['close'])
        streaming_indicators['BBands'].update(tick['close'])
        streaming_indicators['OBV'].update(tick['close'], tick['volume'])
        streaming_indicators['MFI'].update(tick['high'], tick['low'], tick['close'], tick['volume'])
    
    # Store timing results
    bulk_times = []
    streaming_times = []
    
    # Historical data buffer for bulk calculation
    historical_buffer = {
        'close': list(close_warmup[-LOOKBACK_WINDOW:]),
        'high': list(high_warmup[-LOOKBACK_WINDOW:]),
        'low': list(low_warmup[-LOOKBACK_WINDOW:]),
        'volume': list(volume_warmup[-LOOKBACK_WINDOW:])
    }
    
    print(f"\nüéØ SIMULATING {LIVE_TICKS:,} LIVE MARKET TICKS...")
    print("-" * 60)
    
    # Progress tracking
    progress_interval = LIVE_TICKS // 10
    
    for i in range(LIVE_TICKS):
        # Get next market tick
        tick = market.get_next_tick()
        
        # === BULK PROCESSING APPROACH ===
        # Add new tick to historical buffer
        historical_buffer['close'].append(tick['close'])
        historical_buffer['high'].append(tick['high'])
        historical_buffer['low'].append(tick['low'])
        historical_buffer['volume'].append(tick['volume'])
        
        # Keep only lookback window
        if len(historical_buffer['close']) > LOOKBACK_WINDOW:
            historical_buffer['close'].pop(0)
            historical_buffer['high'].pop(0)
            historical_buffer['low'].pop(0)
            historical_buffer['volume'].pop(0)
        
        # Convert to arrays
        close_array = np.array(historical_buffer['close'])
        high_array = np.array(historical_buffer['high'])
        low_array = np.array(historical_buffer['low'])
        volume_array = np.array(historical_buffer['volume'])
        
        # Calculate all indicators using bulk functions
        start_bulk = time.perf_counter()
        
        bulk_sma = sma_numba(close_array, 20)[-1]
        bulk_ema = ema_numba(close_array, 20)[-1]
        bulk_rsi = relative_strength_index_numba(close_array, 14)[-1]
        bulk_atr = average_true_range_numba(high_array, low_array, close_array, 14)[-1]
        bulk_bb_upper, bulk_bb_middle, bulk_bb_lower = bollinger_bands_numba(close_array, 20)
        bulk_bb = {'upper': bulk_bb_upper[-1], 'middle': bulk_bb_middle[-1], 'lower': bulk_bb_lower[-1]}
        bulk_obv = on_balance_volume_numba(close_array, volume_array)[-1]
        bulk_mfi = money_flow_index_numba(high_array, low_array, close_array, volume_array, 14)[-1]
        
        bulk_time = time.perf_counter() - start_bulk
        bulk_times.append(bulk_time)
        
        # === STREAMING APPROACH ===
        start_streaming = time.perf_counter()
        
        stream_sma = streaming_indicators['SMA'].update(tick['close'])
        stream_ema = streaming_indicators['EMA'].update(tick['close'])
        stream_rsi = streaming_indicators['RSI'].update(tick['close'])
        stream_atr = streaming_indicators['ATR'].update(tick['high'], tick['low'], tick['close'])
        stream_bb = streaming_indicators['BBands'].update(tick['close'])
        stream_obv = streaming_indicators['OBV'].update(tick['close'], tick['volume'])
        stream_mfi = streaming_indicators['MFI'].update(tick['high'], tick['low'], tick['close'], tick['volume'])
        
        streaming_time = time.perf_counter() - start_streaming
        streaming_times.append(streaming_time)
        
        # Progress update
        if (i + 1) % progress_interval == 0:
            progress = (i + 1) / LIVE_TICKS * 100
            avg_bulk = np.mean(bulk_times[-progress_interval:]) * 1000
            avg_streaming = np.mean(streaming_times[-progress_interval:]) * 1000
            print(f"Progress: {progress:>3.0f}% | "
                  f"Avg Bulk: {avg_bulk:>6.3f}ms | "
                  f"Avg Streaming: {avg_streaming:>6.3f}ms | "
                  f"Speedup: {avg_bulk/avg_streaming:>5.1f}x")
    
    # Calculate final statistics
    bulk_times_ms = np.array(bulk_times) * 1000
    streaming_times_ms = np.array(streaming_times) * 1000
    
    print("\nüìä FINAL RESULTS")
    print("=" * 60)
    print(f"Total ticks processed: {LIVE_TICKS:,}")
    print(f"Lookback window size: {LOOKBACK_WINDOW}")
    print()
    
    print("‚è±Ô∏è  TIMING STATISTICS (per tick):")
    print(f"{'Method':<15} {'Mean':>10} {'Median':>10} {'95%ile':>10} {'99%ile':>10}")
    print("-" * 55)
    
    # Bulk statistics
    print(f"{'Bulk':<15} {np.mean(bulk_times_ms):>9.3f}ms "
          f"{np.median(bulk_times_ms):>9.3f}ms "
          f"{np.percentile(bulk_times_ms, 95):>9.3f}ms "
          f"{np.percentile(bulk_times_ms, 99):>9.3f}ms")
    
    # Streaming statistics
    print(f"{'Streaming':<15} {np.mean(streaming_times_ms):>9.3f}ms "
          f"{np.median(streaming_times_ms):>9.3f}ms "
          f"{np.percentile(streaming_times_ms, 95):>9.3f}ms "
          f"{np.percentile(streaming_times_ms, 99):>9.3f}ms")
    
    print()
    print("üöÄ PERFORMANCE IMPROVEMENT:")
    speedup = np.mean(bulk_times_ms) / np.mean(streaming_times_ms)
    print(f"Average speedup: {speedup:.1f}x faster")
    print(f"Median speedup: {np.median(bulk_times_ms) / np.median(streaming_times_ms):.1f}x faster")
    
    # Memory usage comparison
    print("\nüíæ MEMORY USAGE COMPARISON:")
    print(f"Bulk approach: O(n) = {LOOKBACK_WINDOW} * 8 bytes * 7 indicators = {LOOKBACK_WINDOW * 8 * 7 / 1024:.1f} KB")
    print(f"Streaming approach: O(1) = ~1 KB total (constant)")
    print(f"Memory efficiency: {LOOKBACK_WINDOW * 8 * 7 / 1024:.0f}x less memory")
    
    # Latency analysis
    print("\n‚ö° LATENCY ANALYSIS:")
    print(f"Bulk 99th percentile: {np.percentile(bulk_times_ms, 99):.3f}ms")
    print(f"Streaming 99th percentile: {np.percentile(streaming_times_ms, 99):.3f}ms")
    print(f"For HFT (<1ms requirement): {'‚ùå Bulk fails' if np.percentile(bulk_times_ms, 99) > 1.0 else '‚úÖ Bulk passes'}, "
          f"{'‚úÖ Streaming passes' if np.percentile(streaming_times_ms, 99) < 1.0 else '‚ùå Streaming fails'}")
    
    # Create visualization
    create_performance_visualization(bulk_times_ms, streaming_times_ms)
    
    return bulk_times_ms, streaming_times_ms


def create_performance_visualization(bulk_times: np.ndarray, streaming_times: np.ndarray):
    """Create performance comparison visualization."""
    try:
        plt.figure(figsize=(12, 8))
        
        # Subplot 1: Time series of latencies
        plt.subplot(2, 2, 1)
        plt.plot(bulk_times[:200], label='Bulk', alpha=0.7, color='red')
        plt.plot(streaming_times[:200], label='Streaming', alpha=0.7, color='green')
        plt.xlabel('Tick Number')
        plt.ylabel('Latency (ms)')
        plt.title('Per-Tick Latency (First 200 ticks)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Subplot 2: Histogram comparison
        plt.subplot(2, 2, 2)
        bins = np.linspace(0, max(np.percentile(bulk_times, 99), np.percentile(streaming_times, 99)), 50)
        plt.hist(bulk_times, bins=bins, alpha=0.5, label='Bulk', color='red', density=True)
        plt.hist(streaming_times, bins=bins, alpha=0.5, label='Streaming', color='green', density=True)
        plt.xlabel('Latency (ms)')
        plt.ylabel('Density')
        plt.title('Latency Distribution')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Subplot 3: Box plot comparison
        plt.subplot(2, 2, 3)
        plt.boxplot([streaming_times, bulk_times], labels=['Streaming', 'Bulk'])
        plt.ylabel('Latency (ms)')
        plt.title('Latency Box Plot')
        plt.grid(True, alpha=0.3)
        
        # Subplot 4: Cumulative distribution
        plt.subplot(2, 2, 4)
        sorted_bulk = np.sort(bulk_times)
        sorted_streaming = np.sort(streaming_times)
        p = np.linspace(0, 100, len(bulk_times))
        
        plt.plot(sorted_bulk, p, label='Bulk', color='red')
        plt.plot(sorted_streaming, p, label='Streaming', color='green')
        plt.xlabel('Latency (ms)')
        plt.ylabel('Percentile')
        plt.title('Cumulative Distribution')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('realtime_streaming_performance.png', dpi=150)
        print("\nüìà Performance visualization saved to 'realtime_streaming_performance.png'")
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è  Could not create visualization: {e}")


def analyze_use_cases():
    """Analyze different trading use cases."""
    print("\nüéØ USE CASE ANALYSIS")
    print("=" * 60)
    
    print("\n1Ô∏è‚É£ HIGH-FREQUENCY TRADING (< 1ms latency requirement):")
    print("   Bulk Processing: ‚ùå Too slow, requires recalculating entire array")
    print("   Streaming: ‚úÖ Sub-millisecond updates, perfect for HFT")
    
    print("\n2Ô∏è‚É£ REAL-TIME DASHBOARDS (< 100ms update):")
    print("   Bulk Processing: ‚ö†Ô∏è  Possible but inefficient")
    print("   Streaming: ‚úÖ Optimal choice, minimal latency")
    
    print("\n3Ô∏è‚É£ HISTORICAL BACKTESTING (process years of data):")
    print("   Bulk Processing: ‚úÖ Optimal, vectorized operations")
    print("   Streaming: ‚ùå Unnecessary overhead for historical data")
    
    print("\n4Ô∏è‚É£ LIVE TRADING BOTS (1-60 second intervals):")
    print("   Bulk Processing: ‚ö†Ô∏è  Works but wastes resources")
    print("   Streaming: ‚úÖ Efficient and scalable")
    
    print("\n5Ô∏è‚É£ MULTI-SYMBOL MONITORING (100+ symbols):")
    print("   Bulk Processing: ‚ùå Memory explosion (100 * lookback * indicators)")
    print("   Streaming: ‚úÖ Constant memory per symbol")


def main():
    """Run the real-time comparison."""
    # Run main benchmark
    bulk_times, streaming_times = benchmark_realtime_scenario()
    
    # Analyze use cases
    analyze_use_cases()
    
    print("\n‚úÖ CONCLUSION")
    print("=" * 60)
    print("In real-time trading scenarios, streaming indicators are:")
    print(f"‚Ä¢ {np.mean(bulk_times) / np.mean(streaming_times):.1f}x faster on average")
    print(f"‚Ä¢ {500 * 8 * 7 / 1024:.0f}x more memory efficient")
    print("‚Ä¢ Provide constant O(1) latency regardless of history size")
    print("‚Ä¢ Essential for production trading systems")
    
    print("\nüèÅ Real-time streaming comparison complete!")


if __name__ == "__main__":
    main()