# TestTeller RAG Agent Configuration Example
# Copy this file to .env and update the values as needed

# =============================================================================
# LLM PROVIDER CONFIGURATION (Required: Choose one)
# =============================================================================
# Available providers: gemini, openai, claude, llama
LLM_PROVIDER=gemini

# -----------------------------------------------------------------------------
# Google Gemini Configuration (Required for Gemini provider)
# -----------------------------------------------------------------------------
# Get your API key from: https://aistudio.google.com/
GOOGLE_API_KEY=your_gemini_api_key_here
GEMINI_EMBEDDING_MODEL=text-embedding-004
GEMINI_GENERATION_MODEL=gemini-2.0-flash

# -----------------------------------------------------------------------------
# OpenAI Configuration (Required for OpenAI provider, also needed for Claude embeddings)
# -----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_GENERATION_MODEL=gpt-4o-mini

# -----------------------------------------------------------------------------
# Anthropic Claude Configuration (Required for Claude provider)
# -----------------------------------------------------------------------------
# Get your API key from: https://console.anthropic.com/
# Note: Claude also requires OPENAI_API_KEY for embeddings
CLAUDE_API_KEY=your_claude_api_key_here
CLAUDE_GENERATION_MODEL=claude-3-5-haiku-20241022

# -----------------------------------------------------------------------------
# Llama/Ollama Configuration (Required for Llama provider - local models)
# -----------------------------------------------------------------------------
# Install Ollama from: https://ollama.ai/
# No API key required - runs locally
LLAMA_EMBEDDING_MODEL=llama3.2:1b
LLAMA_GENERATION_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# OPTIONAL CONFIGURATIONS
# =============================================================================

# -----------------------------------------------------------------------------
# GitHub Integration (Optional)
# -----------------------------------------------------------------------------
# Personal Access Token for accessing private repositories
# Get from: https://github.com/settings/tokens
GITHUB_TOKEN=your_github_token_here

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
LOG_LEVEL=ERROR
LOG_FORMAT=json

# -----------------------------------------------------------------------------
# ChromaDB Configuration
# -----------------------------------------------------------------------------
# Local ChromaDB settings
CHROMA_DB_HOST=localhost
CHROMA_DB_PORT=8000
CHROMA_DB_USE_REMOTE=false
CHROMA_DB_PERSIST_DIRECTORY=./chroma_data
DEFAULT_COLLECTION_NAME=test_documents

# -----------------------------------------------------------------------------
# Document Processing Configuration
# -----------------------------------------------------------------------------
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
CODE_EXTENSIONS=.py,.js,.ts,.java,.go,.rs,.cpp,.c,.cs,.rb,.php
TEMP_CLONE_DIR_BASE=./temp_cloned_repos

# -----------------------------------------------------------------------------
# Output Configuration
# -----------------------------------------------------------------------------
OUTPUT_FILE_PATH=testteller-testcases.md

# -----------------------------------------------------------------------------
# API Retry Configuration
# -----------------------------------------------------------------------------
API_RETRY_ATTEMPTS=3
API_RETRY_WAIT_SECONDS=2

# =============================================================================
# PROVIDER-SPECIFIC NOTES
# =============================================================================

# Gemini (Default):
# - Fast and cost-effective
# - Only requires GOOGLE_API_KEY
# - Good for general-purpose testing

# OpenAI:
# - High-quality responses
# - Only requires OPENAI_API_KEY
# - Best for complex scenarios

# Claude:
# - Advanced reasoning capabilities
# - Requires both CLAUDE_API_KEY and OPENAI_API_KEY (for embeddings)
# - Excellent for safety-critical applications

# Llama (Local):
# - Complete privacy, runs locally
# - No API key required
# - Requires Ollama installation and model downloads:
#   curl -fsSL https://ollama.ai/install.sh | sh
#   ollama serve
#   ollama pull llama3.2:3b
#   ollama pull llama3.2:1b
