# Refinireã§ã®ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¨å¯è¦³æ¸¬æ€§

Refinireã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ç›£è¦–ã¨ãƒ‡ãƒãƒƒã‚°ã‚’æ”¯æ´ã™ã‚‹åŒ…æ‹¬çš„ãªãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€çµ„ã¿è¾¼ã¿ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¨é«˜åº¦ãªOpenTelemetryçµ±åˆã®ä¸¡æ–¹ã‚’ã‚«ãƒãƒ¼ã—ã¾ã™ã€‚

## æ¦‚è¦

Refinireã¯2ã¤ã®ãƒ¬ãƒ™ãƒ«ã®ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’æä¾›ã—ã¾ã™ï¼š

1. **çµ„ã¿è¾¼ã¿ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°** - å¸¸ã«åˆ©ç”¨å¯èƒ½ã€è¿½åŠ ã®ä¾å­˜é–¢ä¿‚ä¸è¦
2. **OpenTelemetryãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°** - OTLP ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«ã‚ˆã‚‹é«˜åº¦ãªå¯è¦³æ¸¬æ€§ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ä¾å­˜é–¢ä¿‚ãŒå¿…è¦ï¼‰

## çµ„ã¿è¾¼ã¿ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã€Refinireã¯è‰²åˆ†ã‘ã•ã‚ŒãŸå‡ºåŠ›ã§ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è©³ç´°ãªãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™ï¼š

- **ğŸ”µ ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³** - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç”ŸæˆæŒ‡ç¤ºï¼ˆé’ï¼‰
- **ğŸŸ¢ ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›** - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã¨å…¥åŠ›ï¼ˆç·‘ï¼‰
- **ğŸŸ¡ LLMå‡ºåŠ›** - ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ã¨çµæœï¼ˆé»„ï¼‰
- **ğŸ”´ ã‚¨ãƒ©ãƒ¼** - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨è­¦å‘Šï¼ˆèµ¤ï¼‰

### ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã®ä¾‹

```python
from refinire import RefinireAgent
from refinire.agents.flow import Context

agent = RefinireAgent(
    name="example_agent",
    generation_instructions="ã‚ãªãŸã¯å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
    model="gpt-4o-mini"
)

ctx = Context()
result = await agent.run_async("é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ", ctx)
```

ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼š
```
ğŸ”µ [Instructions] ã‚ãªãŸã¯å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ğŸŸ¢ [User Input] é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ
ğŸŸ¡ [LLM Output] é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¯é©æ–°çš„ãªã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ...
âœ… [Result] æ“ä½œãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ
```

## OpenTelemetryãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

æœ¬ç•ªç’°å¢ƒã‚„é«˜åº¦ãªãƒ‡ãƒãƒƒã‚°ã§ã¯ã€Refinireã¯Grafana Tempoã€Jaegerãªã©ã®å¯è¦³æ¸¬æ€§ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¸ã®OTLPã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’æŒã¤OpenTelemetryã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®OpenInference instrumentationä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼š

```bash
# extrasã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install refinire[openinference-instrumentation]

# ã¾ãŸã¯æ‰‹å‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install openinference-instrumentation openinference-instrumentation-openai opentelemetry-exporter-otlp
```

### åŸºæœ¬çš„ãªOpenTelemetryã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```python
from refinire import (
    RefinireAgent,
    enable_opentelemetry_tracing,
    disable_opentelemetry_tracing
)
from refinire.agents.flow import Context

# OpenTelemetryãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
enable_opentelemetry_tracing(
    service_name="my-agent-app",
    otlp_endpoint="http://localhost:4317",  # Grafana Tempoã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    console_output=True  # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚è¡¨ç¤º
)

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ - è‡ªå‹•çš„ã«ã‚¹ãƒ‘ãƒ³ã¨ã—ã¦ãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚Œã¾ã™
agent = RefinireAgent(
    name="traced_agent",
    generation_instructions="ã‚ãªãŸã¯å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
    model="gpt-4o-mini"
)

# ã™ã¹ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡ŒãŒè‡ªå‹•çš„ã«ã‚¹ãƒ‘ãƒ³ã‚’ä½œæˆ
ctx = Context()
result = await agent.run_async("æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ", ctx)

# ä»¥ä¸‹ã®æƒ…å ±ãŒã‚¹ãƒ‘ãƒ³ã«è‡ªå‹•çš„ã«ã‚­ãƒ£ãƒ—ãƒãƒ£ã•ã‚Œã¾ã™ï¼š
# - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå: "RefinireAgent(traced_agent)"
# - å…¥åŠ›: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª
# - æŒ‡ç¤º: ç”ŸæˆæŒ‡ç¤º
# - å‡ºåŠ›: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”
# - ãƒ¢ãƒ‡ãƒ«: "gpt-4o-mini"
# - æˆåŠŸ/ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹
# - è©•ä¾¡ã‚¹ã‚³ã‚¢ï¼ˆè©•ä¾¡ãŒæœ‰åŠ¹ãªå ´åˆï¼‰

# å®Œäº†æ™‚ã«ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’ç„¡åŠ¹åŒ–
disable_opentelemetry_tracing()
```

### å…¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®ç„¡åŠ¹åŒ–

ã™ã¹ã¦ã®ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ« + OpenTelemetryï¼‰ã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ–ã™ã‚‹ã«ã¯ã€`disable_tracing()`é–¢æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

```python
from refinire import disable_tracing

# å…¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°å‡ºåŠ›ã‚’ç„¡åŠ¹åŒ–
disable_tracing()

# ã“ã‚Œã§å…¨ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡ŒãŒãƒˆãƒ¬ãƒ¼ã‚¹å‡ºåŠ›ãªã—ã§é™å¯‚ã«å‹•ä½œ
agent = RefinireAgent(
    name="silent_agent",
    generation_instructions="ã‚ãªãŸã¯å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
    model="gpt-4o-mini"
)

result = agent.run("ã“ã‚Œã¯é™å¯‚ã«å®Ÿè¡Œã•ã‚Œã¾ã™")
# ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ãªã—ã€OpenTelemetryã‚¹ãƒ‘ãƒ³ã‚‚ä½œæˆã•ã‚Œã¾ã›ã‚“
```

### ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®å†æœ‰åŠ¹åŒ–

ç„¡åŠ¹åŒ–å¾Œã«ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’å†åº¦æœ‰åŠ¹åŒ–ã™ã‚‹å ´åˆï¼š

```python
from refinire import enable_console_tracing, enable_opentelemetry_tracing

# ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®ã¿ã‚’å†æœ‰åŠ¹åŒ–
enable_console_tracing()

# ã¾ãŸã¯OpenTelemetryãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’å†æœ‰åŠ¹åŒ–
enable_opentelemetry_tracing(
    service_name="my-service",
    otlp_endpoint="http://localhost:4317"
)
```

### ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¨­å®š

Refinireã¯`REFINIRE_TRACE_*`å¤‰æ•°ã‚’ä½¿ç”¨ã—ãŸç’°å¢ƒãƒ™ãƒ¼ã‚¹ã®è¨­å®šã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ï¼š

```bash
# ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
export REFINIRE_TRACE_OTLP_ENDPOINT="http://localhost:4317"
export REFINIRE_TRACE_SERVICE_NAME="my-agent-service"
export REFINIRE_TRACE_RESOURCE_ATTRIBUTES="environment=production,team=ai"

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¦ - ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨
enable_opentelemetry_tracing()
```

### è¨­å®šç®¡ç†ã«oneenvã‚’ä½¿ç”¨

Refinireã¯ç°¡å˜ãªç’°å¢ƒç®¡ç†ã®ãŸã‚ã®oneenvãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æä¾›ã—ã¾ã™ï¼š

```bash
# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°è¨­å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆæœŸåŒ–
oneenv init --template refinire.tracing

# ã“ã‚Œã«ã‚ˆã‚Šä»¥ä¸‹ã®å†…å®¹ã®.envãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã™ï¼š
# REFINIRE_TRACE_OTLP_ENDPOINT=
# REFINIRE_TRACE_SERVICE_NAME=refinire-agent
# REFINIRE_TRACE_RESOURCE_ATTRIBUTES=

# è¨­å®šã§.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†
# REFINIRE_TRACE_OTLP_ENDPOINT=http://localhost:4317
# REFINIRE_TRACE_SERVICE_NAME=my-application
# REFINIRE_TRACE_RESOURCE_ATTRIBUTES=environment=production,team=ai
```

Pythonã‚³ãƒ¼ãƒ‰ã§ã¯ï¼š

```python
from oneenv import load_env

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_env()

# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°é–¢æ•°ã‚’ä½¿ç”¨å¯èƒ½
from refinire import enable_opentelemetry_tracing

# ç’°å¢ƒå¤‰æ•°ãŒè‡ªå‹•çš„ã«ä½¿ç”¨ã•ã‚Œã¾ã™
enable_opentelemetry_tracing()
```

## è‡ªå‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

### è‡ªå‹•çš„ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚Œã‚‹å†…å®¹

OpenTelemetryãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€ã™ã¹ã¦ã®RefinireAgentå®Ÿè¡ŒãŒè‡ªå‹•çš„ã«è±Šå¯Œãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŒã¤ã‚¹ãƒ‘ãƒ³ã‚’ä½œæˆã—ã¾ã™ï¼š

```python
from refinire import RefinireAgent, enable_opentelemetry_tracing
from refinire.agents.flow import Context

# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ– - ã“ã‚Œã ã‘ã§ååˆ†ã§ã™ï¼
enable_opentelemetry_tracing(
    service_name="my-app",
    otlp_endpoint="http://localhost:4317"
)

# è©•ä¾¡ä»˜ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
agent = RefinireAgent(
    name="helpful_assistant",
    generation_instructions="ã‚ãªãŸã¯æŠ€è¡“åˆ†é‡ã«ç‰¹åŒ–ã—ãŸå½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
    evaluation_instructions="æ­£ç¢ºæ€§ã¨æœ‰ç”¨æ€§ã«åŸºã¥ã„ã¦å¿œç­”å“è³ªã‚’0-100ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚",
    threshold=75.0,
    model="gpt-4o-mini"
)

# ã“ã®å˜ä¸€ã®å‘¼ã³å‡ºã—ãŒä»¥ä¸‹ã®æƒ…å ±ã‚’å«ã‚€ã‚¹ãƒ‘ãƒ³ã‚’è‡ªå‹•ä½œæˆï¼š
# - ã‚¹ãƒ‘ãƒ³å: "RefinireAgent(helpful_assistant)"
# - å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã€æŒ‡ç¤ºã€å‡ºåŠ›
# - ãƒ¢ãƒ‡ãƒ«åã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
# - æˆåŠŸ/å¤±æ•—çŠ¶æ…‹
# - è©•ä¾¡ã‚¹ã‚³ã‚¢ã¨åˆæ ¼/ä¸åˆæ ¼çŠ¶æ…‹
# - å¤±æ•—ãŒç™ºç”Ÿã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼è©³ç´°
ctx = Context()
result = await agent.run_async("é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„", ctx)
```

### è‡ªå‹•ã‚¹ãƒ‘ãƒ³ã‚«ãƒãƒ¬ãƒƒã‚¸

Refinireã¯ä»¥ä¸‹ã‚’è‡ªå‹•çš„ã«ã‚¹ãƒ‘ãƒ³åŒ–ã—ã¾ã™ï¼š

#### **RefinireAgentã‚¹ãƒ‘ãƒ³**
ã™ã¹ã¦ã®RefinireAgentå®Ÿè¡ŒãŒè©³ç´°ãªã‚¹ãƒ‘ãƒ³ã‚’ä½œæˆï¼š
- **`input`**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã¾ãŸã¯å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
- **`instructions`**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç”ŸæˆæŒ‡ç¤º
- **`output`**: ç”Ÿæˆã•ã‚ŒãŸå¿œç­”
- **`model`**: ä½¿ç”¨ã•ã‚ŒãŸLLMãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹ï¼š"gpt-4o-mini"ï¼‰
- **`success`**: å®Ÿè¡ŒãŒæˆåŠŸã—ãŸã‹ã‚’ç¤ºã™ãƒ–ãƒ¼ãƒ«å€¤
- **`evaluation.score`**: è©•ä¾¡ãŒæœ‰åŠ¹ãªå ´åˆã®è©•ä¾¡ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
- **`evaluation.passed`**: è©•ä¾¡é–¾å€¤ã‚’æº€ãŸã—ãŸã‹ã‚’ç¤ºã™ãƒ–ãƒ¼ãƒ«å€¤
- **`error`**: å®Ÿè¡ŒãŒå¤±æ•—ã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

#### **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—ã‚¹ãƒ‘ãƒ³**
ã™ã¹ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—ãŒè‡ªå‹•çš„ã«ã‚¹ãƒ‘ãƒ³ã‚’ä½œæˆï¼š

**ConditionStepã‚¹ãƒ‘ãƒ³ï¼š**
- **`condition_result`**: æ¡ä»¶è©•ä¾¡ã®ãƒ–ãƒ¼ãƒ«çµæœ
- **`if_true`**: trueåˆ†å²ã®ã‚¹ãƒ†ãƒƒãƒ—å
- **`if_false`**: falseåˆ†å²ã®ã‚¹ãƒ†ãƒƒãƒ—å
- **`next_step`**: å®Ÿéš›ã«å–ã‚‰ã‚ŒãŸæ¬¡ã‚¹ãƒ†ãƒƒãƒ—

**FunctionStepã‚¹ãƒ‘ãƒ³ï¼š**
- **`function_name`**: å®Ÿè¡Œã•ã‚ŒãŸé–¢æ•°å
- **`next_step`**: å®Ÿè¡Œå¾Œã®æ¬¡ã‚¹ãƒ†ãƒƒãƒ—
- **`success`**: å®Ÿè¡ŒæˆåŠŸçŠ¶æ…‹

**ParallelStepã‚¹ãƒ‘ãƒ³ï¼š**
- **`parallel_steps`**: ä¸¦åˆ—ã‚¹ãƒ†ãƒƒãƒ—åã®ãƒªã‚¹ãƒˆ
- **`execution_time_seconds`**: ç·ä¸¦åˆ—å®Ÿè¡Œæ™‚é–“
- **`successful_steps`**: æ­£å¸¸å®Œäº†ã—ãŸã‚¹ãƒ†ãƒƒãƒ—ã®ãƒªã‚¹ãƒˆ
- **`failed_steps`**: å¤±æ•—ã—ãŸä¸¦åˆ—ã‚¹ãƒ†ãƒƒãƒ—æ•°
- **`total_steps`**: ç·ä¸¦åˆ—ã‚¹ãƒ†ãƒƒãƒ—æ•°

**ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¤ãƒ—ã«å«ã¾ã‚Œã‚‹é …ç›®ï¼š**
- **`step.name`**: ã‚¹ãƒ†ãƒƒãƒ—è­˜åˆ¥å­
- **`step.type`**: ã‚¹ãƒ†ãƒƒãƒ—ã‚¯ãƒ©ã‚¹åï¼ˆConditionStepã€FunctionStepãªã©ï¼‰
- **`step.category`**: ã‚¹ãƒ†ãƒƒãƒ—ã‚«ãƒ†ã‚´ãƒªï¼ˆconditionã€functionã€parallelãªã©ï¼‰
- **`current_step`**: ç¾åœ¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä½ç½®
- **`step_count`**: å®Ÿè¡Œã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—æ•°
- **`recent_messages`**: æœ€æ–°3ã¤ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

#### **Flowãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒ‘ãƒ³**
å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒè‡ªå‹•çš„ã«ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚¹ãƒ‘ãƒ³ã‚’ä½œæˆï¼š

**Flowã‚¹ãƒ‘ãƒ³ï¼š**
- **`flow.name`**: ãƒ•ãƒ­ãƒ¼è­˜åˆ¥å
- **`flow.id`**: ä¸€æ„ã®ãƒ•ãƒ­ãƒ¼å®Ÿè¡ŒID
- **`flow.start_step`**: é–‹å§‹ã‚¹ãƒ†ãƒƒãƒ—å
- **`flow.step_count`**: å®šç¾©ã•ã‚ŒãŸç·ã‚¹ãƒ†ãƒƒãƒ—æ•°
- **`flow.step_names`**: ãƒ•ãƒ­ãƒ¼å†…ã®å…¨ã‚¹ãƒ†ãƒƒãƒ—åã®ãƒªã‚¹ãƒˆ
- **`flow_input`**: ãƒ•ãƒ­ãƒ¼ã«æä¾›ã•ã‚ŒãŸå…¥åŠ›ãƒ‡ãƒ¼ã‚¿
- **`flow_completed`**: æ­£å¸¸å®Œäº†ã‚’ç¤ºã™ãƒ–ãƒ¼ãƒ«å€¤
- **`final_step_count`**: å®Ÿéš›ã«å®Ÿè¡Œã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—æ•°
- **`flow_finished`**: ãƒ•ãƒ­ãƒ¼ãŒè‡ªç„¶ãªçµ‚äº†ã«é”ã—ãŸã‹
- **`flow_result`**: ãƒ•ãƒ­ãƒ¼ã‹ã‚‰ã®æœ€çµ‚çµæœï¼ˆ500æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚ï¼‰
- **`flow_error`**: ãƒ•ãƒ­ãƒ¼å®Ÿè¡ŒãŒå¤±æ•—ã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

### é«˜åº¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å ´åˆã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®å‘¨ã‚Šã«ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒ‘ãƒ³ã‚’è¿½åŠ ã§ãã¾ã™ï¼š

```python
from refinire import get_tracer, enable_opentelemetry_tracing
from refinire.agents.flow import Context

# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
enable_opentelemetry_tracing(
    service_name="workflow-app",
    otlp_endpoint="http://localhost:4317"
)

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒ‘ãƒ³ç”¨ã®ãƒˆãƒ¬ãƒ¼ã‚µãƒ¼ã‚’å–å¾—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
tracer = get_tracer("workflow-tracer")

with tracer.start_as_current_span("multi-agent-workflow") as span:
    span.set_attribute("workflow.type", "analysis-pipeline")
    span.set_attribute("user.id", "user123")
    
    # ã“ã‚Œã‚‰ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒ‘ãƒ³å†…ã§è‡ªå‹•çš„ã«ã‚¹ãƒ‘ãƒ³ã‚’ä½œæˆ
    analyzer = RefinireAgent(
        name="content_analyzer",
        generation_instructions="å…¥åŠ›ã‚’åˆ†æã—ã¦åˆ†é¡ã—ã¦ãã ã•ã„ã€‚",
        model="gpt-4o-mini"
    )
    
    expert = RefinireAgent(
        name="domain_expert",
        generation_instructions="å°‚é–€çš„ãªåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
        model="gpt-4o-mini"
    )
    
    ctx = Context()
    
    # ã“ã‚Œã‚‰ã®å‘¼ã³å‡ºã—ã¯ãã‚Œãã‚Œè‡ªå‹•çš„ã«è©³ç´°ãªã‚¹ãƒ‘ãƒ³ã‚’ä½œæˆ
    analysis = await analyzer.run_async("æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„", ctx)
    response = await expert.run_async("æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„", ctx)
    
    span.set_attribute("workflow.status", "completed")
    span.set_attribute("agents.count", 2)
```

### ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒ‘ãƒ³ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ï¼ˆå¾“æ¥ã®æ–¹æ³•ï¼‰

```python
from refinire import get_tracer, enable_opentelemetry_tracing
from refinire.agents.flow import Context

# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
enable_opentelemetry_tracing(
    service_name="workflow-app",
    otlp_endpoint="http://localhost:4317"
)

# ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒ‘ãƒ³ç”¨ã®ãƒˆãƒ¬ãƒ¼ã‚µãƒ¼ã‚’å–å¾—
tracer = get_tracer("workflow-tracer")

with tracer.start_as_current_span("user-workflow") as span:
    span.set_attribute("workflow.type", "question-answering")
    span.set_attribute("user.id", "user123")
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    analyzer = RefinireAgent(
        name="content_analyzer",
        generation_instructions="å…¥åŠ›ã‚’åˆ†æã—ã¦åˆ†é¡ã—ã¦ãã ã•ã„ã€‚",
        model="gpt-4o-mini"
    )
    
    expert = RefinireAgent(
        name="domain_expert",
        generation_instructions="å°‚é–€çš„ãªåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
        model="gpt-4o-mini"
    )
    
    ctx = Context()
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: åˆ†æ
    with tracer.start_as_current_span("content-analysis") as analysis_span:
        analysis = await analyzer.run_async("æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„", ctx)
        analysis_span.set_attribute("analysis.category", str(analysis.result))
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: å°‚é–€å®¶ã®å›ç­”
    with tracer.start_as_current_span("expert-response") as expert_span:
        response = await expert.run_async("æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„", ctx)
        expert_span.set_attribute("response.length", len(str(response.result)))
    
    span.set_attribute("workflow.status", "completed")
```

### ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

```python
# ç•°ãªã‚‹å½¹å‰²ã‚’æŒã¤ç‰¹åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
agents = {
    "analyzer": RefinireAgent(
        name="content_analyzer",
        generation_instructions="å…¥åŠ›ã‚’åˆ†æã—ã¦ã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚",
        model="gpt-4o-mini"
    ),
    "technical": RefinireAgent(
        name="technical_expert",
        generation_instructions="æŠ€è¡“çš„ãªèª¬æ˜ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
        model="gpt-4o-mini"
    ),
    "business": RefinireAgent(
        name="business_expert", 
        generation_instructions="ãƒ“ã‚¸ãƒã‚¹åˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
        model="gpt-4o-mini"
    )
}

tracer = get_tracer("multi-agent-pipeline")

with tracer.start_as_current_span("multi-agent-workflow") as workflow_span:
    user_query = "CI/CDã‚’ã©ã®ã‚ˆã†ã«å®Ÿè£…ã™ã¹ãã§ã™ã‹ï¼Ÿ"
    workflow_span.set_attribute("query", user_query)
    
    ctx = Context()
    
    # åˆ†æã«åŸºã¥ããƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    with tracer.start_as_current_span("routing") as route_span:
        analysis = await agents["analyzer"].run_async(user_query, ctx)
        category = str(analysis.result).lower()
        route_span.set_attribute("route.category", category)
    
    # é©åˆ‡ãªå°‚é–€å®¶ã§å®Ÿè¡Œ
    expert_key = "technical" if "æŠ€è¡“" in category else "business"
    with tracer.start_as_current_span(f"{expert_key}-response") as expert_span:
        result = await agents[expert_key].run_async(user_query, ctx)
        expert_span.set_attribute("expert.type", expert_key)
        expert_span.set_attribute("response.length", len(str(result.result)))
```

## å¯è¦³æ¸¬æ€§ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¨ã®çµ±åˆ

### å®Œå…¨ãªGrafana Tempoã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€Grafana Tempoã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã€Refinireã‹ã‚‰ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’é€ä¿¡ã™ã‚‹æ‰‹é †ã‚’è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚

#### ã‚¹ãƒ†ãƒƒãƒ—1: Grafana Tempoã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³A: ãƒã‚¤ãƒŠãƒªã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**
```bash
# Tempoã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼‰
wget https://github.com/grafana/tempo/releases/download/v2.3.0/tempo_2.3.0_linux_amd64.tar.gz
tar -xzf tempo_2.3.0_linux_amd64.tar.gz
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³B: Dockerã‚’ä½¿ç”¨**
```bash
# Dockerã§Tempoã‚’å®Ÿè¡Œ
docker run -d \
  --name tempo \
  -p 3200:3200 \
  -p 4317:4317 \
  -p 4318:4318 \
  -v $(pwd)/tempo.yaml:/etc/tempo.yaml \
  grafana/tempo:latest \
  -config.file=/etc/tempo.yaml
```

#### ã‚¹ãƒ†ãƒƒãƒ—2: Tempoè¨­å®šã®ä½œæˆ

`tempo.yaml`è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼š

```yaml
# tempo.yaml
server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo/traces

# æ¤œç´¢æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo/traces
    pool:
      max_workers: 100
      queue_depth: 10000
```

#### ã‚¹ãƒ†ãƒƒãƒ—3: Tempoã‚µãƒ¼ãƒãƒ¼ã®é–‹å§‹

```bash
# ãƒã‚¤ãƒŠãƒªã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
./tempo -config.file=tempo.yaml

# TempoãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
curl http://localhost:3200/ready
# æˆ»ã‚Šå€¤: ready
```

#### ã‚¹ãƒ†ãƒƒãƒ—4: ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’é€ä¿¡ã™ã‚‹Refinireã®è¨­å®š

```python
from refinire import (
    RefinireAgent,
    enable_opentelemetry_tracing,
    disable_opentelemetry_tracing
)

# Tempoã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
enable_opentelemetry_tracing(
    service_name="refinire-tempo-demo",
    otlp_endpoint="http://localhost:4317",  # Tempo gRPCã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    console_output=True,  # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¡¨ç¤º
    resource_attributes={
        "environment": "development",
        "service.version": "1.0.0",
        "demo.type": "tempo-integration"
    }
)

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã¦å®Ÿè¡Œ
agent = RefinireAgent(
    name="tempo_agent",
    generation_instructions="ã‚ãªãŸã¯ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
    model="gpt-4o-mini"
)

from refinire.agents.flow import Context
ctx = Context()

# ã“ã‚Œã«ã‚ˆã‚ŠTempoã«é€ä¿¡ã•ã‚Œã‚‹ãƒˆãƒ¬ãƒ¼ã‚¹ãŒç”Ÿæˆã•ã‚Œã¾ã™
result = await agent.run_async("åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®åˆ©ç‚¹ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„", ctx)
print(f"å¿œç­”: {result.result}")

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
disable_opentelemetry_tracing()
```

#### ã‚¹ãƒ†ãƒƒãƒ—5: ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®Grafanaã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

1. **Grafanaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**ï¼š
```bash
# Dockerã‚’ä½¿ç”¨
docker run -d \
  --name grafana \
  -p 3000:3000 \
  grafana/grafana:latest
```

2. **Grafanaã¸ã®ã‚¢ã‚¯ã‚»ã‚¹**ï¼š
   - http://localhost:3000 ã‚’é–‹ã
   - ãƒ­ã‚°ã‚¤ãƒ³: admin/adminï¼ˆåˆå›ãƒ­ã‚°ã‚¤ãƒ³æ™‚ã«ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰æ›´ï¼‰

3. **Tempoãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®è¿½åŠ **ï¼š
   - Configuration â†’ Data Sources ã«ç§»å‹•
   - "Add data source" ã‚’ã‚¯ãƒªãƒƒã‚¯
   - "Tempo" ã‚’é¸æŠ
   - URL: `http://localhost:3200` ã‚’è¨­å®š
   - "Save & Test" ã‚’ã‚¯ãƒªãƒƒã‚¯

4. **ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º**ï¼š
   - Explore ã«ç§»å‹•
   - Tempoãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ
   - TraceQLã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨: `{service.name="refinire-tempo-demo"}`
   - ã¾ãŸã¯ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã§ã‚µãƒ¼ãƒ“ã‚¹åã§æ¤œç´¢

#### ã‚¹ãƒ†ãƒƒãƒ—6: ãƒˆãƒ¬ãƒ¼ã‚¹ãŒé€ä¿¡ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã®ç¢ºèª

Grafana Tempoã®ä¾‹ã‚’å®Ÿè¡Œã—ã¦çµ±åˆã‚’ãƒ†ã‚¹ãƒˆï¼š

```bash
# ä¾‹ã‚’å®Ÿè¡Œ
python examples/grafana_tempo_tracing_example.py
```

æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ï¼š
```
=== Grafana Tempo Tracing Example ===

âœ… OpenTelemetry tracing enabled with Tempo endpoint: http://localhost:4317

--- Running operations (traces sent to Grafana Tempo) ---

ğŸ” Query 1: What are the benefits of using Grafana for observability?
ğŸ“ Response length: 342 characters
ğŸ“Š First 100 chars: Grafana offers several key benefits for observability: 1. **Unified Dashboard**...

âœ… All traces sent to Grafana Tempo at http://localhost:4317
ğŸ”— Check your Grafana Tempo UI to view the traces!
```

#### ã‚¹ãƒ†ãƒƒãƒ—7: Grafanaã§ã®ãƒˆãƒ¬ãƒ¼ã‚¹æ¢ç´¢

1. **ãƒˆãƒ¬ãƒ¼ã‚¹ã®æ¤œç´¢**ï¼š
   - Grafana Exploreã§ã€ã‚µãƒ¼ãƒ“ã‚¹: `refinire-tempo-demo` ã‚’æ¤œç´¢
   - æœ€è¿‘ã®ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆéå»15åˆ†ä»¥å†…ï¼‰ã‚’æ¢ã™
   - ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°ãªã‚¹ãƒ‘ãƒ³æƒ…å ±ã‚’è¡¨ç¤º

2. **è¡¨ç¤ºã•ã‚Œã‚‹ãƒˆãƒ¬ãƒ¼ã‚¹ã®è©³ç´°**ï¼š
   - ã‚µãƒ¼ãƒ“ã‚¹å: `refinire-tempo-demo`
   - æ“ä½œå: OpenAI APIå‘¼ã³å‡ºã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ“ä½œ
   - æœŸé–“ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±
   - ãƒªã‚½ãƒ¼ã‚¹å±æ€§ï¼ˆenvironmentã€demo.type ãªã©ï¼‰
   - å¤±æ•—ãŒç™ºç”Ÿã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼æƒ…å ±

3. **é«˜åº¦ãªã‚¯ã‚¨ãƒª**ï¼š
   ```
   # ã‚¨ãƒ©ãƒ¼ã®ã‚ã‚‹ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æ¤œç´¢
   {service.name="refinire-tempo-demo" && status=error}
   
   # é•·æ™‚é–“å®Ÿè¡Œã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æ¤œç´¢
   {service.name="refinire-tempo-demo" && duration>5s}
   
   # ãƒªã‚½ãƒ¼ã‚¹å±æ€§ã§ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æ¤œç´¢
   {environment="development"}
   ```

#### ã‚¹ãƒ†ãƒƒãƒ—8: é«˜åº¦ãªTempoè¨­å®š

æœ¬ç•ªç’°å¢ƒã§ã¯ã€ä»¥ä¸‹ã®è¿½åŠ è¨­å®šã‚’æ¤œè¨ã—ã¦ãã ã•ã„ï¼š

```yaml
# tempo-production.yaml
server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

# æœ¬ç•ªç’°å¢ƒã§S3ã‚’ä½¿ç”¨
storage:
  trace:
    backend: s3
    s3:
      bucket: tempo-traces
      endpoint: s3.amazonaws.com

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç”Ÿæˆã‚’æœ‰åŠ¹åŒ–
metrics_generator:
  registry:
    external_labels:
      source: tempo
  storage:
    path: /tmp/tempo/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write
```

### Jaegerã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# Jaeger all-in-oneã‚’å®Ÿè¡Œ
docker run -d --name jaeger \
  -p 16686:16686 \
  -p 14250:14250 \
  jaegertracing/all-in-one:latest

# Refinireã‚’è¨­å®š
enable_opentelemetry_tracing(
    service_name="refinire-app",
    otlp_endpoint="http://localhost:14250"
)
```

## ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«

Refinireã¯`examples/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«åŒ…æ‹¬çš„ãªä¾‹ã‚’å«ã‚“ã§ã„ã¾ã™ï¼š

- **`opentelemetry_tracing_example.py`** - åŸºæœ¬çš„ãªOpenTelemetryã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ä½¿ç”¨æ³•
- **`grafana_tempo_tracing_example.py`** - Grafana Tempoçµ±åˆã®ä¾‹
- **`oneenv_tracing_example.py`** - oneenvã§ã®ç’°å¢ƒè¨­å®š

### ä¾‹ã®å®Ÿè¡Œ

```bash
# åŸºæœ¬çš„ãªOpenTelemetryã®ä¾‹
python examples/opentelemetry_tracing_example.py

# Grafana Tempoçµ±åˆ
python examples/grafana_tempo_tracing_example.py

# OneEnvè¨­å®šãƒ‡ãƒ¢
python examples/oneenv_tracing_example.py
```

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. ãƒªã‚½ãƒ¼ã‚¹å±æ€§
å¸¸ã«æ„å‘³ã®ã‚ã‚‹ãƒªã‚½ãƒ¼ã‚¹å±æ€§ã‚’å«ã‚ã‚‹ï¼š

```python
enable_opentelemetry_tracing(
    resource_attributes={
        "environment": "production",
        "service.version": "1.2.3",
        "deployment.environment": "kubernetes",
        "team": "ai-research"
    }
)
```

### 2. ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒ‘ãƒ³
é‡è¦ãªãƒ“ã‚¸ãƒã‚¹æ“ä½œã«ã‚¹ãƒ‘ãƒ³ã‚’ä½œæˆï¼š

```python
with tracer.start_as_current_span("document-processing") as span:
    span.set_attribute("document.type", "pdf")
    span.set_attribute("document.size", file_size)
    # å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã“ã“ã«
    span.set_attribute("processing.status", "completed")
```

### 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
å¸¸ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã§ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼š

```python
try:
    result = await agent.run_async(query, ctx)
    span.set_attribute("operation.success", True)
except Exception as e:
    span.set_attribute("operation.success", False)
    span.set_attribute("error.message", str(e))
    span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))
    raise
```

### 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½è·¡ï¼š

```python
import time

start_time = time.time()
result = await agent.run_async(query, ctx)
duration = time.time() - start_time

span.set_attribute("operation.duration_ms", duration * 1000)
span.set_attribute("tokens.input", len(query.split()))
span.set_attribute("tokens.output", len(str(result.result).split()))
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **ãƒˆãƒ¬ãƒ¼ã‚¹ãŒè¡¨ç¤ºã•ã‚Œãªã„**: OTLPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ¥ç¶šæ€§ã‚’ç¢ºèª
2. **ä¾å­˜é–¢ä¿‚ã®ä¸è¶³**: `refinire[openinference-instrumentation]`ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
3. **ç’°å¢ƒå¤‰æ•°**: `REFINIRE_TRACE_*`å¤‰æ•°ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª

### ãƒ‡ãƒãƒƒã‚°ã®ãƒ’ãƒ³ãƒˆ

1. **é–‹ç™ºæ™‚ã«ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã‚’æœ‰åŠ¹åŒ–**ï¼š
```python
enable_opentelemetry_tracing(console_output=True)
```

2. **ãƒˆãƒ¬ãƒ¼ã‚¹åˆ©ç”¨å¯èƒ½æ€§ã‚’ç¢ºèª**ï¼š
```python
from refinire import is_openinference_available, is_opentelemetry_enabled

print(f"OpenInferenceåˆ©ç”¨å¯èƒ½: {is_openinference_available()}")
print(f"ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°æœ‰åŠ¹: {is_opentelemetry_enabled()}")
```

3. **æ¥ç¶šæ€§ã‚’ãƒ†ã‚¹ãƒˆ**ï¼š
```python
import socket

def test_otlp_connection(host="localhost", port=4317):
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(5)
        result = sock.connect_ex((host, port))
        sock.close()
        return result == 0
    except Exception:
        return False

print(f"OTLPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ°é”å¯èƒ½: {test_otlp_connection()}")
```

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

- Grafana + Tempoã§æœ¬ç•ªå¯è¦³æ¸¬æ€§ã‚¹ã‚¿ãƒƒã‚¯ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¨ä¸¦è¡Œã—ã¦ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å®Ÿè£…
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ç”¨ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆ
- ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã‚¢ãƒ©ãƒ¼ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã‚ˆã‚Šå¤šãã®ä¾‹ã¨é«˜åº¦ãªè¨­å®šã«ã¤ã„ã¦ã¯ã€Refinireãƒªãƒã‚¸ãƒˆãƒªã®`examples/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚