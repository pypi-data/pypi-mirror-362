# Refinire Flow å®Œå…¨ã‚¬ã‚¤ãƒ‰ - åŸºç¤ã‹ã‚‰ä¸Šç´šã¾ã§

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€Refinireã®Flowæ©Ÿèƒ½ã‚’åŸºç¤ã‹ã‚‰ä¸Šç´šã¾ã§ä½“ç³»çš„ã«å­¦ã¹ã¾ã™ã€‚ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ã§é€²ã‚€ã“ã¨ã§ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‹ã‚‰è¤‡é›‘ãªæœ¬ç•ªå¯¾å¿œã®ã‚·ã‚¹ãƒ†ãƒ ã¾ã§æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

## ğŸ“š ç›®æ¬¡

1. [åŸºç¤ç·¨ï¼šFlowã®æ¦‚å¿µã¨åŸºæœ¬æ§‹é€ ](#åŸºç¤ç·¨)
2. [ä¸­ç´šç·¨ï¼šè¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµ±åˆ](#ä¸­ç´šç·¨)
3. [ä¸Šç´šç·¨ï¼šæœ¬ç•ªå¯¾å¿œã®Flowè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³](#ä¸Šç´šç·¨)

---

## åŸºç¤ç·¨ï¼šFlowã®æ¦‚å¿µã¨åŸºæœ¬æ§‹é€ 

### 1.1 Flowã¨ã¯ä½•ã‹ï¼Ÿ

Flowã¯ã€è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‚’é€£é–çš„ã«å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚å¾“æ¥ã®æ‰‹ç¶šãå‹ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ã¯ç•°ãªã‚Šã€**å®£è¨€çš„ãªæ§‹é€ **ã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®šç¾©ã§ãã¾ã™ã€‚

#### å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ vs Flow ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

```python
# å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆLangGraphã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
from langgraph.graph import StateGraph
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
from typing import TypedDict

class WorkflowState(TypedDict):
    user_input: str
    analysis: str
    advice: str
    final_message: str

def analyze_step(state: WorkflowState):
    llm = ChatOpenAI(model="gpt-4o-mini")
    response = llm.invoke([HumanMessage(content=f"åˆ†æã—ã¦ãã ã•ã„: {state['user_input']}")])
    state["analysis"] = response.content
    return state

def advice_step(state: WorkflowState):
    llm = ChatOpenAI(model="gpt-4o-mini")
    response = llm.invoke([
        HumanMessage(content=f"å‰å›ã®åˆ†æ: {state['analysis']}"),
        HumanMessage(content="ã“ã®åˆ†æã«åŸºã¥ã„ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãã ã•ã„")
    ])
    state["advice"] = response.content
    return state

def encourage_step(state: WorkflowState):
    llm = ChatOpenAI(model="gpt-4o-mini")
    response = llm.invoke([
        HumanMessage(content=f"åˆ†æ: {state['analysis']}"),
        HumanMessage(content=f"ã‚¢ãƒ‰ãƒã‚¤ã‚¹: {state['advice']}"),
        HumanMessage(content="ã“ã‚Œã‚‰ã‚’ã¾ã¨ã‚ã¦åŠ±ã¾ã—ã®è¨€è‘‰ã‚’ãã ã•ã„")
    ])
    state["final_message"] = response.content
    return state

# ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰
workflow = StateGraph(WorkflowState)
workflow.add_node("analyze", analyze_step)
workflow.add_node("advice", advice_step)
workflow.add_node("encourage", encourage_step)
workflow.add_edge("analyze", "advice")
workflow.add_edge("advice", "encourage")
workflow.set_entry_point("analyze")
workflow.set_finish_point("encourage")

app = workflow.compile()

def traditional_ai_workflow(user_input):
    result = app.invoke({"user_input": user_input})
    return result["final_message"]

# Refinire Flowã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆå®£è¨€çš„ï¼‰
from refinire import Flow, RefinireAgent

analyzer = RefinireAgent(
    name="analyzer",
    generation_instructions="å…¥åŠ›ã‚’è©³ã—ãåˆ†æã—ã¦ãã ã•ã„",
    model="gpt-4o-mini"
)

advisor = RefinireAgent(
    name="advisor", 
    generation_instructions="åˆ†æçµæœã«åŸºã¥ã„ã¦å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„",
    model="gpt-4o-mini"
)

encourager = RefinireAgent(
    name="encourager",
    generation_instructions="åˆ†æã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¸ã¾ãˆã¦åŠ±ã¾ã—ã®è¨€è‘‰ã‚’ãã ã•ã„",
    model="gpt-4o-mini"
)

flow = Flow({
    "analyze": analyzer,
    "advise": advisor, 
    "encourage": encourager
})

result = await flow.run(user_input)
```

#### Flowã®ä¸»ãªåˆ©ç‚¹

1. **å¯èª­æ€§**: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹é€ ãŒä¸€ç›®ã§ç†è§£ã§ãã‚‹
2. **ä¿å®ˆæ€§**: ã‚¹ãƒ†ãƒƒãƒ—ã®è¿½åŠ ãƒ»å‰Šé™¤ãƒ»å¤‰æ›´ãŒå®¹æ˜“
3. **å†åˆ©ç”¨æ€§**: ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä»–ã®Flowã§å†åˆ©ç”¨å¯èƒ½
4. **ç›£è¦–**: å„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡ŒçŠ¶æ³ã‚’è¿½è·¡å¯èƒ½
5. **ä¸¦åˆ—å‡¦ç†**: ç‹¬ç«‹ã—ãŸã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•çš„ã«ä¸¦åˆ—å®Ÿè¡Œ

### 1.2 åŸºæœ¬çš„ãªFlowã®æ§‹ç¯‰

#### ã‚¹ãƒ†ãƒƒãƒ—1: å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

```python
from refinire import Flow, RefinireAgent
import asyncio
```

#### ã‚¹ãƒ†ãƒƒãƒ—2: æœ€åˆã®Flowã‚’ä½œæˆ - RefinireAgentã®é€£ç¶šå®Ÿè¡Œ

```python
# è¤‡æ•°ã®RefinireAgentã‚’é †æ¬¡å®Ÿè¡Œã™ã‚‹Flow
first_agent = RefinireAgent(
    name="greeter",
    generation_instructions="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¦ªåˆ‡ã«æŒ¨æ‹¶ã—ã¦ãã ã•ã„",
    model="gpt-4o-mini"
)

second_agent = RefinireAgent(
    name="analyzer", 
    generation_instructions="å‰ã®å¿œç­”ã‚’å—ã‘ã¦ã€ãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é©ã—ãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„",
    model="gpt-4o-mini"
)

# åŸºæœ¬çš„ãªFlowã®å®šç¾©
simple_flow = Flow({
    "greet": first_agent,
    "advice": second_agent
})

# Flowã®å®Ÿè¡Œ
async def run_simple_example():
    result = await simple_flow.run("å¤ªéƒ")
    print(f"æœ€çµ‚çµæœ: {result}")

# å®Ÿè¡Œ
asyncio.run(run_simple_example())
```

ã“ã®ä¾‹ã§ã¯ï¼š
1. **first_agent**ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æŒ¨æ‹¶
2. **second_agent**ãŒãã®æŒ¨æ‹¶ã‚’å—ã‘ã¦è¿½åŠ ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›
3. 2ã¤ã®RefinireAgentãŒ**é †æ¬¡å®Ÿè¡Œ**ã•ã‚Œã‚‹

### 1.3 ä¸‰æ®µéšã®RefinireAgenté€£æº

ã‚ˆã‚Šè¤‡é›‘ãªä¾‹ã¨ã—ã¦ã€3ã¤ã®RefinireAgentã‚’é€£æºã•ã›ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python
# ç¬¬ä¸€æ®µéšï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®åˆ†æ
analyzer_agent = RefinireAgent(
    name="analyzer",
    generation_instructions="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå‰ã‹ã‚‰æ€§æ ¼ã‚„ç‰¹å¾´ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚",
    model="gpt-4o-mini"
)

# ç¬¬äºŒæ®µéšï¼šãŠã™ã™ã‚ã®ææ¡ˆ
recommender_agent = RefinireAgent(
    name="recommender",
    generation_instructions="åˆ†æçµæœã«åŸºã¥ã„ã¦ã€ãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãŠã™ã™ã‚ã®æ´»å‹•ã‚„è¶£å‘³ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚",
    model="gpt-4o-mini"
)

# ç¬¬ä¸‰æ®µéšï¼šåŠ±ã¾ã—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
encourager_agent = RefinireAgent(
    name="encourager",
    generation_instructions="ã“ã‚Œã¾ã§ã®åˆ†æã¨ææ¡ˆã‚’è¸ã¾ãˆã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’åŠ±ã¾ã™æ¸©ã‹ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
    model="gpt-4o-mini"
)

# ä¸‰æ®µéšé€£æºFlow
three_step_flow = Flow({
    "analyze": analyzer_agent,
    "recommend": recommender_agent,
    "encourage": encourager_agent
})

async def run_three_step_example():
    result = await three_step_flow.run("ã•ãã‚‰")
    print(f"æœ€çµ‚çš„ãªåŠ±ã¾ã—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {result}")

# å®Ÿè¡Œ
asyncio.run(run_three_step_example())
```

ã“ã®ä¾‹ã§ã¯ï¼š
1. **analyzer_agent**ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼åã‹ã‚‰ç‰¹å¾´ã‚’åˆ†æ
2. **recommender_agent**ãŒåˆ†æçµæœã«åŸºã¥ã„ã¦ãŠã™ã™ã‚ã‚’ææ¡ˆ
3. **encourager_agent**ãŒå…¨ä½“ã‚’è¸ã¾ãˆã¦åŠ±ã¾ã—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ

å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›ãŒæ¬¡ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…¥åŠ›ã¨ãªã‚Šã€**æ®µéšçš„ã«å†…å®¹ãŒæ·±åŒ–**ã—ã¦ã„ãã¾ã™ã€‚

### 1.4 æ¡ä»¶åˆ†å²ã®åŸºæœ¬ - RefinireAgentã«ã‚ˆã‚‹åˆ¤å®š

RefinireAgentã®å‡ºåŠ›ã«åŸºã¥ã„ã¦æ¡ä»¶åˆ†å²ã‚’è¡Œã†ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```python
from refinire import ConditionStep

# åˆ¤å®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼šå…¥åŠ›ã®ç¨®é¡ã‚’åˆ†æ
classifier_agent = RefinireAgent(
    name="classifier",
    generation_instructions="""
    å…¥åŠ›ã‚’åˆ†æã—ã¦ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã§ç­”ãˆã¦ãã ã•ã„ï¼š
    - è³ªå•ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½•ã‹ã‚’è³ªå•ã—ã¦ã„ã‚‹å ´åˆ
    - ç›¸è«‡ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‚©ã¿ã‚„ç›¸è«‡ã‚’ã—ã¦ã„ã‚‹å ´åˆ
    - æŒ¨æ‹¶ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ¨æ‹¶ã‚’ã—ã¦ã„ã‚‹å ´åˆ
    
    å˜èªã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚
    """,
    model="gpt-4o-mini"
)

# è³ªå•ã«ç‰¹åŒ–ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
qa_agent = RefinireAgent(
    name="qa_agent",
    generation_instructions="è³ªå•ã«å¯¾ã—ã¦è©³ã—ãåˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚",
    model="gpt-4o-mini"
)

# ç›¸è«‡ã«ç‰¹åŒ–ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
counseling_agent = RefinireAgent(
    name="counseling_agent", 
    generation_instructions="ç›¸è«‡ã«å¯¾ã—ã¦å…±æ„Ÿçš„ã§å»ºè¨­çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    model="gpt-4o-mini"
)

# æŒ¨æ‹¶ã«ç‰¹åŒ–ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
greeting_agent = RefinireAgent(
    name="greeting_agent",
    generation_instructions="æŒ¨æ‹¶ã«å¯¾ã—ã¦è¦ªã—ã¿ã‚„ã™ãæ¸©ã‹ã„æŒ¨æ‹¶ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚",
    model="gpt-4o-mini"
)

# åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
def route_by_type(ctx):
    """åˆ†é¡çµæœã«åŸºã¥ã„ã¦ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"""
    classification = str(ctx.result).strip().lower()
    if "è³ªå•" in classification:
        return "qa"
    elif "ç›¸è«‡" in classification:
        return "counseling"
    else:
        return "greeting"

# æ¡ä»¶åˆ†å²Flow
branching_flow = Flow({
    "classify": classifier_agent,
    "route": ConditionStep("route", route_by_type, 
                          {"qa": "qa", "counseling": "counseling", "greeting": "greeting"}),
    "qa": qa_agent,
    "counseling": counseling_agent,
    "greeting": greeting_agent
})

async def run_branching_example():
    # è³ªå•ã®å ´åˆ
    result1 = await branching_flow.run("Pythonã§ãƒªã‚¹ãƒˆã‚’ä½œã‚‹æ–¹æ³•ã‚’æ•™ãˆã¦")
    print(f"è³ªå•ã®çµæœ: {result1}")
    
    # ç›¸è«‡ã®å ´åˆ  
    result2 = await branching_flow.run("ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å‹‰å¼·ãŒé›£ã—ãã¦æ‚©ã‚“ã§ã„ã¾ã™")
    print(f"ç›¸è«‡ã®çµæœ: {result2}")
    
    # æŒ¨æ‹¶ã®å ´åˆ
    result3 = await branching_flow.run("ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™")
    print(f"æŒ¨æ‹¶ã®çµæœ: {result3}")

# å®Ÿè¡Œ
asyncio.run(run_branching_example())
```

ã“ã®ä¾‹ã§ã¯ï¼š
1. **classifier_agent**ãŒå…¥åŠ›ã®ç¨®é¡ã‚’åˆ¤å®š
2. **ConditionStep**ãŒåˆ¤å®šçµæœã«åŸºã¥ã„ã¦ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
3. ç¨®é¡ã«å¿œã˜ãŸ**å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**ãŒå¿œç­”

RefinireAgentã®å‡ºåŠ›ã‚’æ¡ä»¶åˆ†å²ã«æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€**ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

### 1.5 åŸºç¤ç·¨ã¾ã¨ã‚ã¨ç·´ç¿’èª²é¡Œ

#### åŸºç¤ç·¨ã§å­¦ã‚“ã ã“ã¨
- Flowã®åŸºæœ¬æ¦‚å¿µã¨å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã®é•ã„
- RefinireAgentã®é€£ç¶šå®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³
- ConditionStepã‚’ä½¿ã£ãŸæ¡ä»¶åˆ†å²
- RefinireAgentã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### ç·´ç¿’èª²é¡Œ: æ„Ÿæƒ…åˆ†æã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹Flow

```python
# èª²é¡Œ: ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™Flowã‚’ä½œæˆã—ã¦ãã ã•ã„
# 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
# 2. æ„Ÿæƒ…ã«åŸºã¥ã„ã¦é©åˆ‡ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
# 3. ãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–ã§ç•°ãªã‚‹å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æŒ¯ã‚Šåˆ†ã‘

# è§£ç­”ä¾‹ï¼š
emotion_analyzer = RefinireAgent(
    name="emotion_analyzer",
    generation_instructions="""
    å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã—ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã§ç­”ãˆã¦ãã ã•ã„ï¼š
    - ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼šå‰å‘ãã§æ˜ã‚‹ã„æ„Ÿæƒ…ã®å ´åˆ
    - ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼šè½ã¡è¾¼ã‚“ã§ã„ãŸã‚Šä¸å®‰ãªæ„Ÿæƒ…ã®å ´åˆ
    
    å˜èªã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚
    """,
    model="gpt-4o-mini"
)

positive_advisor = RefinireAgent(
    name="positive_advisor",
    generation_instructions="ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ°—æŒã¡ã‚’ã•ã‚‰ã«é«˜ã‚ã‚‹ã‚ˆã†ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    model="gpt-4o-mini"
)

negative_advisor = RefinireAgent(
    name="negative_advisor",
    generation_instructions="ãƒã‚¬ãƒ†ã‚£ãƒ–ãªæ°—æŒã¡ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®å„ªã—ã„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    model="gpt-4o-mini"
)

def emotion_router(ctx):
    """æ„Ÿæƒ…ã«åŸºã¥ããƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"""
    emotion = str(ctx.result).strip().lower()
    return "positive" if "ãƒã‚¸ãƒ†ã‚£ãƒ–" in emotion else "negative"

# ç·´ç¿’ç”¨Flow
emotion_flow = Flow({
    "analyze": emotion_analyzer,
    "route": ConditionStep("route", emotion_router, "positive", "negative"),
    "positive": positive_advisor,
    "negative": negative_advisor
})

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
async def test_emotion_flow():
    result1 = await emotion_flow.run("ä»Šæ—¥ã¯ã¨ã¦ã‚‚è‰¯ã„æ—¥ã§ã—ãŸï¼")
    print(f"ãƒã‚¸ãƒ†ã‚£ãƒ–ãªå…¥åŠ›: {result1}")
    
    result2 = await emotion_flow.run("æœ€è¿‘ã†ã¾ãã„ã‹ãªã„ã“ã¨ã°ã‹ã‚Šã§è½ã¡è¾¼ã‚“ã§ã„ã¾ã™")
    print(f"ãƒã‚¬ãƒ†ã‚£ãƒ–ãªå…¥åŠ›: {result2}")
```

ã“ã®èª²é¡Œã§ã¯ã€**RefinireAgentã®é€£æº**ã¨**æ¡ä»¶åˆ†å²**ã‚’çµ„ã¿åˆã‚ã›ã¦ã€æ„Ÿæƒ…ã«å¿œã˜ãŸãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

### 1.6 show()ã‚’ä½¿ã£ãŸFlowå¯è¦–åŒ–

è¤‡é›‘ãªFlowã‚’ç†è§£ã—ã€ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ãŸã‚ã«ã¯ã€Flowæ§‹é€ ã‚’å¯è¦–åŒ–ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚Refinireã®`show()`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã¨ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«å½¢å¼ã®ä¸¡æ–¹ã§Flowã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚

#### åŸºæœ¬çš„ãªFlowå¯è¦–åŒ–

```python
from refinire import Flow, FunctionStep, ConditionStep

def analyze_input(ctx):
    return f"åˆ†ææ¸ˆã¿: {ctx.result}"

def is_complex(ctx):
    return len(str(ctx.result)) > 10

# ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®Flowã‚’ä½œæˆ
demo_flow = Flow(start="analyze", steps={
    "analyze": FunctionStep("analyze", analyze_input, next_step="check"),
    "check": ConditionStep("check", is_complex, "complex_process", "simple_process"),
    "complex_process": FunctionStep("complex_process", lambda ctx: "è¤‡é›‘ãªå‡¦ç†å®Œäº†"),
    "simple_process": FunctionStep("simple_process", lambda ctx: "ç°¡å˜ãªå‡¦ç†å®Œäº†")
})

# ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§Flowæ§‹é€ ã‚’è¡¨ç¤º
print("=== Flowæ§‹é€ ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼‰ ===")
print(demo_flow.show(format="text"))

# Mermaidå½¢å¼ã§Flowæ§‹é€ ã‚’è¡¨ç¤º
print("\n=== Flowæ§‹é€ ï¼ˆMermaidå½¢å¼ï¼‰ ===")
print(demo_flow.show(format="mermaid"))
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:**

```
=== Flowæ§‹é€ ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼‰ ===
Flow Diagram:
==================================================
â†’ analyze (FunctionStep)
  â†’ check (ConditionStep)
    True â†’ complex_process
    False â†’ simple_process
    â†’ complex_process (FunctionStep)
    â†’ simple_process (FunctionStep)

=== Flowæ§‹é€ ï¼ˆMermaidå½¢å¼ï¼‰ ===
graph TD
    analyze["analyze<br/>(FunctionStep)"]:::start
    analyze --> check
    check["check<br/>(ConditionStep)"]:::condition
    check -->|"True"| complex_process
    check -->|"False"| simple_process
    complex_process["complex_process<br/>(FunctionStep)"]
    simple_process["simple_process<br/>(FunctionStep)"]
```

#### å¯è¦–åŒ–å½¢å¼ã®é•ã„

**ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼** (`format="text"`):
- ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ã®ãƒ‡ãƒãƒƒã‚°ã¨è¿…é€Ÿãªç¢ºèªã«æœ€é©
- ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã«ã‚ˆã‚‹éšå±¤æ§‹é€ ã®è¡¨ç¤º
- ã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¤ãƒ—ã¨ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æƒ…å ±ã‚’è¡¨ç¤º
- é–‹ç™ºã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã«ç†æƒ³çš„

**Mermaidå½¢å¼** (`format="mermaid"`):
- Mermaid.jsãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
- GitHubã€GitLabã€Notionã€ãã®ä»–ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¯èƒ½
- ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæ–‡æ›¸ä½œæˆã¨ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆå¯èƒ½

#### ç•°ãªã‚‹Flowã‚¿ã‚¤ãƒ—ã®å¯è¦–åŒ–

```python
# 1. ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«Flowã®å¯è¦–åŒ–
sequential_flow = Flow(steps=[
    FunctionStep("step1", lambda ctx: "ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†"),
    FunctionStep("step2", lambda ctx: "ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†"),
    FunctionStep("step3", lambda ctx: "ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†")
])

print("ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«Flow:")
print(sequential_flow.show(format="text"))

# 2. å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—Flowã®å¯è¦–åŒ–
from refinire import RefinireAgent

single_flow = Flow(steps=RefinireAgent(
    name="assistant",
    generation_instructions="ã‚ãªãŸã¯å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™",
    model="gpt-4o-mini"
))

print("\nå˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—Flow:")
print(single_flow.show(format="text"))

# 3. ä¸¦åˆ—å‡¦ç†Flowã®å¯è¦–åŒ–
parallel_flow = Flow(start="input", steps={
    "input": FunctionStep("input", lambda ctx: ctx.result, next_step="parallel"),
    "parallel": {
        "parallel": [
            RefinireAgent(name="agent1", generation_instructions="è¦–ç‚¹Aã‹ã‚‰åˆ†æ", model="gpt-4o-mini"),
            RefinireAgent(name="agent2", generation_instructions="è¦–ç‚¹Bã‹ã‚‰åˆ†æ", model="gpt-4o-mini")
        ],
        "next_step": "combine",
        "max_workers": 2
    },
    "combine": FunctionStep("combine", lambda ctx: "çµæœçµ±åˆå®Œäº†")
})

print("\nä¸¦åˆ—å‡¦ç†Flow:")
print(parallel_flow.show(format="mermaid"))
```

#### å®Ÿè¡Œå±¥æ­´ä»˜ãå¯è¦–åŒ–

Flowã‚’å®Ÿè¡Œã—ãŸå¾Œã€å®Ÿéš›ã®å®Ÿè¡Œãƒ‘ã‚¹ã‚’å¯è¦–åŒ–ã§ãã¾ã™ï¼š

```python
# æœ€åˆã«Flowã‚’å®Ÿè¡Œ
result = await demo_flow.run("Flowã®ãƒ†ã‚¹ãƒˆå…¥åŠ›")

# å®Ÿè¡Œå±¥æ­´ä»˜ãã§Flowã‚’è¡¨ç¤º
print("=== å®Ÿè¡Œå±¥æ­´ä»˜ãFlow ===")
print(demo_flow.show(format="text", include_history=True))

# å®Ÿè¡Œãƒ‘ã‚¹ãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãMermaidå½¢å¼
print("\n=== å®Ÿè¡Œãƒ‘ã‚¹ä»˜ãMermaid ===")
print(demo_flow.show(format="mermaid", include_history=True))
```

å®Ÿè¡Œå±¥æ­´ã§ã¯ä»¥ä¸‹ãŒãƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚Œã¾ã™ï¼š
- å®Ÿéš›ã«å®Ÿè¡Œã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—
- å®Ÿè¡Œé †åº
- å„ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
- Mermaidå›³ã§ã®è¦–è¦šçš„ãƒ‘ã‚¹ãƒã‚¤ãƒ©ã‚¤ãƒˆ

#### Flowå¯è¦–åŒ–ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

1. **é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚º**:
   - `format="text"`ã‚’ä½¿ç”¨ã—ã¦è¿…é€Ÿãªã‚³ãƒ³ã‚½ãƒ¼ãƒ«ç¢ºèª
   - å®Ÿè£…å‰ã«Flowæ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯
   - æ¡ä»¶åˆ†å²ã¨ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’æ¤œè¨¼

2. **æ–‡æ›¸åŒ–ãƒ•ã‚§ãƒ¼ã‚º**:
   - `format="mermaid"`ã‚’æ–‡æ›¸åŒ–ã«ä½¿ç”¨
   - README ãƒ•ã‚¡ã‚¤ãƒ«ã¨æŠ€è¡“ä»•æ§˜æ›¸ã«å«ã‚ã‚‹
   - ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã¨ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§å…±æœ‰

3. **ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚§ãƒ¼ã‚º**:
   - å®Ÿè¡Œå¾Œã«`include_history=True`ã‚’ä½¿ç”¨
   - ã©ã®ãƒ‘ã‚¹ãŒå–ã‚‰ã‚Œã‚‹ã‹ã‚’ç‰¹å®š
   - äºˆæœŸã—ãªã„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å‹•ä½œã‚’ãƒ‡ãƒãƒƒã‚°

4. **æœ¬ç•ªç›£è¦–**:
   - é‹ç”¨æ–‡æ›¸ç”¨ã«Flowå›³ã‚’ç”Ÿæˆ
   - å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’è¿½è·¡
   - è¤‡é›‘ãªãƒ“ã‚¸ãƒã‚¹ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¯è¦–åŒ–

#### å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¨ã®çµ±åˆ

**Mermaid Live Editor**: Mermaidå‡ºåŠ›ã‚’ [https://mermaid.live/](https://mermaid.live/) ã«ã‚³ãƒ”ãƒ¼ã—ã¦ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªç·¨é›†ã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãŒå¯èƒ½ã§ã™ã€‚

**GitHub/GitLab**: Mermaidå›³ã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã§è‡ªå‹•çš„ã«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã•ã‚Œã¾ã™ï¼š

````markdown
```mermaid
graph TD
    analyze["analyze<br/>(FunctionStep)"]:::start
    analyze --> check
    check["check<br/>(ConditionStep)"]:::condition
    check -->|"True"| complex_process
    check -->|"False"| simple_process
```
````

**æ–‡æ›¸ä½œæˆãƒ„ãƒ¼ãƒ«**: ã»ã¨ã‚“ã©ã®ç¾ä»£çš„ãªæ–‡æ›¸ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§Mermaidãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼ˆNotionã€Obsidianã€GitBook ãªã©ï¼‰ã€‚

---

## ä¸­ç´šç·¨ï¼šè¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµ±åˆ

### 2.1 RefinireAgentã¨Flowã®çµ±åˆ

RefinireAgentã¯ã€LLMã‚’æ´»ç”¨ã—ãŸã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦Flowã«çµ„ã¿è¾¼ã‚ã¾ã™ã€‚

#### åŸºæœ¬çš„ãªRefinireAgentçµ±åˆ

```python
from refinire import RefinireAgent

# ã‚·ãƒ³ãƒ—ãƒ«ãªRefinireAgent
simple_agent = RefinireAgent(
    name="assistant",
    generation_instructions="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«è¦ªåˆ‡ã«ç­”ãˆã¦ãã ã•ã„",
    model="gpt-4o-mini"
)

# Agentã‚’Flowã«çµ±åˆ
agent_flow = Flow({
    "preprocess": FunctionStep("preprocess", lambda data, ctx: f"è³ªå•: {data}"),
    "ai_response": simple_agent,
    "postprocess": FunctionStep("postprocess", lambda data, ctx: f"å›ç­”: {data}")
})

async def run_agent_example():
    result = await agent_flow.run("Pythonã®ç‰¹å¾´ã‚’æ•™ãˆã¦")
    print(result)
```

#### è©•ä¾¡æ©Ÿèƒ½ä»˜ãRefinireAgent

```python
# è©•ä¾¡æ©Ÿèƒ½ä»˜ãAgent
quality_agent = RefinireAgent(
    name="quality_assistant",
    generation_instructions="é«˜å“è³ªã§è©³ç´°ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„",
    evaluation_instructions="å›ç­”ã®å“è³ªã‚’0-100ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚ç¶²ç¾…æ€§ã€æ­£ç¢ºæ€§ã€æ˜ç¢ºæ€§ã‚’é‡è¦–ã—ã¦ãã ã•ã„",
    threshold=80.0,
    max_retries=2,
    model="gpt-4o-mini"
)

def check_quality_score(ctx):
    """å“è³ªã‚¹ã‚³ã‚¢ã«åŸºã¥ãåˆ†å²"""
    if hasattr(ctx, 'evaluation_result') and ctx.evaluation_result:
        return ctx.evaluation_result.get('score', 0) >= 85
    return False

def high_quality_response(data, ctx):
    """é«˜å“è³ªãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†"""
    score = ctx.evaluation_result.get('score', 0)
    return f"é«˜å“è³ªãªå›ç­”ã§ã™ï¼ˆã‚¹ã‚³ã‚¢: {score}ï¼‰\nå›ç­”: {data}"

def standard_response(data, ctx):
    """æ¨™æº–ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†"""
    score = ctx.evaluation_result.get('score', 0) if ctx.evaluation_result else 0
    return f"æ¨™æº–çš„ãªå›ç­”ã§ã™ï¼ˆã‚¹ã‚³ã‚¢: {score}ï¼‰\nå›ç­”: {data}"

# å“è³ªãƒã‚§ãƒƒã‚¯ä»˜ãFlow
quality_flow = Flow({
    "generate": quality_agent,
    "quality_check": ConditionStep("quality_check", check_quality_score, "high_quality", "standard"),
    "high_quality": FunctionStep("high_quality", high_quality_response),
    "standard": FunctionStep("standard", standard_response)
})
```

### 2.2 ä¸¦åˆ—å‡¦ç†ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

ç‹¬ç«‹ã—ãŸã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€å¤§å¹…ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å®Ÿç¾ã§ãã¾ã™ã€‚

#### åŸºæœ¬çš„ãªä¸¦åˆ—å‡¦ç†

```python
def analyze_sentiment(data, ctx):
    """æ„Ÿæƒ…åˆ†æï¼ˆæ¨¡æ“¬ï¼‰"""
    import time
    time.sleep(1)  # å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    return f"æ„Ÿæƒ…: ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼ˆå…¥åŠ›: {data[:20]}...ï¼‰"

def extract_keywords(data, ctx):
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆæ¨¡æ“¬ï¼‰"""
    import time
    time.sleep(1)  # å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    return f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: Python, AI, æ©Ÿæ¢°å­¦ç¿’ï¼ˆå…¥åŠ›: {data[:20]}...ï¼‰"

def classify_category(data, ctx):
    """ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆæ¨¡æ“¬ï¼‰"""
    import time
    time.sleep(1)  # å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    return f"ã‚«ãƒ†ã‚´ãƒª: æŠ€è¡“ï¼ˆå…¥åŠ›: {data[:20]}...ï¼‰"

def combine_analysis_results(data, ctx):
    """åˆ†æçµæœã‚’çµ±åˆ"""
    # ä¸¦åˆ—å®Ÿè¡Œã®çµæœã¯ctx.shared_stateã«æ ¼ç´ã•ã‚Œã‚‹
    return {
        "çµ±åˆçµæœ": "è¤‡æ•°ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ",
        "å®Ÿè¡Œæ™‚é–“": "ç´„1ç§’ï¼ˆä¸¦åˆ—å®Ÿè¡Œï¼‰"
    }

# ä¸¦åˆ—å‡¦ç†Flow
parallel_flow = Flow(start="preprocess", steps={
    "preprocess": FunctionStep("preprocess", lambda data, ctx: data),
    "parallel_analysis": {
        "parallel": [
            FunctionStep("sentiment", analyze_sentiment),
            FunctionStep("keywords", extract_keywords),
            FunctionStep("category", classify_category)
        ],
        "next_step": "combine",
        "max_workers": 3
    },
    "combine": FunctionStep("combine", combine_analysis_results)
})

async def run_parallel_example():
    import time
    start_time = time.time()
    
    result = await parallel_flow.run("Pythonã¯æ©Ÿæ¢°å­¦ç¿’ã‚„AIé–‹ç™ºã«é©ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™")
    
    end_time = time.time()
    print(f"å®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
    print(f"çµæœ: {result}")
```

### 2.3 RouterAgentã®çµ±åˆ

RouterAgentã¯ã€å…¥åŠ›ã‚’åˆ†æã—ã¦é©åˆ‡ãªãƒ«ãƒ¼ãƒˆã«æŒ¯ã‚Šåˆ†ã‘ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

```python
from refinire import RouterAgent

# RouterAgentã®è¨­å®š
router_config = {
    "name": "content_router",
    "routes": {
        "technical": "tech_specialist",
        "business": "business_specialist",
        "general": "general_assistant"
    },
    "classifier_type": "llm",
    "generation_instructions": """
    ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã®ã„ãšã‚Œã‹ã«åˆ†é¡ã—ã¦ãã ã•ã„ï¼š
    - technical: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€æŠ€è¡“ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–¢é€£
    - business: ãƒ“ã‚¸ãƒã‚¹ã€çµŒå–¶ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°é–¢é€£  
    - general: ãã®ä»–ã®ä¸€èˆ¬çš„ãªè³ªå•
    
    ã‚«ãƒ†ã‚´ãƒªåã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
    """
}

router = RouterAgent(router_config)

# å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®šç¾©
tech_specialist = RefinireAgent(
    name="tech_specialist",
    generation_instructions="æŠ€è¡“çš„ãªå°‚é–€çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦è©³ç´°ã«å›ç­”ã—ã¦ãã ã•ã„",
    model="gpt-4o-mini"
)

business_specialist = RefinireAgent(
    name="business_specialist", 
    generation_instructions="ãƒ“ã‚¸ãƒã‚¹ã®è¦³ç‚¹ã‹ã‚‰å®Ÿè·µçš„ã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¦ãã ã•ã„",
    model="gpt-4o-mini"
)

general_assistant = RefinireAgent(
    name="general_assistant",
    generation_instructions="åˆ†ã‹ã‚Šã‚„ã™ãä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„",
    model="gpt-4o-mini"
)

# RouterAgentçµ±åˆFlow
router_flow = Flow({
    "preprocess": FunctionStep("preprocess", lambda data, ctx: data),
    "route": router,
    "tech_specialist": tech_specialist,
    "business_specialist": business_specialist,
    "general_assistant": general_assistant,
    "postprocess": FunctionStep("postprocess", lambda data, ctx: f"å°‚é–€å›ç­”: {data}")
})

async def run_router_example():
    # æŠ€è¡“çš„ãªè³ªå•
    tech_result = await router_flow.run("Pythonã§ã®ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰å‡¦ç†ã«ã¤ã„ã¦æ•™ãˆã¦")
    print(f"æŠ€è¡“è³ªå•ã®çµæœ: {tech_result}")
    
    # ãƒ“ã‚¸ãƒã‚¹è³ªå•
    business_result = await router_flow.run("æ–°è¦äº‹æ¥­ã®ç«‹ã¡ä¸Šã’æ–¹æ³•ã«ã¤ã„ã¦æ•™ãˆã¦")
    print(f"ãƒ“ã‚¸ãƒã‚¹è³ªå•ã®çµæœ: {business_result}")
```

### 2.4 ClarifyAgentã®çµ±åˆ

ClarifyAgentã¯ã€æ›–æ˜§ãªè¦æ±‚ã‚’æ˜ç¢ºåŒ–ã™ã‚‹ãŸã‚ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

```python
from refinire import ClarifyAgent

# ClarifyAgentã®è¨­å®š
clarify_agent = ClarifyAgent(
    name="requirement_clarifier",
    generation_instructions="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’æ˜ç¢ºåŒ–ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„",
    clarification_instructions="è¦æ±‚ãŒååˆ†ã«æ˜ç¢ºã‹ã©ã†ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„",
    threshold=80.0,
    model="gpt-4o-mini"
)

def is_clarification_needed(ctx):
    """æ˜ç¢ºåŒ–ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    # ClarifyAgentã®çµæœã‚’ç¢ºèª
    if hasattr(ctx, 'clarification_result'):
        return not ctx.clarification_result.get('is_clear', False)
    return False

def process_clear_request(data, ctx):
    """æ˜ç¢ºãªè¦æ±‚ã®å‡¦ç†"""
    return f"è¦æ±‚ãŒæ˜ç¢ºã§ã™ã€‚å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™: {data}"

def request_clarification(data, ctx):
    """æ˜ç¢ºåŒ–ã®è¦æ±‚"""
    clarification = ctx.clarification_result.get('clarification_question', '')
    return f"è©³ç´°ã‚’æ•™ãˆã¦ãã ã•ã„: {clarification}"

# ClarifyAgentçµ±åˆFlow
clarify_flow = Flow({
    "clarify": clarify_agent,
    "check_clarity": ConditionStep("check_clarity", is_clarification_needed, "request_more", "process"),
    "request_more": FunctionStep("request_more", request_clarification),
    "process": FunctionStep("process", process_clear_request)
})

async def run_clarify_example():
    # æ›–æ˜§ãªè¦æ±‚
    vague_result = await clarify_flow.run("ä½•ã‹ã„ã„æ„Ÿã˜ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã£ã¦")
    print(f"æ›–æ˜§ãªè¦æ±‚ã®çµæœ: {vague_result}")
    
    # æ˜ç¢ºãªè¦æ±‚
    clear_result = await clarify_flow.run("Pythonã§é¡§å®¢ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æ©Ÿèƒ½ã¨ã—ã¦é¡§å®¢æƒ…å ±ã®ç™»éŒ²ã€æ¤œç´¢ã€æ›´æ–°ã€å‰Šé™¤ãŒå¿…è¦ã§ã™")
    print(f"æ˜ç¢ºãªè¦æ±‚ã®çµæœ: {clear_result}")
```

### 2.5 ä¸­ç´šç·¨ã¾ã¨ã‚ã¨å®Ÿè·µèª²é¡Œ

#### ä¸­ç´šç·¨ã§å­¦ã‚“ã ã“ã¨
- RefinireAgentã®æ§˜ã€…ãªçµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³
- è©•ä¾¡æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸå“è³ªç®¡ç†
- ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- RouterAgentã¨ClarifyAgentã®æ´»ç”¨

#### å®Ÿè·µèª²é¡Œï¼šå¤šæ©Ÿèƒ½ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 

```python
# èª²é¡Œ: ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æŒã¤ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆFlowã‚’ä½œæˆã—ã¦ãã ã•ã„
# 1. å•ã„åˆã‚ã›å†…å®¹ã®åˆ†é¡ï¼ˆæŠ€è¡“çš„/ä¸€èˆ¬çš„/ç·Šæ€¥ï¼‰
# 2. ç·Šæ€¥ã®å ´åˆã¯å³åº§ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
# 3. æŠ€è¡“çš„ãªå•ã„åˆã‚ã›ã¯è©³ç´°ç¢ºèªå¾Œã«å°‚é–€å¯¾å¿œ
# 4. ä¸€èˆ¬çš„ãªå•ã„åˆã‚ã›ã¯ç›´æ¥å›ç­”
# 5. ã™ã¹ã¦ã®å¯¾å¿œã‚’ä¸¦åˆ—ã§è¨˜éŒ²ã¨ãƒ¡ãƒ¼ãƒ«é€ä¿¡

def classify_inquiry(ctx):
    """å•ã„åˆã‚ã›ã‚’åˆ†é¡"""
    content = ctx.result.lower()
    if any(word in content for word in ["ç·Šæ€¥", "ã‚¨ãƒ©ãƒ¼", "åœæ­¢", "éšœå®³"]):
        ctx.shared_state["category"] = "urgent"
        return "urgent"
    elif any(word in content for word in ["æŠ€è¡“", "å®Ÿè£…", "ã‚³ãƒ¼ãƒ‰", "api"]):
        ctx.shared_state["category"] = "technical"
        return "technical"
    else:
        ctx.shared_state["category"] = "general"
        return "general"

# å®Ÿè£…ä¾‹ï¼ˆä¸€éƒ¨ï¼‰
support_flow = Flow({
    "classify": FunctionStep("classify", lambda data, ctx: classify_inquiry(ctx)),
    "route": ConditionStep("route", 
                          lambda ctx: ctx.shared_state.get("category"),
                          {"urgent": "escalate", "technical": "clarify", "general": "respond"}),
    # ... ç¶šãã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
})
```

---

## ä¸Šç´šç·¨ï¼šæœ¬ç•ªå¯¾å¿œã®Flowè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³

### 3.1 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å›å¾©åŠ›ã®ã‚ã‚‹Flow

æœ¬ç•ªç’°å¢ƒã§ã¯ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãŒé‡è¦ã§ã™ã€‚

#### å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
from refinire import FlowExecutionError
import logging

logger = logging.getLogger(__name__)

def safe_external_api_call(data, ctx):
    """å¤–éƒ¨APIå‘¼ã³å‡ºã—ï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ï¼‰"""
    import random
    
    # 30%ã®ç¢ºç‡ã§ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    if random.random() < 0.3:
        raise Exception("å¤–éƒ¨APIã‚¨ãƒ©ãƒ¼: æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
    
    return f"APIå¿œç­”: {data}ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"

def fallback_local_processing(data, ctx):
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
    logger.warning("å¤–éƒ¨APIãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
    return f"ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†: {data}ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å‡¦ç†ã—ã¾ã—ãŸï¼ˆæ©Ÿèƒ½åˆ¶é™ã‚ã‚Šï¼‰"

def error_handler(error, ctx):
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    logger.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error}")
    ctx.shared_state["error_occurred"] = True
    ctx.shared_state["error_message"] = str(error)
    return "error_fallback"

def has_error(ctx):
    """ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‹ãƒã‚§ãƒƒã‚¯"""
    return ctx.shared_state.get("error_occurred", False)

def success_response(data, ctx):
    """æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    return f"âœ… æ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸ: {data}"

def error_response(data, ctx):
    """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    error_msg = ctx.shared_state.get("error_message", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
    return f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒä»£æ›¿å‡¦ç†ã§å¯¾å¿œã—ã¾ã—ãŸ: {data}\nã‚¨ãƒ©ãƒ¼è©³ç´°: {error_msg}"

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œFlow
resilient_flow = Flow({
    "try_external": FunctionStep("try_external", safe_external_api_call),
    "error_check": ConditionStep("error_check", has_error, "error_response", "success_response"),
    "error_fallback": FunctionStep("fallback", fallback_local_processing),
    "success_response": FunctionStep("success", success_response),
    "error_response": FunctionStep("error", error_response)
})

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
resilient_flow.set_error_handler(error_handler)

async def run_resilient_example():
    for i in range(5):
        try:
            result = await resilient_flow.run(f"ãƒ‡ãƒ¼ã‚¿{i}")
            print(f"è©¦è¡Œ {i+1}: {result}")
        except FlowExecutionError as e:
            print(f"è©¦è¡Œ {i+1}: Flowå®Ÿè¡Œã‚¨ãƒ©ãƒ¼ - {e}")
```

### 3.2 å‹•çš„Flowç”Ÿæˆã¨ãƒ¡ã‚¿ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°

å®Ÿè¡Œæ™‚ã«Flowã‚’å‹•çš„ã«ç”Ÿæˆã™ã‚‹é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚

```python
def create_multi_agent_analysis_flow(agents_config, analysis_type="comprehensive"):
    """å‹•çš„ã«ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æFlowã‚’ç”Ÿæˆ"""
    
    # åŸºæœ¬ã‚¹ãƒ†ãƒƒãƒ—
    steps = {
        "preprocess": FunctionStep("preprocess", lambda data, ctx: data)
    }
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‹•çš„ã«ä½œæˆ
    agent_steps = []
    for i, config in enumerate(agents_config):
        agent = RefinireAgent(
            name=f"agent_{i}",
            generation_instructions=config["instructions"],
            model=config.get("model", "gpt-4o-mini")
        )
        agent_steps.append(agent)
    
    # ä¸¦åˆ—å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½åŠ 
    steps["parallel_analysis"] = {
        "parallel": agent_steps,
        "next_step": "synthesize",
        "max_workers": min(len(agent_steps), 4)
    }
    
    # çµ±åˆã‚¹ãƒ†ãƒƒãƒ—
    if analysis_type == "comprehensive":
        synthesizer = RefinireAgent(
            name="synthesizer",
            generation_instructions="""
            è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆ†æçµæœã‚’çµ±åˆã—ã€åŒ…æ‹¬çš„ãªçµè«–ã‚’å°å‡ºã—ã¦ãã ã•ã„ã€‚
            å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¦–ç‚¹ã‚’è€ƒæ…®ã—ã€ä¸€è²«æ€§ã®ã‚ã‚‹æœ€çµ‚çš„ãªåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
            """,
            model="gpt-4o-mini"
        )
    else:
        synthesizer = FunctionStep("simple_combine", lambda data, ctx: f"åˆ†æå®Œäº†: {data}")
    
    steps["synthesize"] = synthesizer
    
    return Flow(start="preprocess", steps=steps)

# å‹•çš„Flowç”Ÿæˆã®ä¾‹
async def run_dynamic_flow_example():
    # è¤‡æ•°ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
    agents_config = [
        {
            "instructions": "æŠ€è¡“çš„ãªè¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„",
            "model": "gpt-4o-mini"
        },
        {
            "instructions": "ãƒ“ã‚¸ãƒã‚¹çš„ãªè¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„", 
            "model": "gpt-4o-mini"
        },
        {
            "instructions": "ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„",
            "model": "gpt-4o-mini"
        },
        {
            "instructions": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„",
            "model": "gpt-4o-mini"
        }
    ]
    
    # å‹•çš„ã«Flowã‚’ç”Ÿæˆ
    dynamic_flow = create_multi_agent_analysis_flow(agents_config, "comprehensive")
    
    # å®Ÿè¡Œ
    result = await dynamic_flow.run("æ–°ã—ã„Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦åˆ†æã—ã¦ãã ã•ã„")
    print(f"å‹•çš„Flowçµæœ: {result}")
```

### 3.3 ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç›£è¦–ã¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

æœ¬ç•ªç’°å¢ƒã§ã¯ã€Flowå®Ÿè¡Œã®ç›£è¦–ã¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãŒé‡è¦ã§ã™ã€‚

```python
from refinire import get_global_registry, enable_console_tracing
import time
from datetime import datetime

# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
enable_console_tracing()

class ProductionFlowMonitor:
    """æœ¬ç•ªFlowç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.metrics = {
            "total_executions": 0,
            "successful_executions": 0,
            "failed_executions": 0,
            "average_duration": 0,
            "error_patterns": {}
        }
    
    def log_execution_start(self, flow_name, input_data):
        """å®Ÿè¡Œé–‹å§‹ãƒ­ã‚°"""
        timestamp = datetime.now().isoformat()
        logger.info(f"[{timestamp}] Flow '{flow_name}' é–‹å§‹ - å…¥åŠ›: {str(input_data)[:100]}...")
        return time.time()
    
    def log_execution_end(self, flow_name, start_time, success, result=None, error=None):
        """å®Ÿè¡Œçµ‚äº†ãƒ­ã‚°"""
        duration = time.time() - start_time
        timestamp = datetime.now().isoformat()
        
        self.metrics["total_executions"] += 1
        
        if success:
            self.metrics["successful_executions"] += 1
            logger.info(f"[{timestamp}] Flow '{flow_name}' æˆåŠŸ - å®Ÿè¡Œæ™‚é–“: {duration:.2f}ç§’")
        else:
            self.metrics["failed_executions"] += 1
            error_type = type(error).__name__ if error else "Unknown"
            self.metrics["error_patterns"][error_type] = self.metrics["error_patterns"].get(error_type, 0) + 1
            logger.error(f"[{timestamp}] Flow '{flow_name}' å¤±æ•— - ã‚¨ãƒ©ãƒ¼: {error}")
        
        # å¹³å‡å®Ÿè¡Œæ™‚é–“ã‚’æ›´æ–°
        self.metrics["average_duration"] = (
            (self.metrics["average_duration"] * (self.metrics["total_executions"] - 1) + duration) 
            / self.metrics["total_executions"]
        )
    
    def get_health_status(self):
        """ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
        total = self.metrics["total_executions"]
        if total == 0:
            return {"status": "no_data", "message": "å®Ÿè¡Œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        success_rate = (self.metrics["successful_executions"] / total) * 100
        
        if success_rate >= 95:
            status = "healthy"
        elif success_rate >= 85:
            status = "warning"
        else:
            status = "critical"
        
        return {
            "status": status,
            "success_rate": f"{success_rate:.2f}%",
            "average_duration": f"{self.metrics['average_duration']:.2f}ç§’",
            "total_executions": total,
            "error_patterns": self.metrics["error_patterns"]
        }

# ç›£è¦–æ©Ÿèƒ½ä»˜ãFlowå®Ÿè¡Œé–¢æ•°
monitor = ProductionFlowMonitor()

async def run_monitored_flow(flow, input_data, flow_name):
    """ç›£è¦–æ©Ÿèƒ½ä»˜ãFlowå®Ÿè¡Œ"""
    start_time = monitor.log_execution_start(flow_name, input_data)
    
    try:
        result = await flow.run(input_data)
        monitor.log_execution_end(flow_name, start_time, True, result)
        return result
    except Exception as error:
        monitor.log_execution_end(flow_name, start_time, False, error=error)
        raise

# æœ¬ç•ªå¯¾å¿œFlowä¾‹
production_flow = Flow({
    "validate_input": FunctionStep("validate", lambda data, ctx: data.strip() if data else ""),
    "process": RefinireAgent(
        name="production_agent",
        generation_instructions="æœ¬ç•ªç’°å¢ƒã§å®‰å…¨ã§é«˜å“è³ªãªå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„",
        evaluation_instructions="å¿œç­”ã®å®‰å…¨æ€§ã¨å“è³ªã‚’è©•ä¾¡ã—ã¦ãã ã•ã„",
        threshold=85.0,
        model="gpt-4o-mini"
    ),
    "postprocess": FunctionStep("postprocess", lambda data, ctx: f"[æœ¬ç•ªå¿œç­”] {data}")
})

async def run_production_example():
    # è¤‡æ•°ã®å®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    test_inputs = [
        "æ­£å¸¸ãªå…¥åŠ›ãƒ‡ãƒ¼ã‚¿",
        "åˆ¥ã®æ­£å¸¸ãªå…¥åŠ›",
        "",  # ç©ºã®å…¥åŠ›ï¼ˆã‚¨ãƒ©ãƒ¼ã«ãªã‚‹å¯èƒ½æ€§ï¼‰
        "ã‚‚ã†ä¸€ã¤ã®æ­£å¸¸ãªå…¥åŠ›"
    ]
    
    for i, input_data in enumerate(test_inputs):
        try:
            result = await run_monitored_flow(production_flow, input_data, "production_flow")
            print(f"å®Ÿè¡Œ {i+1}: æˆåŠŸ - {result[:50]}...")
        except Exception as e:
            print(f"å®Ÿè¡Œ {i+1}: å¤±æ•— - {e}")
    
    # ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º
    health_status = monitor.get_health_status()
    print(f"\n=== Flow ãƒ˜ãƒ«ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ ===")
    print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {health_status['status']}")
    print(f"æˆåŠŸç‡: {health_status['success_rate']}")
    print(f"å¹³å‡å®Ÿè¡Œæ™‚é–“: {health_status['average_duration']}")
    print(f"ç·å®Ÿè¡Œå›æ•°: {health_status['total_executions']}")
    if health_status['error_patterns']:
        print(f"ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³: {health_status['error_patterns']}")
```

### 3.4 A/Bãƒ†ã‚¹ãƒˆã¨å®Ÿé¨“çš„Flow

æœ¬ç•ªç’°å¢ƒã§ã®A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…ã™ã‚‹é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚

```python
import random
from enum import Enum

class FlowVariant(Enum):
    """Flow ãƒãƒªã‚¢ãƒ³ãƒˆ"""
    CONTROL = "control"
    EXPERIMENTAL = "experimental"

class ABTestingManager:
    """A/Bãƒ†ã‚¹ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, experiment_name, traffic_split=0.5):
        self.experiment_name = experiment_name
        self.traffic_split = traffic_split
        self.results = {
            FlowVariant.CONTROL: {"success": 0, "total": 0, "avg_score": 0},
            FlowVariant.EXPERIMENTAL: {"success": 0, "total": 0, "avg_score": 0}
        }
    
    def assign_variant(self, user_id=None):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒãƒªã‚¢ãƒ³ãƒˆã‚’å‰²ã‚Šå½“ã¦"""
        if user_id:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã«åŸºã¥ãä¸€è²«ã—ãŸã‚¢ã‚µã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ
            hash_value = hash(f"{user_id}_{self.experiment_name}") % 100
            return FlowVariant.EXPERIMENTAL if hash_value < (self.traffic_split * 100) else FlowVariant.CONTROL
        else:
            # ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚µã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ
            return FlowVariant.EXPERIMENTAL if random.random() < self.traffic_split else FlowVariant.CONTROL
    
    def record_result(self, variant, success, score=None):
        """çµæœã‚’è¨˜éŒ²"""
        self.results[variant]["total"] += 1
        if success:
            self.results[variant]["success"] += 1
        if score is not None:
            current_avg = self.results[variant]["avg_score"]
            total = self.results[variant]["total"]
            self.results[variant]["avg_score"] = ((current_avg * (total - 1)) + score) / total
    
    def get_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        stats = {}
        for variant in FlowVariant:
            data = self.results[variant]
            total = data["total"]
            if total > 0:
                success_rate = (data["success"] / total) * 100
                stats[variant.value] = {
                    "success_rate": f"{success_rate:.2f}%",
                    "avg_score": f"{data['avg_score']:.2f}",
                    "sample_size": total
                }
            else:
                stats[variant.value] = {"success_rate": "N/A", "avg_score": "N/A", "sample_size": 0}
        return stats

# A/Bãƒ†ã‚¹ãƒˆå¯¾è±¡ã®Flow
def create_control_flow():
    """ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ç‰ˆFlowï¼ˆå¾“æ¥æ‰‹æ³•ï¼‰"""
    return Flow({
        "process": RefinireAgent(
            name="control_agent",
            generation_instructions="ç°¡æ½”ã§ç›´æ¥çš„ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„",
            model="gpt-4o-mini"
        )
    })

def create_experimental_flow():
    """å®Ÿé¨“ç‰ˆFlowï¼ˆæ–°æ‰‹æ³•ï¼‰"""
    return Flow({
        "analyze": RefinireAgent(
            name="analyzer",
            generation_instructions="ã¾ãšå…¥åŠ›ã‚’è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„",
            model="gpt-4o-mini"
        ),
        "respond": RefinireAgent(
            name="responder",
            generation_instructions="åˆ†æçµæœã«åŸºã¥ã„ã¦åŒ…æ‹¬çš„ã§æœ‰ç”¨ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„",
            evaluation_instructions="å›ç­”ã®æœ‰ç”¨æ€§ã¨åŒ…æ‹¬æ€§ã‚’0-100ã§è©•ä¾¡ã—ã¦ãã ã•ã„",
            threshold=80.0,
            model="gpt-4o-mini"
        )
    })

# A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
ab_test = ABTestingManager("response_quality_experiment", traffic_split=0.5)
control_flow = create_control_flow()
experimental_flow = create_experimental_flow()

async def run_ab_test_example():
    test_queries = [
        "Pythonã§ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¯ï¼Ÿ",
        "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦æ•™ãˆã¦",
        "Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã¯ï¼Ÿ",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã®åŸºæœ¬åŸå‰‡ã¯ï¼Ÿ",
        "APIã®è¨­è¨ˆã«ãŠã„ã¦é‡è¦ãªè€ƒæ…®ç‚¹ã¯ï¼Ÿ"
    ]
    
    for i, query in enumerate(test_queries):
        user_id = f"user_{i % 3}"  # 3ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        variant = ab_test.assign_variant(user_id)
        
        try:
            if variant == FlowVariant.CONTROL:
                result = await control_flow.run(query)
                success = len(result) > 50  # ç°¡å˜ãªæˆåŠŸåˆ¤å®š
                score = len(result) / 10  # ç°¡å˜ãªã‚¹ã‚³ã‚¢ç®—å‡º
            else:
                ctx = Context()
                result = await experimental_flow.run(query, ctx)
                success = len(result) > 50
                # å®Ÿé¨“ç‰ˆã§ã¯è©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨
                score = ctx.evaluation_result.get('score', 50) if hasattr(ctx, 'evaluation_result') and ctx.evaluation_result else 50
            
            ab_test.record_result(variant, success, score)
            print(f"ã‚¯ã‚¨ãƒª {i+1} ({variant.value}): {'æˆåŠŸ' if success else 'å¤±æ•—'} (ã‚¹ã‚³ã‚¢: {score:.1f})")
            
        except Exception as e:
            ab_test.record_result(variant, False)
            print(f"ã‚¯ã‚¨ãƒª {i+1} ({variant.value}): ã‚¨ãƒ©ãƒ¼ - {e}")
    
    # çµæœã®è¡¨ç¤º
    stats = ab_test.get_statistics()
    print(f"\n=== A/Bãƒ†ã‚¹ãƒˆçµæœ ===")
    print(f"ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ç‰ˆ: æˆåŠŸç‡ {stats['control']['success_rate']}, å¹³å‡ã‚¹ã‚³ã‚¢ {stats['control']['avg_score']}, ã‚µãƒ³ãƒ—ãƒ«æ•° {stats['control']['sample_size']}")
    print(f"å®Ÿé¨“ç‰ˆ: æˆåŠŸç‡ {stats['experimental']['success_rate']}, å¹³å‡ã‚¹ã‚³ã‚¢ {stats['experimental']['avg_score']}, ã‚µãƒ³ãƒ—ãƒ«æ•° {stats['experimental']['sample_size']}")
```

### 3.5 ä¸Šç´šç·¨ã¾ã¨ã‚ã¨å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

#### ä¸Šç´šç·¨ã§å­¦ã‚“ã ã“ã¨
- å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
- å‹•çš„Flowç”Ÿæˆã¨ãƒ¡ã‚¿ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æŠ€æ³•
- ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç›£è¦–ã¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
- A/Bãƒ†ã‚¹ãƒˆã¨å®Ÿé¨“çš„ãªæ©Ÿèƒ½é–‹ç™º

#### æœ€çµ‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆFlowã‚·ã‚¹ãƒ†ãƒ 

```python
# æœ€çµ‚èª²é¡Œ: ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç´šã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„
# 
# 1. ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œï¼ˆãƒ†ãƒŠãƒ³ãƒˆã”ã¨ã®è¨­å®šã¨ãƒ‡ãƒ¼ã‚¿åˆ†é›¢ï¼‰
# 2. å½¹å‰²ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ï¼ˆç®¡ç†è€…ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã‚²ã‚¹ãƒˆï¼‰
# 3. è¤‡æ•°ã®Flowãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆå–¶æ¥­æ”¯æ´ã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã€ãƒ‡ãƒ¼ã‚¿åˆ†æï¼‰
# 4. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
# 5. A/Bãƒ†ã‚¹ãƒˆæ©Ÿèƒ½
# 6. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªä¸¦åˆ—å‡¦ç†
# 7. åŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
# 8. ç›£æŸ»ãƒ­ã‚°æ©Ÿèƒ½

class EnterpriseFlowSystem:
    """ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºFlow ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.tenants = {}
        self.flow_templates = {}
        self.monitoring = {}
        self.ab_tests = {}
    
    def register_tenant(self, tenant_id, config):
        """ãƒ†ãƒŠãƒ³ãƒˆç™»éŒ²"""
        # å®Ÿè£…ã—ã¦ãã ã•ã„
        pass
    
    def create_flow_template(self, template_name, flow_config):
        """Flowãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ"""
        # å®Ÿè£…ã—ã¦ãã ã•ã„
        pass
    
    async def execute_flow(self, tenant_id, user_id, template_name, input_data, user_role="user"):
        """Flowå®Ÿè¡Œï¼ˆæ¨©é™ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰"""
        # å®Ÿè£…ã—ã¦ãã ã•ã„
        pass
    
    def get_monitoring_dashboard(self, tenant_id):
        """ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        # å®Ÿè£…ã—ã¦ãã ã•ã„
        pass

# ãƒ’ãƒ³ãƒˆ: ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ã“ã‚Œã¾ã§å­¦ã‚“ã ã™ã¹ã¦ã®æŠ€æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã—ã¾ã™
# - å‹•çš„Flowç”Ÿæˆ
# - å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
# - ç›£è¦–ã¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°
# - A/Bãƒ†ã‚¹ãƒˆ
# - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨æ¨©é™ç®¡ç†
```

---

## ğŸ“‹ å­¦ç¿’ã®é€²ã‚æ–¹ã¨ã¾ã¨ã‚

### æ¨å¥¨å­¦ç¿’é †åº

1. **åŸºç¤ç·¨**ï¼ˆ1-2æ—¥ï¼‰
   - Flowã®åŸºæœ¬æ¦‚å¿µã‚’ç†è§£
   - FunctionStepã¨ConditionStepã‚’ãƒã‚¹ã‚¿ãƒ¼
   - ç°¡å˜ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ

2. **ä¸­ç´šç·¨**ï¼ˆ3-5æ—¥ï¼‰
   - RefinireAgentã®çµ±åˆã‚’å­¦ç¿’
   - ä¸¦åˆ—å‡¦ç†ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ¹æœã‚’ä½“é¨“
   - RouterAgentã¨ClarifyAgentã‚’æ´»ç”¨

3. **ä¸Šç´šç·¨**ï¼ˆ1-2é€±é–“ï¼‰
   - æœ¬ç•ªç’°å¢ƒã‚’æƒ³å®šã—ãŸFlowè¨­è¨ˆ
   - ç›£è¦–ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè£…
   - A/Bãƒ†ã‚¹ãƒˆã¨å®Ÿé¨“çš„æ©Ÿèƒ½ã‚’è©¦è¡Œ

### ã•ã‚‰ãªã‚‹å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

- **API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹**: [Flow API è©³ç´°](flow_step.md)
- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¬ã‚¤ãƒ‰**: [Flow ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](composable-flow-architecture.md)
- **å®Ÿè·µä¾‹**: `examples/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å„ç¨®ã‚µãƒ³ãƒ—ãƒ«
- **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£**: GitHub Discussions ã§ã®è³ªå•ã¨æƒ…å ±äº¤æ›

### æˆåŠŸã®ã‚³ãƒ„

1. **å°ã•ãå§‹ã‚ã‚‹**: ã‚·ãƒ³ãƒ—ãƒ«ãªFlowã‹ã‚‰å§‹ã‚ã¦æ®µéšçš„ã«è¤‡é›‘ã•ã‚’è¿½åŠ 
2. **å®Ÿéš›ã«å‹•ã‹ã™**: ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèª
3. **ç›£è¦–ã‚’é‡è¦–**: æœ¬ç•ªã§ã¯å¿…ãšç›£è¦–ã¨ãƒ­ã‚°ã‚’å®Ÿè£…
4. **ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**: å„ã‚¹ãƒ†ãƒƒãƒ—ã¨Flowå…¨ä½“ã®ãƒ†ã‚¹ãƒˆã‚’ä½œæˆ
5. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–**: Flowã®è¨­è¨ˆæ„å›³ã¨å‹•ä½œã‚’æ–‡æ›¸åŒ–

Flowã‚’ä½¿ã„ã“ãªã—ã¦ã€å …ç‰¢ã§ä¿å®ˆæ€§ã®é«˜ã„AIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã—ã‚‡ã†ï¼