#!/usr/bin/env python3
"""
LMStudio Mistral Connection Example

English: Demonstrates connecting to LMStudio's mistralai/devstral-small-2507 model.
æ—¥æœ¬èª: LMStudio ã® mistralai/devstral-small-2507 ãƒ¢ãƒ‡ãƒ«ã¸ã®æ¥ç¶šä¾‹ã€‚

Note: This example shows the current behavior of RefinireAgent with LMStudio.
Due to configuration issues, the agent may not return results properly.
For direct API access, use the raw curl examples provided.

æ³¨æ„: ã“ã®ä¾‹ã§ã¯ã€RefinireAgent ã¨ LMStudio ã®ç¾åœ¨ã®å‹•ä½œã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
è¨­å®šã®å•é¡Œã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçµæœã‚’é©åˆ‡ã«è¿”ã•ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
ç›´æ¥çš„ãªAPIã‚¢ã‚¯ã‚»ã‚¹ã«ã¯ã€æä¾›ã•ã‚ŒãŸcurlã®ä¾‹ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
"""

import os
from refinire import RefinireAgent, Context, disable_tracing
from refinire.core.llm import get_llm


def main():
    """
    LMStudio Mistral connection example
    LMStudio Mistral æ¥ç¶šä¾‹
    """
    print("=== LMStudio Mistral Connection Example ===")
    
    # Disable tracing for cleaner output
    # å‡ºåŠ›ã‚’ãã‚Œã„ã«ã™ã‚‹ãŸã‚ã«ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’ç„¡åŠ¹åŒ–
    disable_tracing()
    
    # Clear OLLAMA_BASE_URL to prevent provider misidentification
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®èª¤èªè­˜ã‚’é˜²ããŸã‚ã« OLLAMA_BASE_URL ã‚’ã‚¯ãƒªã‚¢
    if 'OLLAMA_BASE_URL' in os.environ:
        del os.environ['OLLAMA_BASE_URL']
        print("ğŸ”§ Cleared OLLAMA_BASE_URL environment variable")
    
    # LMStudio configuration
    # LMStudio ã®è¨­å®š
    lmstudio_base_url = os.getenv('LMSTUDIO_BASE_URL', 'http://localhost:1234')
    
    # Ensure /v1 is appended to base URL for proper API endpoint
    # é©åˆ‡ãªAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãŸã‚ã«base URLã« /v1 ã‚’è¿½åŠ 
    if not lmstudio_base_url.endswith('/v1'):
        lmstudio_base_url = lmstudio_base_url.rstrip('/') + '/v1'
        print(f"ğŸ”§ Added /v1 to base URL: {lmstudio_base_url}")
    
    model_name = "mistralai/devstral-small-2507"
    
    print(f"Using LMStudio at: {lmstudio_base_url}")
    print(f"Using model: {model_name}")
    
    # Show direct API example
    # ç›´æ¥APIã®ä¾‹ã‚’è¡¨ç¤º
    print("\nğŸ“„ Direct API Example (works correctly):")
    print("curl " + lmstudio_base_url + "/chat/completions \\")
    print("  -H \"Content-Type: application/json\" \\")
    print("  -d '{")
    print("    \"model\": \"mistralai/devstral-small-2507\",")
    print("    \"messages\": [")
    print("      {\"role\": \"user\", \"content\": \"Hello!\"},")
    print("    ],")
    print("    \"temperature\": 0.7")
    print("  }'")
    
    try:
        # Create LLM with Chat Completion client for LMStudio
        # LMStudio ç”¨ã® Chat Completion ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ LLM ã‚’ä½œæˆ
        print(f"ğŸ”§ Creating LLM with provider='lmstudio', base_url={lmstudio_base_url}")
        llm = get_llm(
            provider="lmstudio",  # Use Chat Completion client for LMStudio
            model=model_name,
            base_url=lmstudio_base_url,
            api_key="lm-studio"
        )
        print(f"âœ… LLM created: {type(llm)}")
        print(f"   Model: {llm.model}")
        
        # Verify the LLM configuration
        # LLMè¨­å®šã‚’ç¢ºèª
        if hasattr(llm, '_client') and hasattr(llm._client, 'base_url'):
            print(f"   Base URL: {llm._client.base_url}")
        elif hasattr(llm, 'base_url'):
            print(f"   Base URL: {llm.base_url}")
        else:
            print("   Base URL: Could not determine")
        
        # Create agent with the configured LLM
        # è¨­å®šã•ã‚ŒãŸLLMã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
        agent = RefinireAgent(
            name="lmstudio_agent",
            generation_instructions="You are a helpful assistant powered by Mistral. Keep responses concise.",
            model=llm
        )
        
        # Test queries
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_queries = [
            "Hello! Can you introduce yourself?",
            "What is the capital of France?",
            "Write a short Python function to calculate factorial."
        ]
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n--- Query {i} ---")
            print(f"Input: {query}")
            
            # Create fresh context for each query
            # å„ã‚¯ã‚¨ãƒªã«æ–°ã—ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            context = Context()
            
            # Query the model
            # ãƒ¢ãƒ‡ãƒ«ã«ã‚¯ã‚¨ãƒª
            result_context = agent.run(query, context)
            
            # Get response
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—
            result = result_context.shared_state.get('lmstudio_agent_result')
            
            if result is None:
                print("âš ï¸  No response received from RefinireAgent")
                print("   This is a known issue with LMStudio integration")
                print("   The agent communicates with LMStudio but doesn't return results")
                print("   See lmstudio_direct_integration.py for working solution")
            else:
                print(f"âœ… Response: {result}")
        
        print("\nğŸ“ Status Summary:")
        print("âœ… RefinireAgent connects to LMStudio successfully")
        print("âœ… LMStudio API is working (verified with curl)")
        print("âœ… RefinireAgent result retrieval working with Chat Completion client")
        print("ğŸ’¡ Key: Use provider='lmstudio' for Chat Completion client")
        
    except Exception as e:
        print(f"âŒ Error connecting to LMStudio: {e}")
        import traceback
        traceback.print_exc()
        print("\nğŸ” Known Issue Analysis:")
        print("The 'NoneType' object is not iterable error occurs because:")
        print("1. RefinireAgent calls /responses or /chat/completions endpoints")
        print("2. LMStudio only supports /v1/chat/completions endpoint")
        print("3. Response format mismatch causes parsing errors")
        print("\nTroubleshooting tips:")
        print("1. Make sure LMStudio is running and serving the model")
        print("2. Check that the model name matches exactly: mistralai/devstral-small-2507")
        print("3. Verify LMSTUDIO_BASE_URL environment variable is set")
        print("4. Ensure the model is loaded and ready in LMStudio")
        print("5. Use the direct API integration example for reliable LMStudio access")


if __name__ == '__main__':
    main()