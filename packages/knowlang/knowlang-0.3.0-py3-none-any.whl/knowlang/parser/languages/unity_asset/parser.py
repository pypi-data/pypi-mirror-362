from __future__ import annotations
from pathlib import Path
import os
from typing import List, Union, Dict
from dataclasses import dataclass
from abc import ABC, abstractmethod

from knowlang.assets.codebase.models import CodeProcessorConfig
from knowlang.core.types import BaseChunkType, CodeChunk, CodeLocation, LanguageEnum
from knowlang.parser.base.parser import LanguageParser
from knowlang.utils import FancyLogger
import aiofiles
import json
import yaml

LOG = FancyLogger(__name__)


@dataclass
class Node:
    x: float
    y: float
    id: str
    type: str
    guid: str
    raw_json: str
    graph_id: int  # generated by us


@dataclass
class Connection:
    start_id: str
    end_id: str
    id: str
    type: str
    raw_json: str
    graph_id: int  # generated by us


@dataclass
class Group:
    x_min: float
    y_min: float
    x_max: float
    y_max: float
    id: str
    type: str
    raw_json: str
    graph_id: int  # generated by us


class UnityYAMLLoader(yaml.SafeLoader):
    """Custom YAML loader for Unity asset files that handles Unity-specific tags"""

    pass


def unity_object_constructor(
    loader: yaml.SafeLoader, tag_suffix: str, node: yaml.Node
) -> dict:
    """Constructor for Unity objects with custom tags"""
    if isinstance(node, yaml.MappingNode):
        return loader.construct_mapping(node)
    elif isinstance(node, yaml.SequenceNode):
        return loader.construct_sequence(node)
    else:
        return loader.construct_scalar(node)


# Register constructors for Unity-specific tags
UnityYAMLLoader.add_multi_constructor("tag:unity3d.com,2011:", unity_object_constructor)


class UnityObjectHandler(ABC):
    """Abstract base class for handling different Unity object types"""

    def __init__(self, config: CodeProcessorConfig = None):
        self.config = config

    @abstractmethod
    def can_handle(self, unity_type: str, data: dict) -> bool:
        """Check if this handler can process the given Unity object type"""
        pass

    @abstractmethod
    def extract_chunks(self, data: dict, file_path: str) -> List[CodeChunk]:
        """Extract code chunks from the Unity object data"""
        pass


class MonoBehaviourHandler(UnityObjectHandler):
    """Handler for MonoBehaviour objects (Visual Scripting)"""

    def can_handle(self, unity_type: str, data: dict) -> bool:
        """Check if this is a MonoBehaviour with Visual Scripting data"""
        return unity_type == "114" and "_data" in data and "_json" in data["_data"]

    def extract_chunks(self, data: dict, file_path: str) -> List[CodeChunk]:
        """Extract Visual Scripting chunks from MonoBehaviour"""
        try:
            json_string = data["_data"]["_json"]
            graph_data = json.loads(json_string)
        except json.JSONDecodeError:
            LOG.warning(f"Failed to parse JSON in MonoBehaviour from {file_path}")
            return []

        # Extract all raw elements from the graph
        raw_elements = graph_data.get("graph", {}).get("elements", [])

        # Parse each raw element into the appropriate data class
        nodes: Dict[str, Node] = {}
        connections: List[Connection] = []
        groups: List[Group] = []

        for i, raw_element in enumerate(raw_elements):
            element = self._parse_element(raw_element)
            element.graph_id = i
            if isinstance(element, Node):
                nodes[element.id] = element
            elif isinstance(element, Connection):
                connections.append(element)
            elif isinstance(element, Group):
                groups.append(element)

        # Group connected elements together
        self._group_connected_elements(nodes, connections, groups)

        # Convert to chunks
        return self._create_chunks(nodes, connections, groups, file_path)

    def _parse_element(self, raw_element: dict) -> Union[Node, Connection, Group]:
        """Parse a raw element dictionary into the appropriate data class"""
        element_type = raw_element.get("$type", "")

        if "Connection" in element_type:
            # Parse connection (both control and value connections)
            return Connection(
                start_id=raw_element.get("sourceUnit", {}).get("$ref", ""),
                end_id=raw_element.get("destinationUnit", {}).get("$ref", ""),
                id=raw_element.get("guid", ""),
                type=element_type,
                raw_json=json.dumps(raw_element),
                graph_id=0,
            )
        elif "GraphGroup" in element_type:
            # Parse group
            position = raw_element.get("position", {})
            return Group(
                x_min=position.get("xMin", 0.0),
                y_min=position.get("yMin", 0.0),
                x_max=position.get("xMax", 0.0),
                y_max=position.get("yMax", 0.0),
                id=raw_element.get("guid", ""),
                raw_json=json.dumps(raw_element),
                type=element_type,
                graph_id=0,
            )
        else:
            # Parse node (everything else with an ID)
            position = raw_element.get("position", {})
            return Node(
                x=position.get("x", 0.0),
                y=position.get("y", 0.0),
                id=raw_element.get("$id", ""),
                raw_json=json.dumps(raw_element),
                type=element_type,
                guid=raw_element.get("guid", ""),
                graph_id=0,
            )

    def _group_connected_elements(
        self, nodes: Dict[str, Node], connections: List[Connection], groups: List[Group]
    ):
        """Group connected elements together by assigning same graph_id"""

        def merge_elements(elements: List[Union[Node, Connection, Group]]):
            if len(elements) == 0:
                return
            shared_graph_id = elements[0].graph_id
            for element in elements:
                element.graph_id = shared_graph_id

        # Create connected graphs based on groups first
        for group in groups:
            group_nodes = []
            for node in nodes.values():
                x_collide = group.x_min <= node.x <= group.x_max
                y_collide = group.y_min <= node.y <= group.y_max
                if x_collide and y_collide:
                    group_nodes.append(node)

            merge_elements(group_nodes + [group])

        def merge_graphs(graph_ids):
            if len(graph_ids) == 0:
                return
            new_graph_id = graph_ids[0]
            all_elements = list(nodes.values()) + connections + groups
            elements_to_merge = list(
                filter(lambda e: e.graph_id in graph_ids, all_elements)
            )
            for element in elements_to_merge:
                element.graph_id = new_graph_id

        for connection in connections:
            if not (connection.start_id in nodes and connection.end_id in nodes):
                continue
            start_node_graph_id = nodes[connection.start_id].graph_id
            end_node_graph_id = nodes[connection.end_id].graph_id
            merge_graphs([start_node_graph_id, end_node_graph_id, connection.graph_id])

    def _create_chunks(
        self,
        nodes: Dict[str, Node],
        connections: List[Connection],
        groups: List[Group],
        file_path: str,
    ) -> List[CodeChunk]:
        """Create CodeChunk objects from grouped elements"""
        elements_by_graph = {}

        for element in list(nodes.values()) + connections + groups:
            if element.graph_id not in elements_by_graph:
                elements_by_graph[element.graph_id] = []
            elements_by_graph[element.graph_id].append(element)

        chunks = []
        relative_path = os.path.relpath(file_path, self.config.directory_path)

        for i, graph_elements in enumerate(elements_by_graph.values()):
            raw_json_elements = map(lambda e: e.raw_json, graph_elements)
            content = "[" + (", ").join(raw_json_elements) + "]"

            chunk = CodeChunk(
                language=LanguageEnum.UNITYASSET,
                type=BaseChunkType.OTHER,
                name="",
                content=content,
                location=CodeLocation(
                    file_path=str(relative_path),
                    start_line=i,
                    end_line=i + 1,
                ),
                docstring="",
            )
            chunks.append(chunk)

        return chunks


# Placeholder handlers for future Unity object types
class GameObjectHandler(UnityObjectHandler):
    """Handler for GameObject objects (type 1)"""

    def can_handle(self, unity_type: str, data: dict) -> bool:
        return unity_type == "1"

    def extract_chunks(self, data: dict, file_path: str) -> List[CodeChunk]:
        # TODO: Implement GameObject parsing
        LOG.debug(f"GameObject handler not yet implemented for {file_path}")
        return []


class InputManagerHandler(UnityObjectHandler):
    """Handler for InputManager objects (type 13)"""

    def can_handle(self, unity_type: str, data: dict) -> bool:
        return unity_type == "13"

    def extract_chunks(self, data: dict, file_path: str) -> List[CodeChunk]:
        # TODO: Implement InputManager parsing
        LOG.debug(f"InputManager handler not yet implemented for {file_path}")
        return []


class UnityAssetParser(LanguageParser):
    """Parser for Unity Assets with extensible handler system"""

    # https://docs.unity3d.com/Manual/ClassIDReference.html
    _unity_class_code_mapping: Dict[str, str] = {
        "GameObject": "1",
        "MonoBehaviour": "114",
        "InputManager": "13",
        # Add more mappings as needed
    }

    def setup(self) -> None:
        """Initialize parser for Unity Assets"""
        self.language_name = LanguageEnum.UNITYASSET
        self.language_config = self.config.languages[LanguageEnum.UNITYASSET.value]

        self.handlers: Dict[str, UnityObjectHandler] = {
            "1": GameObjectHandler(self.config),
            "114": MonoBehaviourHandler(self.config),
            "13": InputManagerHandler(self.config),
        }

    async def parse_file(self, file_path: Path) -> List[CodeChunk]:
        """Parse a single Unity Asset file using proper YAML parsing"""
        if not self.supports_extension(file_path.suffix):
            LOG.debug(f"Skipping file {file_path}: unsupported extension")
            return []

        # Check file size limit
        if file_path.stat().st_size > self.language_config.max_file_size:
            LOG.warning(
                f"Skipping file {file_path}: exceeds size limit of {self.language_config.max_file_size} bytes"
            )
            return []

        try:
            async with aiofiles.open(file_path, "r") as f:
                source_code = await f.read()
        except UnicodeDecodeError:
            LOG.warning(f"Skipping file {file_path}: binary encoded files are skipped")
            return []

        # Parse Unity asset file using proper YAML parsing
        try:
            documents = list(yaml.load_all(source_code, Loader=UnityYAMLLoader))
        except yaml.YAMLError as e:
            LOG.warning(f"Skipping file {file_path}: YAML parsing failed - {e}")
            return []

        chunks = []

        # Process each YAML document in the file
        for doc in documents:
            if doc is None:
                continue

            # Extract Unity object type and data
            for unity_object_key, unity_object_data in doc.items():
                if (
                    unity_type := self._unity_class_code_mapping.get(
                        unity_object_key, ""
                    )
                ) is None:
                    LOG.warning(
                        f"Unknown Unity object type in {file_path}: {unity_object_key}"
                    )
                    continue

                if (handler := self.handlers.get(unity_type, None)) is None:
                    LOG.warning(
                        f"Unknown handler for Unity object type {unity_type} in {file_path}"
                    )
                    continue

                if handler.can_handle(unity_type, unity_object_data) is False:
                    LOG.debug(
                        f"Handler {handler.__class__.__name__} cannot handle {unity_object_key} in {file_path}"
                    )
                    continue

                try:
                    handler_chunks = handler.extract_chunks(
                        unity_object_data, str(file_path)
                    )
                    chunks.extend(handler_chunks)
                except Exception as e:
                    LOG.warning(
                        f"Handler {handler.__class__.__name__} failed for {file_path}: {e}"
                    )

        return chunks

    def supports_extension(self, ext: str) -> bool:
        """Check if this parser supports a given file extension"""
        return ext in self.language_config.file_extensions
