from pathlib import Path
from cryptoservice.models.universe import UniverseDefinition
from cryptoservice.models.enums import Freq
from cryptoservice.data import MarketDB
from cryptoservice.services.market_service import MarketDataService

# ============== é…ç½®å‚æ•° ==============
# æ–‡ä»¶è·¯å¾„
UNIVERSE_FILE = "./data/universe.json"  # Universeå®šä¹‰æ–‡ä»¶
DB_PATH = "./data/database/market.db"  # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
EXPORT_BASE_PATH = "./data/exports"  # å¯¼å‡ºæ–‡ä»¶åŸºç¡€è·¯å¾„

# å¯¼å‡ºé…ç½®
DATA_FREQ = Freq.d1  # æ•°æ®åº“æ•°æ®é¢‘ç‡
EXPORT_FREQ = Freq.d1  # å¯¼å‡ºæ•°æ®é¢‘ç‡
CHUNK_DAYS = 100  # åˆ†å—å¤©æ•°

# å¯¼å‡ºçš„ç‰¹å¾ï¼ˆçŸ­å­—æ®µåæ ¼å¼ï¼ŒæŒ‰æŒ‡å®šé¡ºåºï¼‰
EXPORT_FEATURES = [
    "cls",
    "hgh",
    "low",
    "tnum",
    "opn",
    "amt",
    "tbvol",
    "tbamt",
    "vol",
    "vwap",
    "ret",
    "tsvol",
    "tsamt",
    # æ–°ç‰¹å¾ï¼ˆä¸‰ä¸ªæ ¸å¿ƒç‰¹å¾ï¼‰
    "fr",  # èµ„é‡‘è´¹ç‡
    "oi",  # æŒä»“é‡
    "lsr",  # å¤šç©ºæ¯”ä¾‹
]

# ç‰¹å¾æè¿°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
FEATURE_DESCRIPTIONS = {
    "cls": "æ”¶ç›˜ä»·",
    "hgh": "æœ€é«˜ä»·",
    "low": "æœ€ä½ä»·",
    "tnum": "äº¤æ˜“ç¬”æ•°",
    "opn": "å¼€ç›˜ä»·",
    "amt": "æˆäº¤é¢",
    "tbvol": "ä¸»åŠ¨ä¹°å…¥é‡",
    "tbamt": "ä¸»åŠ¨ä¹°å…¥é¢",
    "vol": "æˆäº¤é‡",
    "vwap": "VWAP",
    "ret": "æ”¶ç›Šç‡",
    "tsvol": "ä¸»åŠ¨å–å‡ºé‡",
    "tsamt": "ä¸»åŠ¨å–å‡ºé¢",
    # æ–°ç‰¹å¾æè¿°
    "fr": "èµ„é‡‘è´¹ç‡",
    "oi": "æŒä»“é‡",
    "lsr": "å¤šç©ºæ¯”ä¾‹",
}

# ========================================


def main():
    """ä»æ•°æ®åº“å¯¼å‡ºæ•°æ®è„šæœ¬"""
    print("ğŸ“¤ å¼€å§‹ä»æ•°æ®åº“å¯¼å‡ºæ•°æ®")
    print(f"ğŸ“‹ Universeæ–‡ä»¶: {UNIVERSE_FILE}")
    print(f"ğŸ’¾ æ•°æ®åº“è·¯å¾„: {DB_PATH}")
    print(f"ğŸ“ å¯¼å‡ºè·¯å¾„: {EXPORT_BASE_PATH}")
    print(f"â±ï¸ å¯¼å‡ºé¢‘ç‡: {EXPORT_FREQ}")
    print(f"ğŸ“Š å¯¼å‡ºç‰¹å¾: {len(EXPORT_FEATURES)}ä¸ª")
    print(
        f"    {', '.join([f'{feat}({FEATURE_DESCRIPTIONS[feat]})' for feat in EXPORT_FEATURES[:5]])}..."
    )

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(UNIVERSE_FILE).exists():
        print(f"âŒ Universeæ–‡ä»¶ä¸å­˜åœ¨: {UNIVERSE_FILE}")
        print("è¯·å…ˆè¿è¡Œ define_universe.py åˆ›å»ºUniverseæ–‡ä»¶")
        return

    if not Path(DB_PATH).exists():
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {DB_PATH}")
        print("è¯·å…ˆè¿è¡Œ download_data.py ä¸‹è½½æ•°æ®")
        return

    # ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨
    Path(EXPORT_BASE_PATH).mkdir(parents=True, exist_ok=True)

    try:
        # åŠ è½½Universeå®šä¹‰
        print("ğŸ“– åŠ è½½Universeå®šä¹‰...")
        universe_def = UniverseDefinition.load_from_file(UNIVERSE_FILE)
        print(f"   âœ… æˆåŠŸåŠ è½½ {len(universe_def.snapshots)} ä¸ªå¿«ç…§")

        t1 = universe_def.config.t1_months
        t2 = universe_def.config.t2_months
        t3 = universe_def.config.t3_months
        top_k = universe_def.config.top_k
        top_ratio = universe_def.config.top_ratio
        delay_days = universe_def.config.delay_days
        quote_asset = universe_def.config.quote_asset

        # åˆ›å»ºMarketDBå®ä¾‹
        db = MarketDB(DB_PATH)

        # å¤„ç†æ¯ä¸ªå¿«ç…§
        for i, snapshot in enumerate(universe_def.snapshots):
            print(
                f"\nğŸ“‹ å¤„ç†å¿«ç…§ {i+1}/{len(universe_def.snapshots)}: {snapshot.start_date} - {snapshot.end_date}"
            )
            start_date_ts = snapshot.start_date_ts
            end_date_ts = snapshot.end_date_ts
            symbols = snapshot.symbols

            print(f"   â° æ—¶é—´èŒƒå›´: {start_date_ts} - {end_date_ts}")
            print(f"   ğŸ’± äº¤æ˜“å¯¹æ•°é‡: {len(symbols)}")
            print(f"   ğŸ“ å‰5ä¸ªäº¤æ˜“å¯¹: {symbols[:5]}")

            # åˆ›å»ºå¿«ç…§ä¸“ç”¨çš„å¯¼å‡ºç›®å½•
            snapshot_export_path = (
                Path(EXPORT_BASE_PATH)
                / f"{t1}_{t2}_{t3}_{(top_k if top_k else top_ratio)}_{delay_days}_{quote_asset}"
            )

            # å¯¼å‡ºæ•°æ®
            db.export_to_files_by_timestamp(
                output_path=snapshot_export_path,
                start_ts=start_date_ts,
                end_ts=end_date_ts,
                freq=DATA_FREQ,
                target_freq=EXPORT_FREQ,
                symbols=symbols,
                chunk_days=CHUNK_DAYS,
            )

            MarketDataService.download_and_save_categories_for_universe(
                universe_file=UNIVERSE_FILE,
                output_path=snapshot_export_path,
            )

            # æ˜¾ç¤ºå¯¼å‡ºçš„æ–‡ä»¶ä¿¡æ¯
            if snapshot_export_path.exists():
                export_files = list(snapshot_export_path.rglob("*.npy"))
                universe_files = list(snapshot_export_path.rglob("universe_token.pkl"))

                if export_files:
                    total_size = sum(f.stat().st_size for f in export_files) / (
                        1024 * 1024
                    )  # MB
                    print(f"      ğŸ“Š å¯¼å‡ºæ–‡ä»¶æ•°é‡: {len(export_files)}ä¸ª.npyæ–‡ä»¶")
                    print(f"      ğŸ¯ Universeæ–‡ä»¶: {len(universe_files)}ä¸ª.pklæ–‡ä»¶")
                    print(f"      ğŸ’¾ æ€»æ–‡ä»¶å¤§å°: {total_size:.1f} MB")

                    # æ˜¾ç¤ºç‰¹å¾åˆ†å¸ƒ
                    feature_dirs = [f.parent.name for f in export_files]
                    unique_features = set(feature_dirs)
                    print(
                        f"      ğŸ“ˆ ç‰¹å¾ç±»å‹: {len(unique_features)}ç§ ({', '.join(sorted(unique_features))})"
                    )

    except Exception as e:
        print(f"âŒ æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
