workflow:
  rules:
    # don't create a pipeline if it's a commit pipeline, on a branch and that branch has open merge requests.
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - when: always

default:
  image:
    name: $CI_REGISTRY_IMAGE/ci-build-runner:$CI_COMMIT_REF_SLUG
    pull_policy: always
  before_script:
    - python --version # For debugging
  interruptible: true
  cache:
    paths:
      - .cache/pip
      # Do not cache .tox, to recreate virtualenvs for every step

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip" # Caching of dependencies to speed up builds

stages:
  - prepare
  - lint
  - test
  - package
  - publish

include:
  - template: Security/SAST.gitlab-ci.yml
  - template: Security/Dependency-Scanning.gitlab-ci.yml
  - template: Security/Secret-Detection.gitlab-ci.yml

# Prepare image to run ci on
trigger_prepare:
  stage: prepare
  trigger:
    strategy: depend
    include: .prepare.gitlab-ci.yml

run_lint:
  stage: lint
  script:
    - tox -e lint
  allow_failure: true

sast:
  variables:
    SAST_EXCLUDED_ANALYZERS: brakeman, flawfinder, kubesec, nodejs-scan, phpcs-security-audit,
      pmd-apex, security-code-scan, sobelow, spotbugs
  stage: test

dependency_scanning:
  # override default before_script, job won't have Python available
  before_script:
    - uname

secret_detection:
  # override default before_script, job won't have Python available
  before_script:
    - uname

# Basic setup for all Python versions for which we don't have a base image
.run_unit_test_version_base:
  before_script:
    - python --version # For debugging
    - python -m pip install --upgrade pip
    - python -m pip install --upgrade tox twine

# Run all unit tests for Python versions except the base image
run_unit_tests:
  extends: .run_unit_test_version_base
  stage: test
  image: python:3.${PY_VERSION}
  script:
    - tox -e py3${PY_VERSION}
  parallel:
    matrix: # use the matrix for testing
      - PY_VERSION: [10, 11, 12]

# Run code coverage on the base image thus also performing unit tests
run_unit_tests_coverage:
  stage: test
  script:
   - tox -e coverage
  coverage: '/(?i)total.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - htmlcov/*
      - coverage.xml

sonarcloud-check:
  stage: test
  image:
    name: sonarsource/sonar-scanner-cli:latest
    entrypoint: [""]
  variables:
    SONAR_USER_HOME: "${CI_PROJECT_DIR}/.sonar"  # Defines the location of the analysis task cache
    GIT_DEPTH: "0"  # Tells git to fetch all the branches of the project, required by the analysis task
  needs:
    - job: run_unit_tests_coverage
      artifacts: true
  before_script:
    - uname
  cache:
    key: "${CI_JOB_NAME}"
    paths:
      - .sonar/cache
  script:
    - sonar-scanner
  only:
    - merge_requests
    - main

package_files:
  stage: package
  artifacts:
    expire_in: 1w
    paths:
      - dist/*
  script:
    - tox -e build

package_docs:
  stage: package
  artifacts:
    expire_in: 1w
    paths:
      - docs/build/*
  script:
    - tox -e docs

publish_on_gitlab:
  stage: publish
  environment: gitlab
  needs:
    - package_files
  when: manual
  rules:
    - if: $CI_COMMIT_TAG
  script:
    - echo "run twine for gitlab"
    - |
      TWINE_PASSWORD=${CI_JOB_TOKEN} \
      TWINE_USERNAME=gitlab-ci-token \
      python -m twine upload \
      --repository-url ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi dist/*

publish_on_pypi:
  stage: publish
  environment: pypi
  needs:
    - package_files
  when: manual
  rules:
    - if: '$CI_COMMIT_TAG && $CI_COMMIT_REF_PROTECTED == "true"'
  variables:
    TWINE_PASSWORD: "${PYPI_TOKEN}"
    TWINE_USERNAME: "__token__"
  script:
    - echo "run twine for pypi"
    - python -m twine upload dist/*
