interactions:
- request:
    body: '{"model":"granite3.2:2b","prompt":"<|start_of_role|>system<|end_of_role|>Knowledge
      Cutoff Date: April 2024.\nToday''s Date: March 14, 2025.\nYou are Granite, developed
      by IBM. You are a helpful AI assistant.<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>Hello,
      how are you?<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>I''m doing
      great. How can I help you today?<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>I''d
      like to show off how chat templating works!<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>","best_of":3,"max_tokens":1024,"n":3}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '574'
      content-type:
      - application/json
      host:
      - localhost:11434
      rits_api_key:
      - ollama
      user-agent:
      - AsyncOpenAI/Python 1.66.3
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.66.3
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.11
    method: POST
    uri: http://localhost:11434/v1/completions
  response:
    content: '{"id":"cmpl-66a0fe50c276468bb9332c52d53d998c","object":"text_completion","created":1741998839,"model":"granite3.2:2b","choices":[{"index":0,"text":"Sure,
      I''m ready! Chat templating involves using variables and placeholders within
      a conversation script to adjust responses dynamically based on user input. It''s
      a powerful tool for creating more personalized and interactive conversations.\n\nFor
      example, consider this simple chat template that uses placeholders:\n\n\"Hello,
      [user_name]! It''s nice to meet you. How can I assist you today?\"\n\nIn this
      case, [user_name] is a placeholder. When a user responds, the AI can replace
      this with the actual user''s name:\n\n\"Hello, Alice! It''s nice to meet you.
      How can I assist you today?\"\n\nOr, if you''re teaching me to create more complex
      templates, you might have something like:\n\n\"In today''s forecast, the temperature
      will be [high_temp] degrees, with a chance of [probability_rain] of rain. Enjoy
      your day!\"\n\nWhere ''high_temp'' and ''probability_rain'' are placeholders
      that will change depending on the weather data.\n\nWould you like me to demonstrate
      a specific template or explain how to create one?","logprobs":null,"finish_reason":"stop","stop_reason":null,"prompt_logprobs":null},{"index":1,"text":"Absolutely,
      I''d be happy to demonstrate chat templating! In essence, it''s a system for
      dynamically generating responses based on predefined templates filled with variable
      contents.\n\nLet''s take a simple example:\n\n```\nHello, user! It''s nice to
      chat with you.\n\nAre you feeling:\n\n- [energized](energized)\n- [tired](tired)\n-
      [calm](calm)\n- [curious](curious)\n- [happy](happy)\n\nPlease choose one:\n```\n\nIn
      this template, `[sedentary](energized)`, `[tired](tired)`, `[calm](calm)`, `[curious](curious)`,
      or `[happy](happy)` are placeholders. The user can be represented by `you`.\n\nTo
      populate the template, I would extract the user''s sentiment and rephrase it
      as one of the options you see:\n\n```\nHello, user! It''s nice to chat with
      you.\n\nAre you feeling:\n\n- [energized](energized)\n- [tired](tired)\n- [calm](calm)\n-
      [curious](curious)\n- [happy](happy)\n\nPlease choose one:\n```\n\nIf the user
      says \"I''m currently energized,\" the template becomes:\n\n```\nHello, user!
      It''s nice to chat with you.\n\nAre you feeling:\n\n- [energized](energized)\n\nPlease
      choose one:\n```\n\nOr if they say \"I''m feeling quite calm today,\" it would
      be:\n\n```\nHello, user! It''s nice to chat with you.\n\nAre you feeling:\n\n-
      [calm](calm)\n\nPlease choose one:\n```\n\nAnd this allows the conversation
      to be dynamically generated and personalized based on user input. In the context
      of an AI like me, this system enables a wide range of conversational adaptability.
      Isn''t it fascinating how templates can be used to structure and customize responses
      in such a flexible fashion?","logprobs":null,"finish_reason":"stop","stop_reason":null,"prompt_logprobs":null},{"index":2,"text":"Sure,
      I''d be happy to demonstrate chat templating with you. It''s a technique used
      in some AI models to structure responses in a more organized manner.\n\nLet''s
      say we have a basic conversation template for a restaurant review:\n\n\"Customer:
      I recently dined at [Establishment].\nAssistant: That sounds like a delightful
      experience! Here''s what you shared:\n\n''[Establishment]''\n''[Your detail
      about the atmosphere or service]''\n''[Your ratings on a scale of 1-5 for ambiance,
      service, food, and overall]''\n\nNow, let''s use this template for a specific
      example:\n\n**Customer:** I recently dined at ''The Gourmet Oven'' in downtown.\n\n**Assistant:**
      That sounds like a delightful experience! Here''s what you shared:\n\n''The
      Gourmet Oven''\n''The atmosphere was charming and inviting, perfect for a cozy
      dinner. The staff was incredibly welcoming and attentive.''\n\nNow, does this
      approach make sense for structuring conversations? Would you like another example
      or explain concepts related to chat templating?","logprobs":null,"finish_reason":"stop","stop_reason":null,"prompt_logprobs":null}],"usage":{"prompt_tokens":99,"total_tokens":1041,"completion_tokens":942,"prompt_tokens_details":null}}'
    headers:
      content-length:
      - '4140'
      content-type:
      - application/json
      date:
      - Sat, 15 Mar 2025 00:33:59 GMT
      server:
      - uvicorn
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"model":"granite3.2:2b","prompt":"<|start_of_role|>system<|end_of_role|>Knowledge
      Cutoff Date: April 2024.\nToday''s Date: March 14, 2025.\nYou are Granite, developed
      by IBM. You are a helpful AI assistant.<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>Hello,
      how are you?<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>I''m doing
      great. How can I help you today?<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>I''d
      like to show off how chat templating works!<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>","best_of":3,"max_tokens":1024,"n":3}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '574'
      content-type:
      - application/json
      host:
      - localhost:11434
      rits_api_key:
      - ollama
      user-agent:
      - AsyncOpenAI/Python 1.66.3
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.66.3
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.11
    method: POST
    uri: http://localhost:11434/v1/completions
  response:
    content: "{\"id\":\"cmpl-1becabccb4f1495ba95bc8ea258d2508\",\"object\":\"text_completion\",\"created\":1741998868,\"model\":\"granite3.2:2b\",\"choices\":[{\"index\":0,\"text\":\"Absolutely,
      I'd be happy to demonstrate chat templating with you! Here's a simple example:\\n\\nIn
      standard text-based conversation, we might say:\\n\\n**User:** \\\"Hi, what's
      the weather like today?\\\"\\n\\n**Assistant:** \\\"Hello! The forecast for
      today says it's mostly sunny with a high of 75\xB0F (24\xB0C) and a gentle breeze
      from the southwest.\\\"\\n\\nNow, let's enhance this with templating:\\n\\n```\\nGreeting:
      Hello!\\nQuestion: What's the weather like today?\\nResponse: The forecast indicates
      it's most-ly {weather_adjective} with a high of {high_temperature}\xB0{temperature_unit}
      and a gentle wind from {wind_direction}.#\\n```\\n\\nWhen we input the same
      question, we get:\\n\\n**User:** \\\"Hi, what's the weather like today?\\\"\\n\\n**Assistant:**
      \\\"Hello! The forecast for today says it's mostly {weather_adjective} with
      a high of {high_temperature}\xB0{temperature_unit} and a gentle wind from {wind_direction}.\\\"\\n\\nIn
      this setup, `{weather_adjective}`, `{high_temperature}`, `{temperature_unit}`,
      and `{wind_direction}` are placeholders that are dynamically filled with the
      appropriate weather details based on actual data.\\n\\nFor instance:\\n\\n**Actual
      Weather Data:**\\n- Adjective: Sunny\\n- High Temperature: 75\xB0F\\n- Temperature
      Unit: Fahrenheit\\n- Wind Direction: Southwest\\n\\n**Chatbot Response:**\\n\\\"Hello!
      The forecast for today says it's mostly sunny with a high of 75\xB0F Fahrenheit
      and a gentle wind from southwest.\\\"\\n\\nBy using a database or programmatically
      fetched weather APIs, these placeholders can be dynamically populated with real-time
      weather data. This method of templating not only enhances the user experience
      but also makes it easier to organize and update content. Is there any specific
      templating topic you'd like to explore further?\",\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null,\"prompt_logprobs\":null},{\"index\":1,\"text\":\"Absolutely,
      I'd be happy to demonstrate chat templating with you. In this format, you can
      input variables enclosed in double curly braces, like this: `{{variable_name}}`.
      I can then replace these with corresponding text or even data using a backend
      system or pre-defined responses.\\n\\nFor example, if you've set a variable
      named \\\"greeting\\\" with the value \\\"Hello, how are you?\\\", you could
      ask: \\\"What's your {{greeting}}?\\\"\\n\\nWhen I reply, it might look like:
      \\\"What's your `Hello, how are you?`?\\\"\\n\\nLet's try an example to see
      it in action. Please provide a variable or a simple template.\",\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null,\"prompt_logprobs\":null},{\"index\":2,\"text\":\"Absolutely!
      Chat templating allows us to construct responses dynamically using placeholders
      or variables. Here's an example:\\n\\n```\\nHello, {user_name}! Today is {day_of_week}.
      How can I assist you today?\\n```\\n\\nIn this template:\\n- `{user_name}` represents
      the user's input.\\n- `{day_of_week}` represents a predefined value (e.g., \\\"Monday\\\",
      \\\"Tuesday\\\", etc.).\\n\\nWhen the user interacts, I would fill in `{user_name}`
      with their input, and `{day_of_week}` with an appropriate day of the week. For
      instance, if you type \\\"John Doe\\\", the message would look like this:\\n\\n\\\"Hello,
      John Doe! Today is Monday. How can I assist you today?\\\"\\n\\nDoes that provide
      a good illustration of how chat templating works? Let's modify it to another
      scenario if you'd like.\",\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null,\"prompt_logprobs\":null}],\"usage\":{\"prompt_tokens\":99,\"total_tokens\":901,\"completion_tokens\":802,\"prompt_tokens_details\":null}}"
    headers:
      content-length:
      - '3643'
      content-type:
      - application/json
      date:
      - Sat, 15 Mar 2025 00:34:28 GMT
      server:
      - uvicorn
    http_version: HTTP/1.1
    status_code: 200
version: 1
