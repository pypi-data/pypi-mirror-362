"""hammad.genai.embedding_models.embedding_model_response"""

from typing import List, Literal

from pydantic import BaseModel

from ....types.base import BaseGenAIModelResponse

__all__ = (
    "Embedding",
    "EmbeddingUsage",
    "EmbeddingResponse",
)


class Embedding(BaseModel):
    embedding: List[float]
    """The embedding vector, which is a list of floats.

    The length of vector depends on the model as listed in the
    [embedding guide](https://platform.openai.com/docs/guides/embeddings).
    """

    index: int
    """The index of the embedding in the list of embeddings."""

    object: Literal["embedding"]
    """The object type, which is always "embedding"."""

    @property
    def dimensions(self) -> int:
        """The dimensions of the embedding."""
        return len(self.embedding)


class EmbeddingUsage(BaseModel):
    """Usage statistics for embedding requests."""

    prompt_tokens: int
    """The number of tokens used by the prompt."""

    total_tokens: int
    """The total number of tokens used by the request."""


class EmbeddingModelResponse(BaseGenAIModelResponse[List[Embedding]]):
    output: List[Embedding]
    """The list of embeddings generated by the model."""

    model: str
    """The name of the model used to generate the embedding."""

    object: Literal["list"]
    """The object type, which is always "list"."""

    usage: EmbeddingUsage
    """The usage information for the request."""

    @property
    def data(self) -> List[Embedding]:
        """The list of embeddings generated by the model."""
        return self.output

    @property
    def dimensions(self) -> int:
        """The dimensions of the embedding."""
        return len(self.output[0].embedding)

    def __str__(self) -> str:
        return (
            "EmbeddingModelResponse:\n"
            f">>> Model: {self.model}\n"
            f">>> Dimensions: {self.dimensions}\n"
            f">>> Usage: {self.usage}\n"
            f">>> Number of Generated Embeddings: {len(self.output)}\n"
        )
