"""Markdown formatter for folder contents."""

import datetime
from pathlib import Path
from typing import Optional

from pygments.lexers import guess_lexer_for_filename
from pygments.util import ClassNotFound

from ..__about__ import __version__
from ..utils.file_utils import get_language_from_extension


class MarkdownFormatter:
    """Formats folder contents as markdown."""

    def __init__(
        self,
        include_tree: bool = True,
        include_stats: bool = True,
        include_preamble: bool = True,
    ):
        self.include_tree = include_tree
        self.include_stats = include_stats
        self.include_preamble = include_preamble
        # We don't need pygments formatter for markdown output - we'll format manually

    def _generate_preamble(
        self, folder_path: Path, processing_stats: Optional[dict] = None
    ) -> str:
        """Generate preamble explaining what the output file contains."""
        folder_name = folder_path.name
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Get processing stats with defaults
        file_count = processing_stats.get("file_count", 0) if processing_stats else 0
        token_count = processing_stats.get("token_count", 0) if processing_stats else 0

        preamble = f"""<!--
This file was generated by folder2md4llms v{__version__}
Generated on: {timestamp}
Source: {folder_path}
Output format: Markdown
-->

# ðŸ“ Folder Analysis: {folder_name}

> **Generated by [folder2md4llms](https://github.com/henriqueslab/folder2md4llms)**
> This file contains a structured representation of the folder contents optimized for Large Language Model (LLM) consumption and analysis.

## ðŸ” About This Document

This document was automatically generated to provide a comprehensive overview of the folder structure, source code, and associated files. It's designed to:

- **Enable LLM Analysis**: Structured format for AI-powered code review, documentation, and analysis
- **Provide Context**: Complete folder snapshot with file relationships and dependencies
- **Support Development**: Quick reference for understanding codebase structure and content
- **Facilitate Collaboration**: Shareable format for code reviews and discussions

**Processing Details:**
- ðŸ“Š Files processed: {file_count:,}
- ðŸ”¢ Estimated tokens: {token_count:,}
- ðŸ“ Directory analyzed: `{folder_path}`
- â±ï¸ Generated: {timestamp}

---

"""
        return preamble

    def format_repository(
        self,
        repo_path: Path,
        tree_structure: Optional[str] = None,
        file_contents: Optional[dict[str, str]] = None,
        file_stats: Optional[dict] = None,
        binary_descriptions: Optional[dict[str, str]] = None,
        converted_docs: Optional[dict[str, str]] = None,
        chunked_files: Optional[dict[str, list]] = None,
        processing_stats: Optional[dict] = None,
    ) -> str:
        """Format the complete folder as markdown."""
        sections = []

        # Add preamble if enabled
        if self.include_preamble:
            sections.append(self._generate_preamble(repo_path, processing_stats))

        # Header (only if preamble is disabled)
        if not self.include_preamble:
            folder_name = repo_path.name
            sections.append(f"# Folder: {folder_name}")
            sections.append("")

        # Table of Contents
        sections.append("## ðŸ“‘ Table of Contents")
        if self.include_tree:
            sections.append("- [ðŸ“ Folder Structure](#-folder-structure)")
        if self.include_stats:
            sections.append("- [ðŸ“Š Folder Statistics](#-folder-statistics)")
        if file_contents:
            sections.append("- [ðŸ“„ Source Code](#-source-code)")
        if chunked_files:
            sections.append("- [ðŸ“„ Large Files (Chunked)](#-large-files-chunked)")
        if converted_docs:
            sections.append("- [ðŸ“‹ Documents](#-documents)")
        if binary_descriptions:
            sections.append("- [ðŸ”§ Binary Files & Assets](#-binary-files--assets)")
        sections.append("")

        # Folder Structure
        if self.include_tree and tree_structure:
            sections.append("## ðŸ“ Folder Structure")
            sections.append("```")
            sections.append(tree_structure)
            sections.append("```")
            sections.append("")

        # Folder Statistics
        if self.include_stats and file_stats:
            sections.append("## ðŸ“Š Folder Statistics")
            sections.append(self._format_stats(file_stats))
            sections.append("")

        # Source Code Files
        if file_contents:
            sections.append("## ðŸ“„ Source Code")
            sections.append("")
            for file_path, content in file_contents.items():
                sections.append(self._format_file_content(file_path, content))
                sections.append("")

        # Large Files (Chunked)
        if chunked_files:
            sections.append("## ðŸ“„ Large Files (Chunked)")
            sections.append("")
            sections.append(
                "*These files were too large to process as single units and have been split into chunks for better LLM processing.*"
            )
            sections.append("")
            for file_path, chunks in chunked_files.items():
                sections.append(self._format_chunked_file(file_path, chunks))
                sections.append("")

        # Converted Documents
        if converted_docs:
            sections.append("## ðŸ“‹ Documents")
            sections.append("")
            for file_path, content in converted_docs.items():
                sections.append(self._format_document_content(file_path, content))
                sections.append("")

        # Binary Files
        if binary_descriptions:
            sections.append("## ðŸ”§ Binary Files & Assets")
            sections.append("")
            for file_path, description in binary_descriptions.items():
                sections.append(self._format_binary_description(file_path, description))
                sections.append("")

        return "\n".join(sections)

    def _format_stats(self, stats: dict) -> str:
        """Format repository statistics."""
        lines = []

        # File counts
        lines.append("### File Counts")
        lines.append(f"- **Total Files:** {stats.get('total_files', 0)}")
        lines.append(f"- **Text Files:** {stats.get('text_files', 0)}")
        lines.append(f"- **Binary Files:** {stats.get('binary_files', 0)}")
        lines.append(f"- **Converted Documents:** {stats.get('converted_docs', 0)}")
        lines.append("")

        # Size information
        if "total_size" in stats:
            lines.append("### Size Information")
            lines.append(f"- **Total Size:** {self._format_size(stats['total_size'])}")
            lines.append(
                f"- **Text Content:** {self._format_size(stats.get('text_size', 0))}"
            )
            lines.append("")

        # Language breakdown
        if "languages" in stats:
            lines.append("### Languages")
            languages = stats["languages"]
            for lang, count in sorted(
                languages.items(), key=lambda x: x[1], reverse=True
            ):
                lines.append(f"- **{lang}:** {count} files")
            lines.append("")

        # Chunked files information
        if "chunked_files" in stats and stats["chunked_files"] > 0:
            lines.append("### Large Files Processing")
            lines.append(f"- **Chunked Files:** {stats['chunked_files']}")
            lines.append(f"- **Total Chunks:** {stats.get('streaming_chunks', 0)}")
            lines.append("")

        # Token estimation
        if "estimated_tokens" in stats:
            lines.append("### Token Estimation")
            lines.append(f"- **Estimated Tokens:** {stats['estimated_tokens']:,}")
            lines.append("")

        return "\n".join(lines)

    def _format_file_content(self, file_path: str, content: str) -> str:
        """Format a single file's content with syntax highlighting."""
        lines = []

        # File header
        lines.append(f"### ðŸ“„ `{file_path}`")
        lines.append("")

        # Detect language for syntax highlighting
        language = self._detect_language(file_path, content)

        # Add syntax-highlighted content
        if language:
            lines.append(f"```{language}")
        else:
            lines.append("```")

        lines.append(content.rstrip())
        lines.append("```")

        return "\n".join(lines)

    def _format_document_content(self, file_path: str, content: str) -> str:
        """Format a converted document's content."""
        lines = []

        # Document header
        lines.append(f"### ðŸ“‹ `{file_path}`")
        lines.append("")

        # Add converted content
        lines.append(content.rstrip())

        return "\n".join(lines)

    def _format_chunked_file(self, file_path: str, chunks: list) -> str:
        """Format a chunked file with multiple chunks."""
        lines = []

        # Get language for syntax highlighting
        language = self._detect_language(file_path, chunks[0] if chunks else "")

        # File header
        lines.append(f"### ðŸ“„ `{file_path}` (Chunked)")
        lines.append("")
        lines.append(f"*File split into {len(chunks)} chunks for processing*")
        lines.append("")

        # Process each chunk
        for i, chunk in enumerate(chunks, 1):
            lines.append(f"#### Chunk {i}/{len(chunks)}")
            lines.append("")

            # Add syntax highlighting
            if language:
                lines.append(f"```{language}")
            else:
                lines.append("```")

            # Add chunk content
            lines.append(chunk.rstrip())
            lines.append("```")
            lines.append("")

        return "\n".join(lines)

    def _format_binary_description(self, file_path: str, description: str) -> str:
        """Format a binary file description."""
        lines = []

        # Binary file header
        lines.append(f"### ðŸ”§ `{file_path}`")
        lines.append("")
        lines.append(description.rstrip())

        return "\n".join(lines)

    def _detect_language(self, file_path: str, content: str) -> Optional[str]:
        """Detect the programming language for syntax highlighting."""
        try:
            # Try to guess from filename
            lexer = guess_lexer_for_filename(file_path, content)
            return lexer.aliases[0] if lexer.aliases else None
        except ClassNotFound:
            # Fall back to extension-based detection
            return get_language_from_extension(Path(file_path).suffix.lower())

    def _format_size(self, size_bytes: int) -> str:
        """Format file size in human-readable format."""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"
