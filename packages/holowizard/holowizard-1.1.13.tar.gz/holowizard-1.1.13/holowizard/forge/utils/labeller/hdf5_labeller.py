# standard libraries
from pathlib import Path

# third party libraries
import numpy as np
import torch
import h5py

# local libraries
from .labeller import Labeller
from holowizard.forge.utils.datatypes import Pathlike, TensorComplex64, TensorFloat32
from holowizard.forge.experiment.setup import Setup
from holowizard.forge.experiment.probe import BeamConfig
import holowizard.forge.experiment as experiment


__all__ = [
    "HDF5Labeller",
]


class HDF5Labeller(Labeller):
    def __init__(
        self,
        output: Pathlike,
        dataset_name: str,
        num_samples: int,
        cache_size: int,
        detector_size: int,
        probe_size: int,
        store_hologram: bool,
        store_gt_hologram: bool,
        store_phantom: bool,
        store_probe: bool,
        store_flatfield: bool,
        store_polynomial: bool,
        store_setup: bool,
        override: bool,
        num_conditions: int = 0,
    ) -> None:
        """Writes generated data as hdf5 file.

        Args:
            output (Pathlike): Directory where the dataset is written to.
            dataset_name (str): Name of the data file.
            num_samples (int): Size of the dataset.
            cache_size (int): Number of elements that can be cached.
            detector_size (int): Size in pixel of the detector (and also of the hologram and phantom).
            probe_size (int): Size in pixel of the probe.
            store_hologram (bool): Store holograms.
            store_phantom (bool): Store phantoms.
            store_probe (bool): Store background illumination.
            store_flatfield (bool): Store multiplicative flatfield.
            store_polynomial (bool): Store polynomial.
            num_conditions (int, optional): Number of flat-fields generated by the flat-field generator as conditioning (further channels in the training of NNs). If 0, no further flat-fields will be loaded. The conditions will be added to the hologram stack
                        channels, store flat-fields as 2D images. The first dimension corresponds to the label. All
                        further channels are conditions for the training.
            store_setup (bool): Store simulation setup.
            override (bool): If True and the output exists, override it. Otherwise raise an exception.

        """
        super().__init__(
            output=Path(output) / f"{dataset_name}.hdf5",
            store_hologram=store_hologram,
            store_gt_hologram=store_gt_hologram,
            store_phantom=store_phantom,
            store_probe=store_probe,
            store_flatfield=store_flatfield,
            store_polynomial=store_polynomial,
            store_setup=store_setup,
            override=override,
        )
        self._num_samples = num_samples
        self._cache_size = cache_size
        self._detector_size = detector_size
        self._probe_size = probe_size
        self._num_conditions = num_conditions

        self._cache_pointer = 0  # idx of current element of caches
        self._output_pointer = 0  # number of elements written to output
        self._initialized = False  # flag if the hdf5-file was already initalized (_initialize_hdf5_file)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        self.flush()

    def update_dataset_size(self, new_size: int) -> None:
        if self.initialized:
            print("WARNING: Cannot change the dataset size anymore. The HDF5 file was already prepared.")
            return
        self._num_samples = new_size

    def _initialize_hdf5_file(self) -> None:
        if self.initialized:
            return

        self.hdf5 = h5py.File(self.output, "w")
        self.hdf5_images = self.hdf5.create_group("images")
        self.hdf5_metadata = None  # only create if needed
        if self.store_hologram:
            self._cached_holograms = torch.zeros(
                (self.cache_size, self.detector_size, self.detector_size), dtype=torch.float32
            )
            self.hdf5_ds_holograms = self.hdf5_images.create_dataset(
                "hologram",
                (self.num_samples, self.detector_size, self.detector_size),
                dtype=np.float32,
            )

        if self.store_gt_hologram:
            self._cached_gt_holograms = torch.zeros(
                (self.cache_size, self.detector_size, self.detector_size), dtype=torch.float32
            )
            self.hdf5_ds_gt_holograms = self.hdf5_images.create_dataset(
                "gt_hologram",
                (self.num_samples, self.detector_size, self.detector_size),
                dtype=np.float32,
            )

        if self.store_phantom:
            self.hdf5_ds_phantoms = self.hdf5_images.create_dataset(
                "phantoms",
                (self.num_samples, self.detector_size, self.detector_size),
                dtype=np.complex64,
            )
            self._cached_phantoms = torch.zeros(
                (self.cache_size, self.detector_size, self.detector_size), dtype=torch.complex64
            )

        if self.store_probe:
            dim = (self.probe_size, self.probe_size)
            self._cached_probes = torch.zeros((self.cache_size, *dim), dtype=torch.float32)
            self.hdf5_ds_probes = self.hdf5_images.create_dataset(
                "probe",
                (self.num_samples, *dim),
                dtype=np.float32,
            )

        if self.store_flatfield:
            dim = (self.detector_size, self.detector_size)  # 2D
            self._cached_flatfields = torch.zeros(
                (self.cache_size, *dim),
                dtype=torch.float32,
            )
            self.hdf5_ds_flatfields = self.hdf5_images.create_dataset(
                "flatfield",
                (self.num_samples, *dim),
                dtype=np.float32,
            )
        if self.num_conditions > 0:
            # store further conditions as 3D Tensor, independed of the number of conditions
            dim = (self.num_conditions, self.detector_size, self.detector_size)  # 3D
            self._cached_conditions = torch.zeros(
                (self.cache_size, *dim),
                dtype=torch.float32,
            )
            self.hdf5_ds_conditions = self.hdf5_images.create_dataset(
                "condition",
                (self.num_samples, *dim),
                dtype=np.float32,
            )

        if self.store_setup:
            self.setup_keys = experiment.GLOBAL_EXP_SETUP.as_dict().keys()  # just need the field names/ dict keys
            if self.hdf5_metadata is None:
                self.hdf5_metadata = self.hdf5.create_group("metadata")
            self.hdf5_setup = self.hdf5_metadata.create_group("setup")
            self._cached_setups = {key: torch.zeros(self.cache_size, dtype=torch.float32) for key in self.setup_keys}
            self.hdf5_ds_setups = {
                key: self.hdf5_setup.create_dataset(key, (self.num_samples,)) for key in self.setup_keys
            }

        if self.store_polynomial:
            self.polynomial_keys = BeamConfig().get_annotation()
            if self.hdf5_metadata is None:
                self.hdf5_metadata = self.hdf5.create_group("metadata")
            self.hdf5_beam_cfg = self.hdf5_metadata.create_group("beam_cfg")
            self._cached_beam_configs = {
                key: torch.zeros(self.cache_size, dtype=torch.float32) for key in self.polynomial_keys
            }
            self.hdf5_ds_beam_cfg = {
                key: self.hdf5_beam_cfg.create_dataset(key, (self.num_samples,)) for key in self.polynomial_keys
            }
        self._initialized = True

    def flush(self) -> None:
        if self.cache_pointer == 0:
            return

        lower, upper = self.output_pointer, self.output_pointer + self.cache_pointer
        if self._store_hologram:
            self.hdf5_ds_holograms[lower:upper, ...] = self._cached_holograms[: self.cache_pointer, ...]

        if self._store_gt_hologram:
            self.hdf5_ds_gt_holograms[lower:upper, ...] = self._cached_gt_holograms[: self.cache_pointer, ...]

        if self._store_phantom:
            self.hdf5_ds_phantoms[lower:upper, ...] = self._cached_phantoms[: self.cache_pointer, ...]

        if self._store_probe:
            self.hdf5_ds_probes[lower:upper, ...] = self._cached_probes[: self.cache_pointer, ...]

        if self._store_flatfield:
            self.hdf5_ds_flatfields[lower:upper, ...] = self._cached_flatfields[: self.cache_pointer, ...]

        if self.num_conditions > 0:
            self.hdf5_ds_conditions[lower:upper, ...] = self._cached_conditions[: self.cache_pointer, ...]

        if self._store_polynomial:
            for key in self.polynomial_keys:
                self.hdf5_ds_beam_cfg[key][lower:upper] = self._cached_beam_configs[key][: self.cache_pointer]

        if self._store_setup:
            for key in self.setup_keys:
                self.hdf5_ds_setups[key][lower:upper] = self._cached_setups[key][: self.cache_pointer]

        self.output_pointer += self.cache_pointer
        self.cache_pointer = 0  # reset cache pointer to first element

    def cache(
        self,
        hologram: TensorFloat32,
        gt_hologram: TensorFloat32,
        phantom: TensorComplex64,
        probe: TensorFloat32,
        flatfield: TensorFloat32,
        condition: TensorFloat32,
        beam_cfg: BeamConfig,
        setup: Setup,
    ) -> None:
        if not self.initialized:
            self._initialize_hdf5_file()

        self._cache_hologram(hologram)
        self._cache_gt_hologram(gt_hologram)
        self._cache_phantom(phantom)
        self._cache_probe(probe)
        self._cache_flatfield(flatfield)
        self._cache_condition(condition)
        self._cache_beam_cfg(beam_cfg)
        self._cache_setup(setup)
        self._cache_pointer += 1
        if self.cache_pointer % self.cache_size == 0:
            self.flush()

    def _cache_hologram(self, hologram: TensorFloat32) -> None:
        if self._store_hologram:
            self._cached_holograms[self._cache_pointer, ...] = hologram

    def _cache_gt_hologram(self, gt_hologram: TensorFloat32) -> None:
        if self._store_gt_hologram:
            self._cached_gt_holograms[self._cache_pointer, ...] = gt_hologram

    def _cache_phantom(self, phantom: TensorComplex64) -> None:
        if self._store_phantom:
            self._cached_phantoms[self._cache_pointer, ...] = phantom

    def _cache_probe(self, probe: TensorFloat32) -> None:
        if self._store_probe:
            self._cached_probes[self._cache_pointer, ...] = probe

    def _cache_flatfield(self, flatfield: TensorFloat32) -> None:
        if self._store_flatfield:
            self._cached_flatfields[self._cache_pointer, ...] = flatfield

    def _cache_condition(self, condition: TensorFloat32) -> None:
        if self.num_conditions > 0:
            self._cached_conditions[self._cache_pointer, ...] = condition

    def _cache_beam_cfg(self, beam_cfg: BeamConfig) -> None:
        if self._store_polynomial:
            for key in self.polynomial_keys:
                self._cached_beam_configs[key][self._cache_pointer] = beam_cfg.as_dict()[key]

    def _cache_setup(self, setup: Setup) -> None:
        if self._store_setup:
            for key in self.setup_keys:
                self._cached_setups[key][self._cache_pointer] = setup.as_dict()[key]

    @property
    def num_samples(self) -> int:
        return self._num_samples

    @property
    def cache_size(self) -> int:
        return self._cache_size

    @property
    def detector_size(self) -> int:
        return self._detector_size

    @property
    def probe_size(self) -> int:
        return self._probe_size

    @property
    def num_conditions(self) -> int:
        return self._num_conditions

    @property
    def cache_pointer(self) -> int:
        return self._cache_pointer

    @cache_pointer.setter
    def cache_pointer(self, val: int) -> None:
        if not isinstance(val, int):
            raise AttributeError(f"Cache pointer must be of type int, not: {type(val)}")
        self._cache_pointer = val

    @property
    def output_pointer(self) -> int:
        return self._output_pointer

    @output_pointer.setter
    def output_pointer(self, val: int) -> None:
        if not isinstance(val, int):
            raise AttributeError(f"Output pointer must be of type int, not: {type(val)}")
        self._output_pointer = val

    @property
    def initialized(self) -> int:
        return self._initialized
