# ğŸŒ Web Maestro - Comprehensive Examples & Recipes

Web Maestro is the AI-powered web automation engine that drives intelligent content extraction. This guide provides extensive examples of its capabilities and advanced usage patterns. ğŸš€

## ğŸ“‹ Table of Contents

- [ğŸ¯ Basic Web Extraction](#basic-web-extraction)
- [ğŸ•µï¸ AI Scout Integration](#ai-scout-integration)
- [ğŸ­ DOM Capture Strategies](#dom-capture-strategies)
- [âš™ï¸ Configuration & Profiles](#configuration--profiles)
- [ğŸ¨ Domain-Specific Extraction](#domain-specific-extraction)
- [ğŸ“ˆ Progressive Content Discovery](#progressive-content-discovery)
- [ğŸ­ Production Patterns](#production-patterns)
- [ğŸ§ª Advanced Techniques](#advanced-techniques)
- [ğŸ› ï¸ Custom Extensions](#custom-extensions)

## ğŸ¯ Basic Web Extraction

### ğŸŒ Simple Content Extraction

```python
from maestro.src.web_maestro.fetch import fetch_with_ai_scout
import asyncio

async def basic_extraction():
    """ğŸ¯ Basic web content extraction example."""

    result = await fetch_with_ai_scout(
        url="https://restaurant-example.com",
        extraction_goal="Extract menu items with prices"
    )

    print(f"ğŸ¯ Extraction completed!")
    print(f"ğŸ“Š Found {len(result.blocks)} content blocks")
    print(f"â±ï¸ Extraction time: {result.extraction_time:.2f}s")
    print(f"âœ… Success: {result.success}")

    # ğŸ“ Display content blocks
    for i, block in enumerate(result.blocks[:5], 1):
        print(f"\nğŸ“¦ Block {i}:")
        print(f"  ğŸ·ï¸ Type: {block.element_type}")
        print(f"  ğŸ“Š Confidence: {block.confidence:.2f}")
        print(f"  ğŸ“ Content: {block.content[:100]}...")
        print(f"  ğŸ¯ Source: {block.source_info.get('selector', 'unknown')}")

    return result

# ğŸš€ Run basic extraction
result = asyncio.run(basic_extraction())
```

### ğŸ” Multiple URL Extraction

```python
async def multi_url_extraction():
    """ğŸ“¦ Extract content from multiple URLs."""

    urls = [
        "https://restaurant1.com/menu",
        "https://restaurant2.com/food",
        "https://cafe.com/beverages"
    ]

    results = []

    for url in urls:
        print(f"ğŸŒ Processing: {url}")

        try:
            result = await fetch_with_ai_scout(
                url=url,
                extraction_goal="Extract menu items and prices",
                timeout=120
            )

            results.append({
                "url": url,
                "status": "success",
                "blocks_found": len(result.blocks),
                "extraction_time": result.extraction_time,
                "result": result
            })

            print(f"âœ… Success: {len(result.blocks)} blocks found")

        except Exception as e:
            print(f"âŒ Failed: {str(e)}")
            results.append({
                "url": url,
                "status": "failed",
                "error": str(e)
            })

    # ğŸ“Š Summary
    successful = len([r for r in results if r["status"] == "success"])
    print(f"\nğŸ“Š Summary: {successful}/{len(urls)} successful extractions")

    return results

# ğŸš€ Run multi-URL extraction
results = asyncio.run(multi_url_extraction())
```

## ğŸ•µï¸ AI Scout Integration

### ğŸ§  AI-Guided Navigation

```python
from maestro.src.web_maestro.agents.scout_bridge import LLMScoutBridge
from maestro.src.clients.portkey_tool_client import PortkeyToolClient

async def ai_scout_navigation():
    """ğŸ•µï¸ Example of AI Scout for intelligent navigation."""

    # ğŸ§  Initialize AI Scout
    client = PortkeyToolClient()
    scout = LLMScoutBridge(client=client)

    # ğŸ¯ Navigation context
    context = {
        "extraction_goal": "Find detailed wine menu with prices",
        "current_page_url": "https://restaurant.com/beverages",
        "page_title": "Beverage Menu",
        "discovered_content": ["beer list", "cocktails", "soft drinks"],
        "previous_actions": ["clicked_beverages_link"]
    }

    # ğŸ” Elements to evaluate
    elements = [
        {
            "text": "Wine Selection",
            "tag": "a",
            "href": "/wines",
            "class": "menu-link",
            "position": {"x": 200, "y": 150}
        },
        {
            "text": "Wine Cellar",
            "tag": "button",
            "data_action": "expand-wine-section",
            "class": "expandable-section",
            "position": {"x": 300, "y": 200}
        },
        {
            "text": "Download Wine List PDF",
            "tag": "a",
            "href": "/wine-list.pdf",
            "class": "download-link",
            "position": {"x": 400, "y": 100}
        }
    ]

    # ğŸ¤” Get AI decisions for each element
    for element in elements:
        decision = await scout.should_interact_with_element(
            element=element,
            context=context
        )

        print(f"ğŸ¯ Element: {element['text']}")
        print(f"ğŸ¤– Decision: {decision.action}")
        print(f"ğŸ§  Reasoning: {decision.reasoning}")
        print(f"ğŸ“Š Confidence: {decision.confidence:.2f}")
        print(f"ğŸ¯ Priority: {decision.priority}")
        print("---")

    return True

# ğŸš€ Run AI scout navigation
result = asyncio.run(ai_scout_navigation())
```

### ğŸ¯ Custom AI Scout Prompts

```python
async def custom_ai_scout():
    """ğŸ¨ Custom AI Scout with domain-specific prompts."""

    # ğŸ¯ Custom prompt for wine menu extraction
    wine_menu_prompt = """
    You are an expert sommelier and web navigation specialist.

    Your goal: Find comprehensive wine information including:
    - Wine names and vintages
    - Prices (bottle/glass)
    - Descriptions and tasting notes
    - Wine regions and varietals

    Prioritize:
    1. Links to dedicated wine sections
    2. Expandable wine menus
    3. PDF wine lists (often most comprehensive)
    4. Wine category tabs

    Avoid:
    - General beverage links
    - Non-alcoholic drinks
    - Restaurant info pages
    """

    client = PortkeyToolClient()
    scout = LLMScoutBridge(
        client=client,
        custom_prompt=wine_menu_prompt
    )

    # ğŸ· Wine-specific extraction
    result = await fetch_with_ai_scout(
        url="https://fine-dining.com/beverages",
        extraction_goal="Extract comprehensive wine menu with prices and descriptions",
        ai_scout=scout,
        domain_keywords=["wine", "vintage", "bottle", "glass", "sommelier"]
    )

    # ğŸ· Filter wine-related content
    wine_blocks = [
        block for block in result.blocks
        if any(keyword in block.content.lower()
               for keyword in ["wine", "vintage", "bottle", "cabernet", "chardonnay"])
    ]

    print(f"ğŸ· Found {len(wine_blocks)} wine-related content blocks")

    return wine_blocks

# ğŸš€ Run custom AI scout
wine_content = asyncio.run(custom_ai_scout())
```

## ğŸ­ DOM Capture Strategies

### ğŸ“‘ Tab Expansion Example

```python
from maestro.src.web_maestro.dom_capture.tab_expansion import expand_all_tabs

async def tab_expansion_example():
    """ğŸ“‘ Example of tab-based content discovery."""

    from maestro.src.web_maestro.browser import create_browser_session

    async with create_browser_session() as session:
        page = session.page

        # ğŸŒ Navigate to page with tabs
        await page.goto("https://restaurant.com/menu")

        # ğŸ“‘ Discover and expand all tabs
        tab_results = await expand_all_tabs(
            page=page,
            max_tabs=10,
            wait_after_click=2
        )

        print(f"ğŸ“‘ Found {len(tab_results)} tab sections:")

        for tab_info in tab_results:
            print(f"  ğŸ·ï¸ Tab: {tab_info['tab_text']}")
            print(f"  ğŸ“Š Content blocks: {len(tab_info['content_blocks'])}")
            print(f"  â±ï¸ Load time: {tab_info['load_time']:.2f}s")

            # ğŸ“ Show sample content
            if tab_info['content_blocks']:
                sample = tab_info['content_blocks'][0]
                print(f"  ğŸ“„ Sample: {sample.content[:80]}...")
            print("---")

    return tab_results

# ğŸš€ Run tab expansion
results = asyncio.run(tab_expansion_example())
```

### ğŸ” Menu & Navigation Expansion

```python
from maestro.src.web_maestro.dom_capture.expansion import expand_navigation_menus

async def menu_expansion_example():
    """ğŸ” Example of menu and navigation expansion."""

    from maestro.src.web_maestro.browser import create_browser_session

    async with create_browser_session() as session:
        page = session.page
        await page.goto("https://restaurant.com")

        # ğŸ” Expand all navigation menus
        expansion_results = await expand_navigation_menus(
            page=page,
            include_hamburger=True,
            include_dropdowns=True,
            include_mega_menus=True
        )

        print(f"ğŸ” Expanded {len(expansion_results)} menu systems:")

        for menu_info in expansion_results:
            print(f"  ğŸ·ï¸ Menu Type: {menu_info['menu_type']}")
            print(f"  ğŸ¯ Trigger: {menu_info['trigger_element']}")
            print(f"  ğŸ“Š Items Found: {len(menu_info['menu_items'])}")

            # ğŸ“ Show menu items
            for item in menu_info['menu_items'][:3]:
                print(f"    - {item['text']} -> {item.get('href', 'no link')}")

            if len(menu_info['menu_items']) > 3:
                print(f"    ... and {len(menu_info['menu_items']) - 3} more items")
            print("---")

    return expansion_results

# ğŸš€ Run menu expansion
results = asyncio.run(menu_expansion_example())
```

### ğŸ‘† Hover Exploration

```python
from maestro.src.web_maestro.dom_capture.exploration import explore_hover_content

async def hover_exploration_example():
    """ğŸ‘† Example of hover-based content discovery."""

    from maestro.src.web_maestro.browser import create_browser_session

    async with create_browser_session() as session:
        page = session.page
        await page.goto("https://restaurant.com/menu")

        # ğŸ‘† Explore hover interactions
        hover_results = await explore_hover_content(
            page=page,
            max_elements=20,
            hover_duration=1.5,
            wait_for_content=2.0
        )

        print(f"ğŸ‘† Explored {len(hover_results)} hover interactions:")

        for hover_info in hover_results:
            if hover_info['new_content_found']:
                print(f"  ğŸ¯ Element: {hover_info['element_text']}")
                print(f"  ğŸ“ Content Type: {hover_info['content_type']}")
                print(f"  ğŸ“Š Content Length: {len(hover_info['revealed_content'])}")
                print(f"  ğŸ” Content: {hover_info['revealed_content'][:100]}...")
                print("---")

    return hover_results

# ğŸš€ Run hover exploration
results = asyncio.run(hover_exploration_example())
```

### ğŸ–±ï¸ Universal Clicking Strategy

```python
from maestro.src.web_maestro.dom_capture.universal_capture import capture_all_content

async def universal_clicking_example():
    """ğŸ–±ï¸ Example of systematic universal clicking."""

    from maestro.src.web_maestro.config.base import STANDARD_CONFIG

    # ğŸ›ï¸ Configure universal capture
    capture_config = STANDARD_CONFIG.copy()
    capture_config.update({
        "max_interactions": 30,
        "click_delay_ms": 500,
        "stability_timeout": 3,
        "enable_hover_exploration": True,
        "enable_tab_expansion": True
    })

    result = await fetch_with_ai_scout(
        url="https://complex-restaurant.com/menu",
        extraction_goal="Extract all menu content from complex interface",
        config=capture_config
    )

    # ğŸ“Š Analyze interaction results
    interaction_summary = result.metadata.get("interaction_summary", {})

    print(f"ğŸ–±ï¸ Universal Clicking Results:")
    print(f"  ğŸ“Š Total Interactions: {interaction_summary.get('total_clicks', 0)}")
    print(f"  âœ… Successful Clicks: {interaction_summary.get('successful_clicks', 0)}")
    print(f"  ğŸ“‘ Tabs Expanded: {interaction_summary.get('tabs_expanded', 0)}")
    print(f"  ğŸ” Menus Opened: {interaction_summary.get('menus_opened', 0)}")
    print(f"  ğŸ‘† Hover Discoveries: {interaction_summary.get('hover_discoveries', 0)}")
    print(f"  ğŸ“Š Content Blocks Found: {len(result.blocks)}")

    return result

# ğŸš€ Run universal clicking
result = asyncio.run(universal_clicking_example())
```

## âš™ï¸ Configuration & Profiles

### âš¡ Fast Configuration

```python
from maestro.src.web_maestro.config.base import FAST_CONFIG

async def fast_extraction_example():
    """âš¡ Quick extraction with minimal interactions."""

    # ğŸ¯ Fast configuration for rapid extraction
    fast_config = FAST_CONFIG.copy()
    fast_config.update({
        "max_interactions": 5,
        "stability_timeout": 1,
        "enable_hover_exploration": False,
        "enable_ai_scout": False,  # Use rule-based decisions
        "timeout_seconds": 30
    })

    start_time = time.time()

    result = await fetch_with_ai_scout(
        url="https://simple-restaurant.com/menu",
        extraction_goal="Quick menu extraction",
        config=fast_config
    )

    end_time = time.time()

    print(f"âš¡ Fast Extraction Results:")
    print(f"  â±ï¸ Total Time: {end_time - start_time:.2f}s")
    print(f"  ğŸ“Š Blocks Found: {len(result.blocks)}")
    print(f"  ğŸ¯ Extraction Speed: {len(result.blocks)/(end_time - start_time):.1f} blocks/sec")
    print(f"  ğŸ’¾ Memory Efficient: {fast_config.get('memory_optimized', True)}")

    return result

# ğŸš€ Run fast extraction
result = asyncio.run(fast_extraction_example())
```

### ğŸ” Thorough Configuration

```python
from maestro.src.web_maestro.config.base import THOROUGH_CONFIG

async def thorough_extraction_example():
    """ğŸ” Comprehensive extraction with maximum coverage."""

    # ğŸ¯ Thorough configuration for complete extraction
    thorough_config = THOROUGH_CONFIG.copy()
    thorough_config.update({
        "max_interactions": 100,
        "stability_timeout": 8,
        "enable_hover_exploration": True,
        "enable_ai_scout": True,
        "enable_tab_expansion": True,
        "enable_menu_expansion": True,
        "max_scroll_attempts": 5,
        "wait_for_load": True,
        "timeout_seconds": 600
    })

    result = await fetch_with_ai_scout(
        url="https://complex-restaurant.com/menu",
        extraction_goal="Extract absolutely everything - menus, specials, wine lists, all content",
        config=thorough_config
    )

    print(f"ğŸ” Thorough Extraction Results:")
    print(f"  ğŸ“Š Total Blocks: {len(result.blocks)}")
    print(f"  â±ï¸ Extraction Time: {result.extraction_time:.2f}s")
    print(f"  ğŸ¯ High Confidence Blocks: {len([b for b in result.blocks if b.confidence > 0.8])}")
    print(f"  ğŸ“‘ Content Types Found: {len(set(b.element_type for b in result.blocks))}")

    # ğŸ“Š Content analysis
    content_types = {}
    for block in result.blocks:
        content_types[block.element_type] = content_types.get(block.element_type, 0) + 1

    print(f"\nğŸ“Š Content Type Breakdown:")
    for content_type, count in sorted(content_types.items()):
        print(f"  {content_type}: {count} blocks")

    return result

# ğŸš€ Run thorough extraction
result = asyncio.run(thorough_extraction_example())
```

### âš–ï¸ Balanced Configuration

```python
from maestro.src.web_maestro.config.base import STANDARD_CONFIG

async def balanced_extraction_example():
    """âš–ï¸ Balanced approach for most use cases."""

    # ğŸ¯ Standard configuration with custom tweaks
    balanced_config = STANDARD_CONFIG.copy()
    balanced_config.update({
        "max_interactions": 25,
        "stability_timeout": 4,
        "enable_hover_exploration": True,
        "enable_ai_scout": True,
        "ai_scout_confidence_threshold": 0.7,
        "max_concurrent_interactions": 3,
        "timeout_seconds": 180
    })

    urls = [
        "https://restaurant1.com/menu",
        "https://restaurant2.com/food",
        "https://restaurant3.com/dining"
    ]

    results = []

    for url in urls:
        print(f"âš–ï¸ Processing {url} with balanced config...")

        result = await fetch_with_ai_scout(
            url=url,
            extraction_goal="Extract menu content efficiently",
            config=balanced_config
        )

        results.append({
            "url": url,
            "blocks_found": len(result.blocks),
            "extraction_time": result.extraction_time,
            "efficiency_score": len(result.blocks) / result.extraction_time
        })

        print(f"  ğŸ“Š Found {len(result.blocks)} blocks in {result.extraction_time:.1f}s")

    # ğŸ“Š Performance summary
    avg_efficiency = sum(r["efficiency_score"] for r in results) / len(results)
    print(f"\nğŸ“Š Balanced Config Performance:")
    print(f"  ğŸ¯ Average Efficiency: {avg_efficiency:.1f} blocks/second")
    print(f"  âš–ï¸ Good balance of speed and comprehensiveness")

    return results

# ğŸš€ Run balanced extraction
results = asyncio.run(balanced_extraction_example())
```

## ğŸ¨ Domain-Specific Extraction

### ğŸ½ï¸ Restaurant Domain

```python
from maestro.src.web_maestro.domains.domain_config import create_domain_config

async def restaurant_domain_example():
    """ğŸ½ï¸ Restaurant-optimized extraction."""

    # ğŸ¯ Restaurant domain configuration
    restaurant_config = create_domain_config(
        domain_type="restaurant",
        custom_keywords=[
            "menu", "food", "dining", "cuisine", "special", "daily",
            "appetizer", "entree", "dessert", "beverage", "wine",
            "price", "dollar", "$", "chef", "seasonal"
        ],
        navigation_patterns=[
            "menu", "food", "dining", "order", "delivery",
            "takeout", "specials", "wine", "drinks"
        ],
        quality_threshold=0.8
    )

    result = await fetch_with_ai_scout(
        url="https://fine-dining-restaurant.com",
        extraction_goal="Extract comprehensive restaurant menu with all sections",
        domain_config=restaurant_config,
        config=THOROUGH_CONFIG
    )

    # ğŸ½ï¸ Analyze restaurant-specific content
    menu_blocks = []
    price_blocks = []
    special_blocks = []

    for block in result.blocks:
        content_lower = block.content.lower()

        if any(keyword in content_lower for keyword in ["appetizer", "entree", "dessert", "main"]):
            menu_blocks.append(block)

        if "$" in block.content or any(price_term in content_lower for price_term in ["price", "cost", "dollar"]):
            price_blocks.append(block)

        if any(special_term in content_lower for special_term in ["special", "daily", "chef", "seasonal"]):
            special_blocks.append(block)

    print(f"ğŸ½ï¸ Restaurant Content Analysis:")
    print(f"  ğŸ“‹ Menu Blocks: {len(menu_blocks)}")
    print(f"  ğŸ’° Price Blocks: {len(price_blocks)}")
    print(f"  â­ Special Blocks: {len(special_blocks)}")
    print(f"  ğŸ“Š Total Blocks: {len(result.blocks)}")

    return {
        "menu_content": menu_blocks,
        "pricing_info": price_blocks,
        "specials": special_blocks,
        "full_result": result
    }

# ğŸš€ Run restaurant domain extraction
result = asyncio.run(restaurant_domain_example())
```

### ğŸ›’ E-commerce Domain

```python
async def ecommerce_domain_example():
    """ğŸ›’ E-commerce optimized extraction."""

    # ğŸ¯ E-commerce domain configuration
    ecommerce_config = create_domain_config(
        domain_type="ecommerce",
        custom_keywords=[
            "product", "price", "buy", "cart", "checkout", "shipping",
            "review", "rating", "stock", "sale", "discount", "offer"
        ],
        navigation_patterns=[
            "shop", "products", "catalog", "categories", "search",
            "cart", "checkout", "account"
        ],
        quality_threshold=0.75
    )

    result = await fetch_with_ai_scout(
        url="https://example-store.com/category/electronics",
        extraction_goal="Extract product catalog with prices and descriptions",
        domain_config=ecommerce_config
    )

    # ğŸ›’ Analyze e-commerce content
    product_blocks = []
    pricing_blocks = []
    review_blocks = []

    for block in result.blocks:
        content_lower = block.content.lower()

        if any(keyword in content_lower for keyword in ["product", "item", "model"]):
            product_blocks.append(block)

        if any(price_indicator in block.content for price_indicator in ["$", "â‚¬", "Â£", "price"]):
            pricing_blocks.append(block)

        if any(review_term in content_lower for review_term in ["review", "rating", "star", "feedback"]):
            review_blocks.append(block)

    print(f"ğŸ›’ E-commerce Content Analysis:")
    print(f"  ğŸ“¦ Product Blocks: {len(product_blocks)}")
    print(f"  ğŸ’° Pricing Blocks: {len(pricing_blocks)}")
    print(f"  â­ Review Blocks: {len(review_blocks)}")

    return {
        "products": product_blocks,
        "pricing": pricing_blocks,
        "reviews": review_blocks,
        "full_result": result
    }

# ğŸš€ Run e-commerce extraction
result = asyncio.run(ecommerce_domain_example())
```

### ğŸ“° News Domain

```python
async def news_domain_example():
    """ğŸ“° News/content optimized extraction."""

    # ğŸ¯ News domain configuration
    news_config = create_domain_config(
        domain_type="news",
        custom_keywords=[
            "article", "news", "story", "headline", "breaking",
            "reporter", "author", "published", "updated", "source"
        ],
        navigation_patterns=[
            "news", "articles", "stories", "breaking", "latest",
            "categories", "sections", "archive"
        ],
        quality_threshold=0.85
    )

    result = await fetch_with_ai_scout(
        url="https://news-website.com/technology",
        extraction_goal="Extract news articles with headlines, content, and metadata",
        domain_config=news_config
    )

    # ğŸ“° Analyze news content
    headline_blocks = []
    article_blocks = []
    metadata_blocks = []

    for block in result.blocks:
        content_lower = block.content.lower()

        if block.element_type in ["h1", "h2", "h3"] and len(block.content) < 200:
            headline_blocks.append(block)

        if len(block.content) > 200 and any(article_indicator in content_lower
                                           for article_indicator in ["article", "story", "report"]):
            article_blocks.append(block)

        if any(meta_term in content_lower for meta_term in ["published", "author", "date", "source"]):
            metadata_blocks.append(block)

    print(f"ğŸ“° News Content Analysis:")
    print(f"  ğŸ“° Headlines: {len(headline_blocks)}")
    print(f"  ğŸ“„ Articles: {len(article_blocks)}")
    print(f"  ğŸ“Š Metadata: {len(metadata_blocks)}")

    return {
        "headlines": headline_blocks,
        "articles": article_blocks,
        "metadata": metadata_blocks,
        "full_result": result
    }

# ğŸš€ Run news extraction
result = asyncio.run(news_domain_example())
```

## ğŸ“ˆ Progressive Content Discovery

### ğŸ”„ Multi-Phase Extraction

```python
async def multi_phase_extraction():
    """ğŸ”„ Progressive extraction with multiple phases."""

    phases = [
        {
            "name": "Quick Scan",
            "config": FAST_CONFIG,
            "goal": "Initial content discovery"
        },
        {
            "name": "Tab Expansion",
            "config": {**STANDARD_CONFIG, "focus_on_tabs": True},
            "goal": "Discover tabbed content"
        },
        {
            "name": "Menu Exploration",
            "config": {**STANDARD_CONFIG, "focus_on_menus": True},
            "goal": "Navigate through menu systems"
        },
        {
            "name": "Deep Dive",
            "config": THOROUGH_CONFIG,
            "goal": "Comprehensive content extraction"
        }
    ]

    url = "https://complex-restaurant.com"
    all_content = []

    for phase in phases:
        print(f"ğŸ”„ Phase: {phase['name']}")

        result = await fetch_with_ai_scout(
            url=url,
            extraction_goal=phase['goal'],
            config=phase['config']
        )

        phase_content = [
            block for block in result.blocks
            if block not in all_content  # Avoid duplicates
        ]

        all_content.extend(phase_content)

        print(f"  ğŸ“Š New content blocks: {len(phase_content)}")
        print(f"  ğŸ“ˆ Total content blocks: {len(all_content)}")
        print(f"  â±ï¸ Phase time: {result.extraction_time:.2f}s")
        print("---")

    print(f"ğŸ¯ Multi-Phase Extraction Complete:")
    print(f"  ğŸ“Š Total unique blocks: {len(all_content)}")
    print(f"  ğŸ­ Content diversity: {len(set(b.element_type for b in all_content))} types")

    return all_content

# ğŸš€ Run multi-phase extraction
content = asyncio.run(multi_phase_extraction())
```

### ğŸ“Š Incremental Content Analysis

```python
async def incremental_content_analysis():
    """ğŸ“Š Analyze content as it's discovered."""

    url = "https://restaurant.com/menu"
    discovered_content = []

    # ğŸ“ˆ Progress callback function
    def content_discovered_callback(new_blocks):
        """ğŸ“Š Analyze content as it's discovered."""
        discovered_content.extend(new_blocks)

        # ğŸ“Š Real-time analysis
        menu_items = len([b for b in new_blocks if "price" in b.content.lower()])
        high_confidence = len([b for b in new_blocks if b.confidence > 0.8])

        print(f"ğŸ“Š New content discovered:")
        print(f"  ğŸ“‹ Menu items: {menu_items}")
        print(f"  ğŸ¯ High confidence: {high_confidence}")
        print(f"  ğŸ“ˆ Total discovered: {len(discovered_content)}")

    # ğŸ”„ Extraction with progress tracking
    result = await fetch_with_ai_scout(
        url=url,
        extraction_goal="Extract menu with real-time analysis",
        progress_callback=content_discovered_callback,
        config=STANDARD_CONFIG
    )

    # ğŸ“Š Final analysis
    print(f"\nğŸ¯ Final Content Analysis:")

    # Group by confidence levels
    confidence_groups = {
        "high": [b for b in discovered_content if b.confidence > 0.8],
        "medium": [b for b in discovered_content if 0.5 < b.confidence <= 0.8],
        "low": [b for b in discovered_content if b.confidence <= 0.5]
    }

    for level, blocks in confidence_groups.items():
        print(f"  ğŸ“Š {level.title()} confidence: {len(blocks)} blocks")

    return discovered_content

# ğŸš€ Run incremental analysis
content = asyncio.run(incremental_content_analysis())
```

## ğŸ­ Production Patterns

### ğŸ”„ Retry and Fallback Strategies

```python
import time
from typing import Dict, Any

async def robust_extraction_with_fallbacks(url: str) -> Dict[str, Any]:
    """ğŸ›¡ï¸ Production-ready extraction with fallback strategies."""

    strategies = [
        {
            "name": "Fast Attempt",
            "config": FAST_CONFIG,
            "timeout": 60,
            "max_retries": 1
        },
        {
            "name": "Standard Attempt",
            "config": STANDARD_CONFIG,
            "timeout": 120,
            "max_retries": 2
        },
        {
            "name": "Thorough Attempt",
            "config": THOROUGH_CONFIG,
            "timeout": 300,
            "max_retries": 1
        }
    ]

    for strategy in strategies:
        for attempt in range(strategy["max_retries"] + 1):
            try:
                print(f"ğŸ”„ {strategy['name']} - Attempt {attempt + 1}")

                start_time = time.time()

                result = await fetch_with_ai_scout(
                    url=url,
                    extraction_goal="Extract content with fallback strategy",
                    config=strategy["config"],
                    timeout=strategy["timeout"]
                )

                execution_time = time.time() - start_time

                # âœ… Success criteria
                if (len(result.blocks) > 0 and
                    result.success and
                    execution_time < strategy["timeout"]):

                    print(f"âœ… Success with {strategy['name']}")
                    return {
                        "status": "success",
                        "strategy_used": strategy["name"],
                        "attempt_number": attempt + 1,
                        "execution_time": execution_time,
                        "blocks_found": len(result.blocks),
                        "result": result
                    }

            except Exception as e:
                print(f"âŒ {strategy['name']} failed: {str(e)}")

                # ğŸ”„ Wait before retry
                if attempt < strategy["max_retries"]:
                    wait_time = (attempt + 1) * 2  # Exponential backoff
                    print(f"â³ Waiting {wait_time}s before retry...")
                    await asyncio.sleep(wait_time)

    # ğŸš¨ All strategies failed
    return {
        "status": "failed",
        "error": "All extraction strategies exhausted",
        "strategies_attempted": len(strategies)
    }

# ğŸš€ Run robust extraction
result = asyncio.run(robust_extraction_with_fallbacks("https://difficult-site.com"))
```

### ğŸ“Š Performance Monitoring

```python
import json
from datetime import datetime
from collections import defaultdict

class WebMaestroMonitor:
    """ğŸ“Š Production monitoring for Web Maestro operations."""

    def __init__(self):
        self.metrics = defaultdict(list)
        self.start_time = time.time()

    def record_extraction(self, url: str, result: Dict[str, Any],
                         strategy: str, execution_time: float):
        """ğŸ“ˆ Record extraction metrics."""

        metric = {
            "timestamp": datetime.now().isoformat(),
            "url": url,
            "strategy": strategy,
            "execution_time": execution_time,
            "success": result.get("status") == "success",
            "blocks_found": result.get("blocks_found", 0),
            "confidence_avg": self._calculate_avg_confidence(result),
            "content_types": self._analyze_content_types(result)
        }

        self.metrics["extractions"].append(metric)

    def _calculate_avg_confidence(self, result: Dict[str, Any]) -> float:
        """ğŸ“Š Calculate average confidence score."""
        if "result" in result and hasattr(result["result"], "blocks"):
            blocks = result["result"].blocks
            if blocks:
                return sum(block.confidence for block in blocks) / len(blocks)
        return 0.0

    def _analyze_content_types(self, result: Dict[str, Any]) -> Dict[str, int]:
        """ğŸ“Š Analyze content type distribution."""
        if "result" in result and hasattr(result["result"], "blocks"):
            blocks = result["result"].blocks
            types = defaultdict(int)
            for block in blocks:
                types[block.element_type] += 1
            return dict(types)
        return {}

    def get_performance_report(self) -> Dict[str, Any]:
        """ğŸ“Š Generate performance report."""
        extractions = self.metrics["extractions"]

        if not extractions:
            return {"error": "No extractions recorded"}

        # ğŸ“Š Calculate statistics
        total = len(extractions)
        successful = sum(1 for e in extractions if e["success"])
        success_rate = successful / total if total > 0 else 0

        execution_times = [e["execution_time"] for e in extractions]
        avg_time = sum(execution_times) / len(execution_times)

        # ğŸ“ˆ Strategy performance
        strategy_stats = defaultdict(lambda: {"total": 0, "successful": 0, "avg_time": 0})

        for extraction in extractions:
            strategy = extraction["strategy"]
            strategy_stats[strategy]["total"] += 1
            if extraction["success"]:
                strategy_stats[strategy]["successful"] += 1
            strategy_stats[strategy]["avg_time"] += extraction["execution_time"]

        # ğŸ“Š Finalize strategy stats
        for strategy, stats in strategy_stats.items():
            stats["success_rate"] = stats["successful"] / stats["total"]
            stats["avg_time"] /= stats["total"]

        return {
            "summary": {
                "total_extractions": total,
                "success_rate": success_rate,
                "average_execution_time": avg_time,
                "uptime_hours": (time.time() - self.start_time) / 3600
            },
            "strategy_performance": dict(strategy_stats),
            "recent_extractions": extractions[-10:]  # Last 10
        }

    def save_report(self, filename: str):
        """ğŸ’¾ Save performance report to file."""
        report = self.get_performance_report()
        with open(filename, 'w') as f:
            json.dump(report, f, indent=2)
        print(f"ğŸ“Š Performance report saved to {filename}")

# ğŸš€ Usage example
async def monitored_extraction_example():
    """ğŸ“Š Example with performance monitoring."""

    monitor = WebMaestroMonitor()

    test_urls = [
        "https://restaurant1.com/menu",
        "https://restaurant2.com/food",
        "https://restaurant3.com/dining"
    ]

    for url in test_urls:
        print(f"ğŸŒ Processing: {url}")

        start_time = time.time()
        result = await robust_extraction_with_fallbacks(url)
        execution_time = time.time() - start_time

        # ğŸ“Š Record metrics
        monitor.record_extraction(
            url=url,
            result=result,
            strategy=result.get("strategy_used", "unknown"),
            execution_time=execution_time
        )

    # ğŸ“Š Generate report
    report = monitor.get_performance_report()
    print(f"\nğŸ“Š Performance Report:")
    print(f"  ğŸ¯ Success Rate: {report['summary']['success_rate']:.2%}")
    print(f"  â±ï¸ Avg Time: {report['summary']['average_execution_time']:.2f}s")
    print(f"  ğŸš€ Total Extractions: {report['summary']['total_extractions']}")

    # ğŸ’¾ Save detailed report
    monitor.save_report("web_maestro_performance.json")

    return report

# ğŸš€ Run monitored extraction
report = asyncio.run(monitored_extraction_example())
```

## ğŸ§ª Advanced Techniques

### ğŸ¯ Content Quality Assessment

```python
async def content_quality_assessment():
    """ğŸ¯ Advanced content quality assessment."""

    url = "https://restaurant.com/menu"

    result = await fetch_with_ai_scout(
        url=url,
        extraction_goal="Extract menu content with quality assessment",
        config=THOROUGH_CONFIG
    )

    # ğŸ¯ Quality assessment criteria
    quality_metrics = {
        "high_confidence": 0,
        "has_pricing": 0,
        "detailed_descriptions": 0,
        "structured_content": 0,
        "relevant_keywords": 0
    }

    relevant_keywords = ["menu", "food", "price", "dish", "appetizer", "entree", "dessert"]

    for block in result.blocks:
        # ğŸ“Š High confidence content
        if block.confidence > 0.8:
            quality_metrics["high_confidence"] += 1

        # ğŸ’° Pricing information
        if "$" in block.content or "price" in block.content.lower():
            quality_metrics["has_pricing"] += 1

        # ğŸ“ Detailed descriptions (longer content)
        if len(block.content) > 50:
            quality_metrics["detailed_descriptions"] += 1

        # ğŸ—ï¸ Structured content (specific HTML elements)
        if block.element_type in ["div", "li", "td", "article"]:
            quality_metrics["structured_content"] += 1

        # ğŸ¯ Relevant keywords
        if any(keyword in block.content.lower() for keyword in relevant_keywords):
            quality_metrics["relevant_keywords"] += 1

    # ğŸ“Š Calculate quality score
    total_blocks = len(result.blocks)
    quality_score = sum(quality_metrics.values()) / (total_blocks * len(quality_metrics))

    print(f"ğŸ¯ Content Quality Assessment:")
    print(f"  ğŸ“Š Total Blocks: {total_blocks}")
    print(f"  ğŸ¯ High Confidence: {quality_metrics['high_confidence']} ({quality_metrics['high_confidence']/total_blocks:.1%})")
    print(f"  ğŸ’° Has Pricing: {quality_metrics['has_pricing']} ({quality_metrics['has_pricing']/total_blocks:.1%})")
    print(f"  ğŸ“ Detailed Descriptions: {quality_metrics['detailed_descriptions']} ({quality_metrics['detailed_descriptions']/total_blocks:.1%})")
    print(f"  ğŸ—ï¸ Structured Content: {quality_metrics['structured_content']} ({quality_metrics['structured_content']/total_blocks:.1%})")
    print(f"  ğŸ¯ Relevant Keywords: {quality_metrics['relevant_keywords']} ({quality_metrics['relevant_keywords']/total_blocks:.1%})")
    print(f"  ğŸ† Overall Quality Score: {quality_score:.2f}")

    return {
        "quality_metrics": quality_metrics,
        "quality_score": quality_score,
        "total_blocks": total_blocks,
        "result": result
    }

# ğŸš€ Run quality assessment
assessment = asyncio.run(content_quality_assessment())
```

### ğŸ” Content Deduplication

```python
import hashlib
from typing import List, Set

async def content_deduplication_example():
    """ğŸ” Advanced content deduplication techniques."""

    result = await fetch_with_ai_scout(
        url="https://restaurant.com/menu",
        extraction_goal="Extract content with deduplication",
        config=THOROUGH_CONFIG
    )

    # ğŸ” Different deduplication strategies
    exact_duplicates: Set[str] = set()
    content_hashes: Set[str] = set()
    semantic_groups: Dict[str, List] = defaultdict(list)

    unique_blocks = []
    duplicate_count = 0

    for block in result.blocks:
        content = block.content.strip()

        # ğŸ¯ Exact duplicate detection
        if content in exact_duplicates:
            duplicate_count += 1
            continue
        exact_duplicates.add(content)

        # ğŸ” Hash-based deduplication (normalize whitespace)
        normalized_content = " ".join(content.split())
        content_hash = hashlib.md5(normalized_content.encode()).hexdigest()

        if content_hash in content_hashes:
            duplicate_count += 1
            continue
        content_hashes.add(content_hash)

        # ğŸ“Š Semantic grouping (by content length and type)
        semantic_key = f"{block.element_type}_{len(content)//50*50}"  # Group by type and length ranges
        semantic_groups[semantic_key].append(block)

        unique_blocks.append(block)

    print(f"ğŸ” Content Deduplication Results:")
    print(f"  ğŸ“Š Original Blocks: {len(result.blocks)}")
    print(f"  âœ¨ Unique Blocks: {len(unique_blocks)}")
    print(f"  ğŸ—‘ï¸ Duplicates Removed: {duplicate_count}")
    print(f"  ğŸ“ˆ Deduplication Rate: {duplicate_count/len(result.blocks):.1%}")

    # ğŸ“Š Semantic group analysis
    print(f"\nğŸ“Š Semantic Groups:")
    for group_key, blocks in semantic_groups.items():
        if len(blocks) > 1:
            print(f"  ğŸ·ï¸ {group_key}: {len(blocks)} similar blocks")

    return {
        "original_count": len(result.blocks),
        "unique_blocks": unique_blocks,
        "duplicates_removed": duplicate_count,
        "semantic_groups": semantic_groups
    }

# ğŸš€ Run deduplication
result = asyncio.run(content_deduplication_example())
```

## ğŸ› ï¸ Custom Extensions

### ğŸ¨ Custom DOM Capture Strategy

```python
from maestro.src.web_maestro.dom_capture.capture import CaptureStrategy

class CustomMenuCaptureStrategy(CaptureStrategy):
    """ğŸ¨ Custom capture strategy for restaurant menus."""

    async def capture_content(self, page, config):
        """ğŸ½ï¸ Custom menu-focused capture logic."""

        # ğŸ” Look for menu-specific elements first
        menu_selectors = [
            ".menu-item", ".food-item", ".dish",
            "[data-menu]", "[data-food]", ".restaurant-menu",
            ".menu-section", ".food-category"
        ]

        captured_blocks = []

        for selector in menu_selectors:
            try:
                elements = await page.query_selector_all(selector)

                for element in elements:
                    # ğŸ“ Extract element content
                    content = await element.text_content()
                    if content and len(content.strip()) > 5:

                        # ğŸ¯ Calculate relevance score
                        relevance = self._calculate_menu_relevance(content)

                        if relevance > 0.5:
                            captured_blocks.append({
                                "content": content.strip(),
                                "element_type": "menu-item",
                                "confidence": relevance,
                                "source_info": {
                                    "selector": selector,
                                    "custom_strategy": "menu_focused"
                                }
                            })

            except Exception as e:
                print(f"âŒ Error with selector {selector}: {e}")

        return captured_blocks

    def _calculate_menu_relevance(self, content: str) -> float:
        """ğŸ¯ Calculate how relevant content is to menus."""

        menu_indicators = [
            "price", "$", "dollar", "appetizer", "entree", "dessert",
            "beverage", "wine", "beer", "cocktail", "dish", "served",
            "ingredients", "sauce", "grilled", "fried", "baked"
        ]

        content_lower = content.lower()
        matches = sum(1 for indicator in menu_indicators if indicator in content_lower)

        # ğŸ“Š Base relevance on keyword density
        relevance = min(matches / 5, 1.0)  # Max out at 5 matches

        # ğŸ¯ Boost for price indicators
        if "$" in content or "price" in content_lower:
            relevance += 0.3

        # ğŸ“ Penalize very short or very long content
        if len(content) < 10:
            relevance *= 0.5
        elif len(content) > 500:
            relevance *= 0.7

        return min(relevance, 1.0)

# ğŸš€ Usage example
async def custom_strategy_example():
    """ğŸ¨ Example using custom capture strategy."""

    custom_strategy = CustomMenuCaptureStrategy()

    # Note: Integration would require modifying the core capture system
    # This is a conceptual example of how custom strategies could work

    print("ğŸ¨ Custom menu capture strategy would be applied here")
    return custom_strategy

# ğŸš€ Run custom strategy example
strategy = asyncio.run(custom_strategy_example())
```

### ğŸ”§ Custom AI Scout Implementation

```python
from maestro.src.web_maestro.agents.scout_bridge import ScoutBridge

class RestaurantAIScout(ScoutBridge):
    """ğŸ”§ Custom AI Scout specialized for restaurant websites."""

    def __init__(self, client):
        super().__init__(client)
        self.restaurant_keywords = [
            "menu", "food", "dining", "cuisine", "special", "wine",
            "appetizer", "entree", "dessert", "chef", "seasonal"
        ]

    async def should_interact_with_element(self, element, context):
        """ğŸ¤” Restaurant-specific interaction decisions."""

        element_text = element.get("text", "").lower()
        element_href = element.get("href", "").lower()

        # ğŸ½ï¸ High priority for menu-related elements
        menu_priority = self._calculate_menu_priority(element_text, element_href)

        if menu_priority > 0.8:
            return {
                "action": "click",
                "confidence": menu_priority,
                "reasoning": f"High menu relevance: {element_text[:50]}",
                "priority": "high"
            }

        # ğŸ§  Use AI for borderline cases
        if menu_priority > 0.3:
            ai_decision = await self._get_ai_decision(element, context)
            return ai_decision

        # ğŸš« Skip irrelevant elements
        return {
            "action": "skip",
            "confidence": 1.0 - menu_priority,
            "reasoning": "Low restaurant relevance",
            "priority": "low"
        }

    def _calculate_menu_priority(self, text: str, href: str) -> float:
        """ğŸ¯ Calculate restaurant-specific priority."""

        priority = 0.0

        # ğŸ½ï¸ Text-based indicators
        for keyword in self.restaurant_keywords:
            if keyword in text:
                priority += 0.2

        # ğŸ”— URL-based indicators
        menu_url_indicators = ["menu", "food", "dining", "wine", "drinks"]
        for indicator in menu_url_indicators:
            if indicator in href:
                priority += 0.3

        # ğŸš« Negative indicators
        negative_indicators = ["about", "contact", "location", "hours", "reservation"]
        for negative in negative_indicators:
            if negative in text or negative in href:
                priority -= 0.2

        return max(0.0, min(1.0, priority))

    async def _get_ai_decision(self, element, context):
        """ğŸ§  Get AI decision for complex cases."""

        prompt = f"""
        You are a restaurant menu extraction specialist.

        Context: {context.get('extraction_goal', 'Extract restaurant menu')}
        Element: {element.get('text', '')[:100]}
        URL: {element.get('href', 'no link')}

        Should I interact with this element to find menu content?
        Consider: Will this likely lead to menu items, prices, or food descriptions?

        Respond with JSON: {{"action": "click/skip", "confidence": 0.0-1.0, "reasoning": "explanation"}}
        """

        # Mock AI response (would use actual LLM client)
        return {
            "action": "click" if "menu" in element.get("text", "").lower() else "skip",
            "confidence": 0.7,
            "reasoning": "AI analysis based on restaurant context",
            "priority": "medium"
        }

# ğŸš€ Usage example
async def custom_scout_example():
    """ğŸ”§ Example using custom restaurant AI scout."""

    client = PortkeyToolClient()
    restaurant_scout = RestaurantAIScout(client)

    # ğŸ§ª Test element
    test_element = {
        "text": "Wine Selection",
        "href": "/wines",
        "tag": "a"
    }

    test_context = {
        "extraction_goal": "Extract comprehensive wine menu"
    }

    decision = await restaurant_scout.should_interact_with_element(
        test_element, test_context
    )

    print(f"ğŸ”§ Custom Scout Decision:")
    print(f"  ğŸ¯ Action: {decision['action']}")
    print(f"  ğŸ“Š Confidence: {decision['confidence']:.2f}")
    print(f"  ğŸ§  Reasoning: {decision['reasoning']}")

    return decision

# ğŸš€ Run custom scout example
decision = asyncio.run(custom_scout_example())
```

This comprehensive Web Maestro examples guide demonstrates the full spectrum of intelligent web automation capabilities, from basic extraction to advanced production patterns and custom extensions! ğŸŒâœ¨
