# coding: utf-8

"""
    Robust Intelligence Firewall REST API

    API methods for Robust Intelligence. Users must authenticate using the `X-Firewall-Auth-Token` header. Your AI Firewall Agent domain forms the base of the URL for REST API calls. To find the Agent domain in the Robust Intelligence UI, click AI Firewall: Settings icon: Firewall Settings. Find your agent in the Firewall Agent Status: Agents Setup page, and copy its URL from the table.

    The version of the OpenAPI document: 1.0
    Contact: dev@robustintelligence.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501

from __future__ import annotations
import json
from enum import Enum
from typing_extensions import Self


class FirewallRuleType(str, Enum):
    """
    FirewallRuleType specifies the different rules for the firewall.   - FIREWALL_RULE_TYPE_TOXICITY: Toxicity checks for toxic text in the model's output.  - FIREWALL_RULE_TYPE_PII_DETECTION: PII detection validates that the model does not leak personal information.  - FIREWALL_RULE_TYPE_PROMPT_INJECTION: Prompt injection flags user input text that contain prompt injection attacks.  - FIREWALL_RULE_TYPE_FACTUAL_INCONSISTENCY: Factual inconsistency verifies the model output does not contradict the input context documents. In a RAG application the context will be the documents loaded during the RAG Retrieval phase to augment the LLM's response.  - FIREWALL_RULE_TYPE_OFF_TOPIC: Off topic flags user inputs that are out of distribution.  - FIREWALL_RULE_TYPE_INDIRECT_PROMPT_INJECTION: Indirect prompt injection flags contexts that contain prompt injection attacks.  - FIREWALL_RULE_TYPE_UNKNOWN_EXTERNAL_SOURCE: Unknown external source flags inputs that contain potentially malicious resources, such as urls that are not configured to be whitelisted.  - FIREWALL_RULE_TYPE_LANGUAGE_DETECTION: Language detection flags inputs that contain any language other than those that are whitelisted.  - FIREWALL_RULE_TYPE_CODE_DETECTION: Code detection flags inputs that contain code snippets.  - FIREWALL_RULE_TYPE_TOKEN_COUNTER: Token counter flags model inputs/outputs that attempt to overload the model. This rule ensures large inputs are blocked if they exceed a configurable number of tokens.
    """

    """
    allowed enum values
    """
    FIREWALL_RULE_TYPE_TOXICITY = 'FIREWALL_RULE_TYPE_TOXICITY'
    FIREWALL_RULE_TYPE_PII_DETECTION = 'FIREWALL_RULE_TYPE_PII_DETECTION'
    FIREWALL_RULE_TYPE_PROMPT_INJECTION = 'FIREWALL_RULE_TYPE_PROMPT_INJECTION'
    FIREWALL_RULE_TYPE_FACTUAL_INCONSISTENCY = 'FIREWALL_RULE_TYPE_FACTUAL_INCONSISTENCY'
    FIREWALL_RULE_TYPE_OFF_TOPIC = 'FIREWALL_RULE_TYPE_OFF_TOPIC'
    FIREWALL_RULE_TYPE_INDIRECT_PROMPT_INJECTION = 'FIREWALL_RULE_TYPE_INDIRECT_PROMPT_INJECTION'
    FIREWALL_RULE_TYPE_UNKNOWN_EXTERNAL_SOURCE = 'FIREWALL_RULE_TYPE_UNKNOWN_EXTERNAL_SOURCE'
    FIREWALL_RULE_TYPE_LANGUAGE_DETECTION = 'FIREWALL_RULE_TYPE_LANGUAGE_DETECTION'
    FIREWALL_RULE_TYPE_CODE_DETECTION = 'FIREWALL_RULE_TYPE_CODE_DETECTION'
    FIREWALL_RULE_TYPE_TOKEN_COUNTER = 'FIREWALL_RULE_TYPE_TOKEN_COUNTER'

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of FirewallRuleType from a JSON string"""
        return cls(json.loads(json_str))


