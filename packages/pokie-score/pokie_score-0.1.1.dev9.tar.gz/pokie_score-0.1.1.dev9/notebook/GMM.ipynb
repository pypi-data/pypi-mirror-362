{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d68a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import gaussian_kde\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Set up path to import from src\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Import pokie from pokie.py\n",
    "from pokie import pokie, get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019fd141",
   "metadata": {},
   "source": [
    "# Section 3.2: Analyzing distribution shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2ddc3",
   "metadata": {},
   "source": [
    "# Sample from GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d670e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples_from_gmm(means, covariances, n_samples):\n",
    "    \"\"\"\n",
    "    means:       shape (n_components, n_dimensions)\n",
    "    covariances: shape (n_components, n_dimensions),\n",
    "                 each row is the diagonal of the covariance matrix for that component\n",
    "    n_samples:   number of samples to generate in total\n",
    "    \"\"\"\n",
    "    n_components, n_dimensions = means.shape\n",
    "    samples = np.zeros((n_samples, n_dimensions))\n",
    "    # Assume uniform mixing weights for simplicity\n",
    "    component_choices = np.random.choice(\n",
    "        n_components, size=n_samples, p=np.ones(n_components)/n_components\n",
    "    )\n",
    "\n",
    "    for i, comp in enumerate(component_choices):\n",
    "        # Use np.diag(...) so each component's covariance is diagonal\n",
    "        cov = np.diag(covariances[comp])\n",
    "        samples[i, :] = np.random.multivariate_normal(means[comp], cov)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5715fa3",
   "metadata": {},
   "source": [
    "# 2 Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148b5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift magnitudes: [-6, -3, 0, 3, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Shifted GMMs: 100%|██████████| 5/5 [00:00<00:00,  7.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set up the GMM parameters\n",
    "n_components = 20\n",
    "n_dimensions = 2\n",
    "n_truth_samples = 5000  # Number of ground truth samples\n",
    "num_posterior_samples = 5000  # Number of posterior samples per truth\n",
    "epsilon = 1e-3  # Small value to avoid division by zero\n",
    "curr_num_runs = 100\n",
    "\n",
    "# Initialize random means and covariances for the GMM components\n",
    "means = np.random.rand(n_components, n_dimensions) * 10  # Random means between 0 and 10\n",
    "covariances = np.random.rand(n_components, n_dimensions) + epsilon  # Ensure strictly positive variance\n",
    "\n",
    "# Generate the truth data (no shift)\n",
    "truth_data = generate_samples_from_gmm(means, covariances, n_truth_samples)\n",
    "\n",
    "# Generate the models with different shift magnitudes from -10 to 10 along the diagonal\n",
    "shift_magnitudes = np.arange(-10, 11, 1)  # Shift values from -10 to 10  # Shift values from -10 to 10\n",
    "# shift_magnitudes = np.arange(-3, 4, 1)  # Shift values from -3 to 3  # Shift values from -10 to 10\n",
    "shift_magnitudes = [-6, -3, 0, 3, 6]  # Example shift magnitudes for testing\n",
    "num_models = len(shift_magnitudes)\n",
    "\n",
    "print(f'Shift magnitudes: {shift_magnitudes}')\n",
    "\n",
    "# Generate shifted GMMs once per model\n",
    "models_base = np.zeros((num_models, num_posterior_samples, n_dimensions))  # Shape: (21, 500, 2)\n",
    "\n",
    "for i, shift in enumerate(tqdm(shift_magnitudes, desc=f'Generating Shifted GMMs')):\n",
    "    models_base[i] = generate_samples_from_gmm(means, covariances, num_posterior_samples) + np.ones(n_dimensions) * shift\n",
    "\n",
    "# Now, expand to (num_models, num_truth_samples, num_posterior_samples, dimensions)\n",
    "models = np.repeat(models_base[:, np.newaxis, :, :], n_truth_samples, axis=1)\n",
    "\n",
    "# Validate shape\n",
    "assert models.shape == (num_models, n_truth_samples, num_posterior_samples, n_dimensions), \"Shape mismatch!\"\n",
    "\n",
    "epsilon = 1e-10  # Small value to avoid division by zero\n",
    "\n",
    "# Get min and max from truth_data (per dimension)\n",
    "low = np.min(truth_data, axis=0, keepdims=True)  # Shape: (1, n_dimensions)\n",
    "high = np.max(truth_data, axis=0, keepdims=True)  # Shape: (1, n_dimensions)\n",
    "\n",
    "# Normalize truth_data\n",
    "truth_data_normalized = (truth_data - low) / (high - low + epsilon)\n",
    "\n",
    "# Normalize models (loop over each shift magnitude)\n",
    "models_normalized = np.zeros_like(models)\n",
    "for m_idx in range(num_models):\n",
    "    models_normalized[m_idx] = (models[m_idx] - low) / (high - low + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceeab660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pokie MC runs: 100%|██████████| 100/100 [00:06<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shift Magnitudes: [-6, -3, 0, 3, 6]\n",
      "Pokie Score: [0.5920529  0.64539456 0.6670515  0.6426327  0.59763235]\n"
     ]
    }
   ],
   "source": [
    "# Identify your device (CUDA > MPS > CPU)\n",
    "device = get_device()\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Convert to torch Tensors on the chosen device\n",
    "truth_data_normalized   = torch.tensor(truth_data_normalized, dtype=torch.float32, device=device)\n",
    "models_normalized = torch.tensor(models_normalized,   dtype=torch.float32, device=device)\n",
    "\n",
    "pokie_score = pokie(\n",
    "    truth_data_normalized, models_normalized, num_runs=curr_num_runs\n",
    ")\n",
    "\n",
    "pokie_score = pokie_score.cpu().numpy()\n",
    "\n",
    "print('\\nShift Magnitudes:', shift_magnitudes)\n",
    "print(\"Pokie Score:\", pokie_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab1bb2",
   "metadata": {},
   "source": [
    "# 20 Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28235817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift magnitudes: [-6, -3, 0, 3, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Shifted GMMs: 100%|██████████| 5/5 [00:00<00:00, 56.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set up the GMM parameters\n",
    "n_components = 20\n",
    "n_dimensions = 20\n",
    "n_truth_samples = 500  # Number of ground truth samples\n",
    "num_posterior_samples = 500  # Number of posterior samples per truth\n",
    "epsilon = 1e-3  # Small value to avoid division by zero\n",
    "curr_num_runs = 100\n",
    "\n",
    "# Initialize random means and covariances for the GMM components\n",
    "means = np.random.rand(n_components, n_dimensions) * 10  # Random means between 0 and 10\n",
    "covariances = np.random.rand(n_components, n_dimensions) + epsilon  # Ensure strictly positive variance\n",
    "\n",
    "# Generate the truth data (no shift)\n",
    "truth_data = generate_samples_from_gmm(means, covariances, n_truth_samples)\n",
    "\n",
    "# Generate the models with different shift magnitudes from -10 to 10 along the diagonal\n",
    "# shift_magnitudes = np.arange(-10, 11, 1)  # Shift values from -10 to 10  # Shift values from -10 to 10\n",
    "shift_magnitudes = [-6, -3, 0, 3, 6]  # Example shift magnitudes for testing\n",
    "num_models = len(shift_magnitudes)\n",
    "\n",
    "print(f'Shift magnitudes: {shift_magnitudes}')\n",
    "\n",
    "# Generate shifted GMMs once per model\n",
    "models_base = np.zeros((num_models, num_posterior_samples, n_dimensions))  # Shape: (21, 500, 2)\n",
    "\n",
    "for i, shift in enumerate(tqdm(shift_magnitudes, desc=f'Generating Shifted GMMs')):\n",
    "    models_base[i] = generate_samples_from_gmm(means, covariances, num_posterior_samples) + np.ones(n_dimensions) * shift\n",
    "\n",
    "# Now, expand to (num_models, num_truth_samples, num_posterior_samples, dimensions)\n",
    "models = np.repeat(models_base[:, np.newaxis, :, :], n_truth_samples, axis=1)\n",
    "\n",
    "# Validate shape\n",
    "assert models.shape == (num_models, n_truth_samples, num_posterior_samples, n_dimensions), \"Shape mismatch!\"\n",
    "\n",
    "epsilon = 1e-10  # Small value to avoid division by zero\n",
    "\n",
    "# Get min and max from truth_data (per dimension)\n",
    "low = np.min(truth_data, axis=0, keepdims=True)  # Shape: (1, n_dimensions)\n",
    "high = np.max(truth_data, axis=0, keepdims=True)  # Shape: (1, n_dimensions)\n",
    "\n",
    "# Normalize truth_data\n",
    "truth_data_normalized = (truth_data - low) / (high - low + epsilon)\n",
    "\n",
    "# Normalize models (loop over each shift magnitude)\n",
    "models_normalized = np.zeros_like(models)\n",
    "for m_idx in range(num_models):\n",
    "    models_normalized[m_idx] = (models[m_idx] - low) / (high - low + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764b1afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pokie MC runs: 100%|██████████| 100/100 [00:01<00:00, 88.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shift Magnitudes: [-6, -3, 0, 3, 6]\n",
      "Pokie Score: [0.50535846 0.6023627  0.66835594 0.5774247  0.5015557 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify your device (CUDA > MPS > CPU)\n",
    "device = get_device()\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Convert to torch Tensors on the chosen device\n",
    "truth_data_normalized   = torch.tensor(truth_data_normalized, dtype=torch.float32, device=device)\n",
    "models_normalized = torch.tensor(models_normalized,   dtype=torch.float32, device=device)\n",
    "\n",
    "pokie_score = pokie(\n",
    "    truth_data_normalized, models_normalized, num_runs=curr_num_runs\n",
    ")\n",
    "\n",
    "# Convert results, calibrated, n_over_N_vals back to numpy arrays\n",
    "pokie_score = pokie_score.cpu().numpy()\n",
    "\n",
    "print('\\nShift Magnitudes:', shift_magnitudes)\n",
    "print(\"Pokie Score:\", pokie_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed34d5",
   "metadata": {},
   "source": [
    "# 100 Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b3f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift magnitudes: [-6, -3, 0, 3, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Shifted GMMs: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set up the GMM parameters\n",
    "n_components = 20\n",
    "n_dimensions = 100\n",
    "n_truth_samples = 500  # Number of ground truth samples\n",
    "num_posterior_samples = 500  # Number of posterior samples per truth\n",
    "epsilon = 1e-3  # Small value to avoid division by zero\n",
    "curr_num_runs = 100\n",
    "\n",
    "# Initialize random means and covariances for the GMM components\n",
    "means = np.random.rand(n_components, n_dimensions) * 10  # Random means between 0 and 10\n",
    "covariances = np.random.rand(n_components, n_dimensions) + epsilon  # Ensure strictly positive variance\n",
    "\n",
    "# Generate the truth data (no shift)\n",
    "truth_data = generate_samples_from_gmm(means, covariances, n_truth_samples)\n",
    "\n",
    "# Generate the models with different shift magnitudes from -10 to 10 along the diagonal\n",
    "# shift_magnitudes = np.arange(-10, 11, 1)  # Shift values from -10 to 10  # Shift values from -10 to 10\n",
    "shift_magnitudes = [-6, -3, 0, 3, 6]  # Example shift magnitudes for testing\n",
    "num_models = len(shift_magnitudes)\n",
    "\n",
    "print(f'Shift magnitudes: {shift_magnitudes}')\n",
    "\n",
    "# Generate shifted GMMs once per model\n",
    "models_base = np.zeros((num_models, num_posterior_samples, n_dimensions))  # Shape: (21, 500, 2)\n",
    "\n",
    "for i, shift in enumerate(tqdm(shift_magnitudes, desc=f'Generating Shifted GMMs')):\n",
    "    models_base[i] = generate_samples_from_gmm(means, covariances, num_posterior_samples) + np.ones(n_dimensions) * shift\n",
    "\n",
    "# Now, expand to (num_models, num_truth_samples, num_posterior_samples, dimensions)\n",
    "models = np.repeat(models_base[:, np.newaxis, :, :], n_truth_samples, axis=1)\n",
    "\n",
    "# Validate shape\n",
    "assert models.shape == (num_models, n_truth_samples, num_posterior_samples, n_dimensions), \"Shape mismatch!\"\n",
    "\n",
    "epsilon = 1e-10  # Small value to avoid division by zero\n",
    "\n",
    "# Get min and max from truth_data (per dimension)\n",
    "low = np.min(truth_data, axis=0, keepdims=True)  # Shape: (1, n_dimensions)\n",
    "high = np.max(truth_data, axis=0, keepdims=True)  # Shape: (1, n_dimensions)\n",
    "\n",
    "# Normalize truth_data\n",
    "truth_data_normalized = (truth_data - low) / (high - low + epsilon)\n",
    "\n",
    "# Normalize models (loop over each shift magnitude)\n",
    "models_normalized = np.zeros_like(models)\n",
    "for m_idx in range(num_models):\n",
    "    models_normalized[m_idx] = (models[m_idx] - low) / (high - low + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c728bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pokie MC runs: 100%|██████████| 100/100 [00:02<00:00, 36.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shift Magnitudes: [-6, -3, 0, 3, 6]\n",
      "Pokie Score: [0.49919492 0.5186664  0.66873    0.5067975  0.50114316]\n"
     ]
    }
   ],
   "source": [
    "# Identify your device (CUDA > MPS > CPU)\n",
    "device = get_device()\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Convert to torch Tensors on the chosen device\n",
    "truth_data_normalized   = torch.tensor(truth_data_normalized, dtype=torch.float32, device=device)\n",
    "models_normalized = torch.tensor(models_normalized,   dtype=torch.float32, device=device)\n",
    "\n",
    "pokie_score = pokie(\n",
    "    truth_data_normalized, models_normalized, num_runs=curr_num_runs\n",
    ")\n",
    "\n",
    "# Convert results, calibrated, n_over_N_vals back to numpy arrays\n",
    "pokie_score = pokie_score.cpu().numpy()\n",
    "\n",
    "print('\\nShift Magnitudes:', shift_magnitudes)\n",
    "print(\"Pokie Score:\", pokie_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2576ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
