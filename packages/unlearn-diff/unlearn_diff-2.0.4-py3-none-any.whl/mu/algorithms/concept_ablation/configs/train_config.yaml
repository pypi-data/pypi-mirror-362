# # Training parameters
# seed : 23 
# scale_lr : True 
# caption_target : "Abstractionism Style"
# regularization : True 
# n_samples : 1
# train_size : 1
# base_lr : 2.0e-06

# # Model configuration
# model_config_path: "mu/algorithms/concept_ablation/configs/model_config.yaml"  # Config path for Stable Diffusion
# ckpt_path: "models/compvis/style50/compvis.ckpt"  # Checkpoint path for Stable Diffusion

# # Dataset directories
# raw_dataset_dir: "data/quick-canvas-dataset/sample"
# processed_dataset_dir: "mu/algorithms/concept_ablation/data"
# dataset_type : "unlearncanvas"
# template : "style"
# template_name : "Abstractionism"

# lr: 5e-5 
# # Output configurations
# output_dir: "outputs/concept_ablation/finetuned_models"  # Output directory to save results

# # Sampling and image configurations

# # Device configuration
# devices: "0,"  # CUDA devices to train on (comma-separated)

# # Additional flags
# use_sample: True  # Use the sample dataset for training

data:
  target: mu.algorithms.concept_ablation.data_handler.ConceptAblationDataHandler
  params:
    batch_size: 4
    num_workers: 4
    wrap: false
    train:
      target: mu.algorithms.concept_ablation.src.finetune_data.MaskBase
      params:
        size: 512
    train2:
      target: mu.algorithms.concept_ablation.src.finetune_data.MaskBase
      params:
        size: 512


lightning:
  callbacks:
    image_logger:
      target: mu.algorithms.concept_ablation.callbacks.ImageLogger
      params:
        batch_frequency: 20000
        save_freq: 10000
        max_images: 8
        increase_log_steps: False
  modelcheckpoint:
    params:
      every_n_train_steps: 10000

  trainer:
    max_steps: 5

