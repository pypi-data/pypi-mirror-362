{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# QCML Client Demo: End-to-End Training with the QCML API\n",
        "\n",
        "This notebook demonstrates the complete QCML workflow:\n",
        "- ğŸ” **Resource Discovery**: Finding available environments and experiments\n",
        "- ğŸ“ **Dataset Management**: Loading and uploading training data\n",
        "- âš™ï¸ **Model Configuration**: Setting up hyperparameters for quantum models\n",
        "- ğŸš€ **Training Experiments**: Running training with real-time monitoring\n",
        "- ğŸ“Š **Results Analysis**: Viewing training metrics and outcomes\n",
        "\n",
        "**Prerequisites:**\n",
        "- QCOG API key set in environment or `.env` file\n",
        "- Access to a QCML project\n",
        "- Test dataset (we'll create one!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ Setup and Imports\n",
        "\n",
        "First, let's import all the necessary libraries and set up our clients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import qcogclient\n",
        "import qcogclient._version\n",
        "from qcogclient.qcog.adapters import load_csv\n",
        "from qcog_types.pytorch_models.hyperparameters import (\n",
        "    GeneralHSModelHyperparameters,\n",
        "    OptimizerConfig,\n",
        "    LossFunctionConfig,\n",
        "    EarlyStoppingConfig\n",
        ")\n",
        "import dotenv\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load environment variables\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "print(\"âœ… All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll create three different clients for different operations:\n",
        "- **AdminClient**: For discovering system resources\n",
        "- **ProjectClient**: For managing datasets\n",
        "- **ExperimentClient**: For running training experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… QCML clients initialized successfully!\n",
            "ğŸ”‘ API key loaded from environment\n"
          ]
        }
      ],
      "source": [
        "# Initialize clients with API key from environment\n",
        "api_key = os.getenv(\"QCOG_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"âŒ QCOG_API_KEY not found in environment variables!\")\n",
        "\n",
        "admin_client = qcogclient.AdminClient(api_key=api_key)\n",
        "project_client = qcogclient.ProjectClient(api_key=api_key)\n",
        "experiment_client = qcogclient.ExperimentClient(api_key=api_key)\n",
        "\n",
        "print(\"âœ… QCML clients initialized successfully!\")\n",
        "print(\"ğŸ”‘ API key loaded from environment\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” Discover Available Resources\n",
        "\n",
        "Before we start, let's see what environments and experiments are available in the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ–¥ï¸ Available Compute Environments:\n",
            "==================================================\n",
            "ğŸ“‹ py3.12          - Python 3.12. CPU\n",
            "ğŸ“‹ py3.12-cuda     - Python 3.12. GPU with CUDA 19.9\n",
            "ğŸ“‹ python3.12      - Basic Python environment with no GPU support\n",
            "\n",
            "ğŸ§ª Available Experiments:\n",
            "==================================================\n",
            "ğŸ”¬ pytorch-models  - A package for training and predicting with pytorch models\n",
            "ğŸ”¬ weighted-general - A package for training and predicting with a weighted general model\n",
            "\n",
            "ğŸ¯ For this demo, we'll use:\n",
            "   Environment: py3.12 (CPU)\n",
            "   Experiment: pytorch-models\n"
          ]
        }
      ],
      "source": [
        "# Discover available environments\n",
        "print(\"ğŸ–¥ï¸ Available Compute Environments:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "envs = await admin_client.list_environments()\n",
        "for env in envs['response']:\n",
        "    print(f\"ğŸ“‹ {env['name']: <15} - {env['description']}\")\n",
        "\n",
        "print(\"\\nğŸ§ª Available Experiments:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "experiments = await admin_client.list_experiments()\n",
        "for exp in experiments['response']:\n",
        "    print(f\"ğŸ”¬ {exp['name']: <15} - {exp['description']}\")\n",
        "\n",
        "print(\"\\nğŸ¯ For this demo, we'll use:\")\n",
        "print(\"   Environment: py3.12 (CPU)\")\n",
        "print(\"   Experiment: pytorch-models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Create Test Dataset\n",
        "\n",
        "Let's create a synthetic dataset perfect for testing QCML models. We'll generate numerical features with realistic relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Created dataset with 100 rows and 6 columns\n",
            "ğŸ’¾ Saved to: demo_dataset.csv\n",
            "\n",
            "ğŸ” Dataset Preview:\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5     target\n",
            "0   5.245071   5.373910   5.413730   6.784545   4.148770  46.072146\n",
            "1   4.148795   4.791861   4.096408   3.795788   5.313840  37.006177\n",
            "2   3.804873   3.524328   4.292516   1.630080   1.912623  27.292355\n",
            "3   3.656569   3.994146   4.654666   3.137964   2.381544  29.846807\n",
            "4   6.698473   6.063586   5.971022   2.362878   3.683426  50.569224\n",
            "\n",
            "ğŸ“ˆ Dataset Statistics:\n",
            "       feature_1  feature_2  feature_3  feature_4  feature_5   target\n",
            "count    100.000    100.000    100.000    100.000    100.000  100.000\n",
            "mean       4.433      4.412      4.455      4.692      4.452   37.562\n",
            "std        1.351      1.119      0.963      1.439      1.609    9.632\n",
            "min        1.572      1.999      2.318      1.630      0.570   18.343\n",
            "25%        3.398      3.598      3.927      3.696      3.364   29.783\n",
            "50%        4.485      4.464      4.469      4.729      4.281   37.868\n",
            "75%        5.286      5.185      5.147      5.502      5.472   43.255\n",
            "max        7.972      7.027      7.039      9.118     10.279   63.620\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic dataset\n",
        "n_samples = 100\n",
        "n_features = 5\n",
        "\n",
        "# Create correlated features\n",
        "X = np.random.randn(n_samples, n_features)\n",
        "X[:, 1] = X[:, 0] * 0.8 + np.random.randn(n_samples) * 0.2  # feature_2 correlated with feature_1\n",
        "X[:, 2] = X[:, 0] * 0.3 + X[:, 1] * 0.4 + np.random.randn(n_samples) * 0.3  # feature_3 depends on both\n",
        "\n",
        "# Scale features to reasonable range\n",
        "X = (X + 3) * 1.5  # Shift and scale to positive values around 1-6\n",
        "\n",
        "# Create target with realistic relationship\n",
        "# Target is a nonlinear combination of features (perfect for quantum models!)\n",
        "target = (\n",
        "    2.5 * X[:, 0] +\n",
        "    1.8 * X[:, 1] +\n",
        "    1.2 * X[:, 2] +\n",
        "    0.9 * X[:, 3] +\n",
        "    0.6 * X[:, 4] +\n",
        "    0.3 * X[:, 0] * X[:, 1] +  # Interaction term\n",
        "    np.random.randn(n_samples) * 0.5  # Noise\n",
        ")\n",
        "\n",
        "# Create DataFrame\n",
        "feature_names = [f'feature_{i+1}' for i in range(n_features)]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['target'] = target\n",
        "\n",
        "# Save to CSV\n",
        "dataset_path = \"demo_dataset.csv\"\n",
        "df.to_csv(dataset_path, index=False)\n",
        "\n",
        "print(f\"ğŸ“Š Created dataset with {len(df)} rows and {len(df.columns)} columns\")\n",
        "print(f\"ğŸ’¾ Saved to: {dataset_path}\")\n",
        "print(\"\\nğŸ” Dataset Preview:\")\n",
        "print(df.head())\n",
        "print(\"\\nğŸ“ˆ Dataset Statistics:\")\n",
        "print(df.describe().round(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¤ Upload Dataset to QCML Platform\n",
        "\n",
        "Now let's upload our dataset to the QCML platform using the `load_csv` adapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¤ Uploading dataset to QCML platform...\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading CSV: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 506.86chunk/s, percentage=100] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Dataset loaded: 101 rows, 6 columns\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‰ Dataset uploaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Dataset configuration\n",
        "dataset_name = \"demo-dataset\"\n",
        "dataset_description = \"Synthetic dataset for QCML demo\"\n",
        "\n",
        "print(\"ğŸ“¤ Uploading dataset to QCML platform...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load the CSV and extract metadata\n",
        "loaded_dataset = load_csv(dataset_path)\n",
        "print(f\"âœ… Dataset loaded: {loaded_dataset['number_of_rows']} rows, {loaded_dataset['number_of_columns']} columns\")\n",
        "\n",
        "try:\n",
        "    await project_client.upload_dataset(\n",
        "        file=loaded_dataset['file'],\n",
        "        name=dataset_name,\n",
        "        description=dataset_description,\n",
        "        override=True,  # Allow overwriting for demo purposes\n",
        "        chunk_size=1024 * 1024 * 10  # 10MB chunks\n",
        "    )\n",
        "    print(\"ğŸ‰ Dataset uploaded successfully!\")\n",
        "\n",
        "    # Store metadata for later use\n",
        "    n_columns = loaded_dataset['number_of_columns']\n",
        "    n_rows = loaded_dataset['number_of_rows']\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to upload dataset: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ Configure Model Hyperparameters\n",
        "\n",
        "Now let's set up hyperparameters for our General Hilbert Space Model. We'll use settings optimized for this demo dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš™ï¸ Configuring QCML Model Hyperparameters\n",
            "==================================================\n",
            "ğŸ“Š Input features: 5\n",
            "ğŸ¯ Target: 1 (regression)\n",
            "ğŸ“ Dataset size: 101 samples\n",
            "âœ… Hyperparameters configured successfully!\n",
            "\n",
            "ğŸ”§ Model Configuration:\n",
            "   Architecture: General HSM\n",
            "   Hilbert Space Dims: 8\n",
            "   Input Operators: 5\n",
            "   Output Operators: 1\n",
            "   Training Epochs: 50\n",
            "   Batch Size: 16\n",
            "   Learning Rate: 0.001\n"
          ]
        }
      ],
      "source": [
        "print(\"âš™ï¸ Configuring QCML Model Hyperparameters\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Calculate input features (total columns - target column)\n",
        "input_features_count = n_columns - 1\n",
        "print(f\"ğŸ“Š Input features: {input_features_count}\")\n",
        "print(\"ğŸ¯ Target: 1 (regression)\")\n",
        "print(f\"ğŸ“ Dataset size: {n_rows} samples\")\n",
        "\n",
        "# Configure hyperparameters for demo\n",
        "hyperparameters = GeneralHSModelHyperparameters(\n",
        "    # Model architecture\n",
        "    hsm_model=\"general\",\n",
        "    input_operator_count=input_features_count,  # Number of input features\n",
        "    output_operator_count=1,  # Single target (regression)\n",
        "    hilbert_space_dims=8,  # Small dimension for quick demo\n",
        "    complex=True,  # Use complex operators (recommended)\n",
        "\n",
        "    # Training configuration\n",
        "    epochs=50,  # Reasonable number for demo\n",
        "    batch_size=16,  # Small batch for small dataset\n",
        "    seed=42,  # Reproducibility\n",
        "    targets=\"target\",  # Our target column name (note: 'targets' not 'target')\n",
        "    device=\"cpu\",  # Use CPU for broader compatibility\n",
        "    split=0.2,  # 20% validation split\n",
        "\n",
        "    # Optimizer settings\n",
        "    optimizer_config=OptimizerConfig(\n",
        "        type=\"Adam\",\n",
        "        default_params={\"lr\": 0.001}  # Standard learning rate\n",
        "    ),\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn_config=LossFunctionConfig(\n",
        "        type=\"MSELoss\",  # Mean Squared Error for regression\n",
        "        params={}\n",
        "    ),\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping_config=EarlyStoppingConfig(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=10,  # Wait 10 epochs before stopping\n",
        "        mode=\"min\",\n",
        "        verbose=True,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"âœ… Hyperparameters configured successfully!\")\n",
        "print(\"\\nğŸ”§ Model Configuration:\")\n",
        "print(f\"   Architecture: General HSM\")\n",
        "print(f\"   Hilbert Space Dims: {hyperparameters.hilbert_space_dims}\")\n",
        "print(f\"   Input Operators: {hyperparameters.input_operator_count}\")\n",
        "print(f\"   Output Operators: {hyperparameters.output_operator_count}\")\n",
        "print(f\"   Training Epochs: {hyperparameters.epochs}\")\n",
        "print(f\"   Batch Size: {hyperparameters.batch_size}\")\n",
        "print(f\"   Learning Rate: {hyperparameters.optimizer_config.default_params['lr']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Launch Training Experiment\n",
        "\n",
        "Time to start our training! We'll submit the experiment to the QCML platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Launching QCML Training Experiment\n",
            "==================================================\n",
            "ğŸ‰ Training launched successfully!\n"
          ]
        }
      ],
      "source": [
        "# Launch training experiment\n",
        "experiment_name = \"qcml-demo\"\n",
        "\n",
        "print(\"ğŸš€ Launching QCML Training Experiment\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    result = await experiment_client.run_experiment(\n",
        "        name=experiment_name,\n",
        "        description=\"QCML demo experiment\",\n",
        "        experiment_name=\"pytorch-models\",\n",
        "        dataset_name=dataset_name,\n",
        "        environment_name=\"py3.12\",\n",
        "        parameters={\n",
        "            \"hyperparameters\": hyperparameters,\n",
        "            \"cpu_count\": 2,\n",
        "            \"memory\": 1024 * 4,\n",
        "            \"timeout\": 3600 * 2,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if 'response' in result:\n",
        "        print(\"ğŸ‰ Training launched successfully!\")\n",
        "    else:\n",
        "        print(f\"âŒ Failed: {result.get('error')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ğŸ’¥ Exception: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Monitor Training Progress\n",
        "\n",
        "Monitor your training experiment with real-time status updates!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Training Monitor\n",
            "==================================================\n",
            "â±ï¸ Status: completed\n",
            "ğŸ“ˆ Metrics:\n",
            "   test_loss: 1230.4495\n",
            "   best_val_loss: 1230.4495\n",
            "   avg_epoch_time: 0.0197\n",
            "   final_val_loss: 1230.4495\n",
            "   epochs_completed: 50\n",
            "   final_train_loss: 1238.3502\n",
            "   val_dataset_size: 20\n",
            "   val_loss_history: [1476.8082275390625, 1463.5443115234375, 1451.2857666015625, 1439.960205078125, 1429.5654296875, 1419.9169921875, 1410.8724365234375, 1402.4344482421875, 1394.45458984375, 1386.916259765625, 1379.869140625, 1373.3643798828125, 1367.2841796875, 1361.681396484375, 1356.4644775390625, 1351.5858154296875, 1347.027587890625, 1342.6849365234375, 1338.5345458984375, 1334.558837890625, 1330.7103271484375, 1326.9677734375, 1323.2818603515625, 1319.666748046875, 1316.068603515625, 1312.531494140625, 1309.0074462890625, 1305.512939453125, 1302.0322265625, 1298.5528564453125, 1295.1033935546875, 1291.650390625, 1288.215087890625, 1284.7786865234375, 1281.3504638671875, 1277.92724609375, 1274.51953125, 1271.1123046875, 1267.707275390625, 1264.3116455078125, 1260.927490234375, 1257.52099609375, 1254.129638671875, 1250.743408203125, 1247.3446044921875, 1243.94580078125, 1240.5689697265625, 1237.2027587890625, 1233.83056640625, 1230.449462890625]\n",
            "   checkpoint_metrics: ['loss']\n",
            "   train_dataset_size: 80\n",
            "   train_loss_history: [1494.7051025390624, 1480.07783203125, 1466.1895751953125, 1453.24384765625, 1441.5482666015625, 1430.9815673828125, 1421.253125, 1412.5267578125, 1404.3672607421875, 1396.6699951171875, 1389.7751708984374, 1383.0783447265626, 1376.9666015625, 1371.32607421875, 1366.02705078125, 1361.080859375, 1356.37841796875, 1351.94560546875, 1347.761279296875, 1343.6904541015624, 1339.73095703125, 1335.839892578125, 1332.087939453125, 1328.35146484375, 1324.74697265625, 1321.0417602539062, 1317.5099975585938, 1313.921875, 1310.401611328125, 1306.94072265625, 1303.3712646484375, 1299.937060546875, 1296.436572265625, 1293.024951171875, 1289.5218872070313, 1286.1080322265625, 1282.625927734375, 1279.1980102539062, 1275.7797119140625, 1272.349267578125, 1268.9306884765624, 1265.558544921875, 1262.103515625, 1258.6943603515624, 1255.336572265625, 1251.9412353515625, 1248.495703125, 1245.1025756835938, 1241.714892578125, 1238.3501708984375]\n",
            "   total_training_time: 36.1997\n",
            "ğŸ‰ Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Monitor training progress\n",
        "print(\"ğŸ“Š Training Monitor\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "result = await experiment_client.get_experiment_run(experiment_name)\n",
        "response = result.get(\"response\", {})\n",
        "response.pop(\"params\", None)\n",
        "\n",
        "status = response.get(\"status\")\n",
        "metrics = response.get(\"metrics\")\n",
        "\n",
        "print(f\"â±ï¸ Status: {status}\")\n",
        "\n",
        "if metrics:\n",
        "    print(\"ğŸ“ˆ Metrics:\")\n",
        "    for key, value in metrics.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {key}: {value}\")\n",
        "else:\n",
        "    print(\"ğŸ“Š No metrics available yet\")\n",
        "\n",
        "if status == 'completed':\n",
        "    print(\"ğŸ‰ Training completed!\")\n",
        "elif status == 'failed':\n",
        "    print(\"âŒ Training failed!\")\n",
        "    print(result)\n",
        "    print(f\"Error: {result['response']['errors']}\")\n",
        "elif status == 'running':\n",
        "    print(\"ğŸƒ Training in progress...\")\n",
        "else:\n",
        "    print(\"â³ Waiting for training to start...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ What You've Learned\n",
        "\n",
        "Congratulations! You've successfully completed a full QCML workflow:\n",
        "\n",
        "### ğŸ”§ **Technical Skills:**\n",
        "- âœ… Set up QCML clients and authentication\n",
        "- âœ… Created and uploaded datasets to the platform\n",
        "- âœ… Configured quantum machine learning hyperparameters\n",
        "- âœ… Launched training experiments on cloud infrastructure\n",
        "- âœ… Monitored training progress in real-time\n",
        "\n",
        "### ğŸš€ **Next Steps:**\n",
        "1. **Experiment with different hyperparameters** (Hilbert space dims, learning rates)\n",
        "2. **Upload your own datasets** and see how quantum models perform\n",
        "3. **Deploy trained models** for inference\n",
        "4. **Scale up** with GPU environments for larger datasets\n",
        "\n",
        "\n",
        "Checkout the documentation for more information on how to use the QCML API!\n",
        "\n",
        "### ğŸ“š **Resources:**\n",
        "- [PyTorch Models Guide](docs/pytorch-models.md)\n",
        "- [Dataset Management](docs/dataset-management.md) \n",
        "- [Training Runs Documentation](docs/training-runs.md)\n",
        "- [Model Deployment](docs/model-deployment.md)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
