Metadata-Version: 2.4
Name: omniduct
Version: 1.2.3
Summary: A toolkit providing a uniform interface for connecting to and extracting data from a wide variety of (potentially remote) data stores (including HDFS, Hive, Presto, MySQL, etc).
Project-URL: Homepage, https://github.com/airbnb/omniduct
Author-email: Matthew Wardrop <mpwardrop@gmail.com>, Dan Frank <danfrankj@gmail.com>
License-Expression: MIT
License-File: LICENSE
Classifier: Development Status :: 5 - Production/Stable
Classifier: Environment :: Console
Classifier: Environment :: Web Environment
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.7
Requires-Dist: decorator
Requires-Dist: interface-meta<2,>=1.2.0
Requires-Dist: jinja2
Requires-Dist: lazy-object-proxy
Requires-Dist: packaging
Requires-Dist: pandas>=0.20.3
Requires-Dist: progressbar2>=3.30.0
Requires-Dist: python-dateutil
Requires-Dist: pyyaml
Requires-Dist: sqlalchemy
Requires-Dist: sqlparse
Requires-Dist: wrapt
Provides-Extra: all
Requires-Dist: boto3; extra == 'all'
Requires-Dist: coverage; extra == 'all'
Requires-Dist: flake8; extra == 'all'
Requires-Dist: mock; extra == 'all'
Requires-Dist: nose; extra == 'all'
Requires-Dist: paramiko; extra == 'all'
Requires-Dist: pexpect; extra == 'all'
Requires-Dist: pydruid>=0.4.0; extra == 'all'
Requires-Dist: pyexasol; extra == 'all'
Requires-Dist: pyfakefs; extra == 'all'
Requires-Dist: pyhive[hive]>=0.4; extra == 'all'
Requires-Dist: pyhive[presto]>=0.4; extra == 'all'
Requires-Dist: pyspark; extra == 'all'
Requires-Dist: pywebhdfs; extra == 'all'
Requires-Dist: requests; extra == 'all'
Requires-Dist: snowflake-sqlalchemy; extra == 'all'
Requires-Dist: sphinx; extra == 'all'
Requires-Dist: sphinx-autobuild; extra == 'all'
Requires-Dist: sphinx-rtd-theme; extra == 'all'
Requires-Dist: thrift>=0.10.0; extra == 'all'
Provides-Extra: docs
Requires-Dist: sphinx; extra == 'docs'
Requires-Dist: sphinx-autobuild; extra == 'docs'
Requires-Dist: sphinx-rtd-theme; extra == 'docs'
Provides-Extra: druid
Requires-Dist: pydruid>=0.4.0; extra == 'druid'
Provides-Extra: exasol
Requires-Dist: pyexasol; extra == 'exasol'
Provides-Extra: hiveserver2
Requires-Dist: pyhive[hive]>=0.4; extra == 'hiveserver2'
Requires-Dist: thrift>=0.10.0; extra == 'hiveserver2'
Provides-Extra: presto
Requires-Dist: pyhive[presto]>=0.4; extra == 'presto'
Provides-Extra: pyspark
Requires-Dist: pyspark; extra == 'pyspark'
Provides-Extra: rest
Requires-Dist: requests; extra == 'rest'
Provides-Extra: s3
Requires-Dist: boto3; extra == 's3'
Provides-Extra: snowflake
Requires-Dist: snowflake-sqlalchemy; extra == 'snowflake'
Provides-Extra: ssh
Requires-Dist: pexpect; extra == 'ssh'
Provides-Extra: ssh-paramiko
Requires-Dist: paramiko; extra == 'ssh-paramiko'
Requires-Dist: pexpect; extra == 'ssh-paramiko'
Provides-Extra: test
Requires-Dist: coverage; extra == 'test'
Requires-Dist: flake8; extra == 'test'
Requires-Dist: mock; extra == 'test'
Requires-Dist: nose; extra == 'test'
Requires-Dist: pyfakefs; extra == 'test'
Provides-Extra: webhdfs
Requires-Dist: pywebhdfs; extra == 'webhdfs'
Requires-Dist: requests; extra == 'webhdfs'
Description-Content-Type: text/markdown

# <img src="https://raw.githubusercontent.com/airbnb/omniduct/master/omniduct/logo.png" height=200> Omniduct
[![PyPI - Version](https://img.shields.io/pypi/v/omniduct.svg)](https://pypi.org/project/omniduct/)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/omniduct.svg)
![PyPI - Status](https://img.shields.io/pypi/status/omniduct.svg)
[![Build Status](https://img.shields.io/github/actions/workflow/status/airbnb/omniduct/tests.yml?branch=main)](https://github.com/airbnb/omniduct/actions?query=workflow%3A%22Run+Tests%22)
[![Documentation Status](https://readthedocs.org/projects/omniduct/badge/?version=latest)](http://omniduct.readthedocs.io/en/latest/?badge=latest)


`omniduct` provides uniform interfaces for connecting to and extracting data from a wide variety of (potentially remote) data stores (including HDFS, Hive, Presto, MySQL, etc).

- **Documentation:** http://omniduct.readthedocs.io
- **Source:** https://github.com/airbnb/omniduct
- **Bug reports:** https://github.com/airbnb/omniduct/issues

It provides:

- A generic plugin-based programmatic API to access data in a consistent manner across different services (see [supported protocols](http://omniduct.readthedocs.io/en/latest/protocols.html)).
- A framework for lazily connecting to data sources and maintaining these connections during the entire lifetime of the relevant Python session.
- Automatic port forwarding of remote services over SSH where connections cannot be made directly.
- Convenient IPython magic functions for interfacing with data providers from within IPython and Jupyter Notebook sessions.
- Utility classes and methods to assist in maintaining registries of useful services.
