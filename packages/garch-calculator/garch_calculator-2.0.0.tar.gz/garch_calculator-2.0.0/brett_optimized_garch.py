#!/usr/bin/env python3
"""
ä¸ºbrett.csvæ•°æ®ä¼˜åŒ–çš„GARCHå‚æ•°é¢„è®¾å·¥å…·
åŸºäºç½‘æ ¼æœç´¢æ‰¾åˆ°çš„æœ€ä¼˜å‚æ•°ç»„åˆ
"""

import garch_lib as gc
import pandas as pd
import numpy as np
from arch import arch_model
from typing import Dict, List, Tuple

class BrettOptimizedGarch:
    """ä¸ºbrett.csvæ•°æ®ä¼˜åŒ–çš„GARCHå‚æ•°ç±»"""
    
    # åŸºäºç½‘æ ¼æœç´¢å¾—åˆ°çš„æœ€ä¼˜å‚æ•°é¢„è®¾
    OPTIMIZED_PARAMS = {
        'default': {
            'mu': 0.883802,
            'omega': 16.607143,
            'alpha': 0.214286,
            'beta': 0.692857,
            'nu': 1.830000,
            'likelihood': -1974.905295,
            'description': 'åŸºäº500ä¸ªæ•°æ®ç‚¹çš„ç½‘æ ¼æœç´¢æœ€ä¼˜å‚æ•°'
        },
        'high_volatility': {
            'mu': 0.883802,
            'omega': 20.0,
            'alpha': 0.25,
            'beta': 0.68,
            'nu': 1.8,
            'description': 'é€‚ç”¨äºé«˜æ³¢åŠ¨ç‡æœŸé—´çš„å‚æ•°'
        },
        'stable_period': {
            'mu': 0.883802,
            'omega': 12.0,
            'alpha': 0.18,
            'beta': 0.75,
            'nu': 2.0,
            'description': 'é€‚ç”¨äºç¨³å®šæœŸé—´çš„å‚æ•°'
        },
        'arch_like': {
            'mu': 0.883802,
            'omega': 16.303085,
            'alpha': 0.243217,
            'beta': 0.685985,
            'nu': 1.858213,
            'description': 'archåº“ä¼°è®¡çš„å‚æ•°ï¼ˆä½œä¸ºåŸºå‡†ï¼‰'
        }
    }
    
    @classmethod
    def create_calculator(cls, param_set: str = 'default', 
                         history_size: int = 500) -> gc.GarchCalculator:
        """
        åˆ›å»ºé¢„é…ç½®çš„GARCHè®¡ç®—å™¨
        
        Args:
            param_set: å‚æ•°é›†åç§° ('default', 'high_volatility', 'stable_period', 'arch_like')
            history_size: å†å²æ•°æ®å¤§å°
            
        Returns:
            é…ç½®å¥½çš„GarchCalculatorå®ä¾‹
        """
        if param_set not in cls.OPTIMIZED_PARAMS:
            raise ValueError(f"æœªçŸ¥çš„å‚æ•°é›†: {param_set}. å¯ç”¨é€‰é¡¹: {list(cls.OPTIMIZED_PARAMS.keys())}")
        
        # åˆ›å»ºè®¡ç®—å™¨
        calc = gc.GarchCalculator(history_size=history_size)
        
        # è®¾ç½®ä¼˜åŒ–å‚æ•°
        params_dict = cls.OPTIMIZED_PARAMS[param_set]
        params = gc.GarchParameters()
        params.mu = params_dict['mu']
        params.omega = params_dict['omega']
        params.alpha = params_dict['alpha']
        params.beta = params_dict['beta']
        params.nu = params_dict['nu']
        
        calc.set_parameters(params)
        
        return calc
    
    @classmethod
    def get_parameters(cls, param_set: str = 'default') -> gc.GarchParameters:
        """
        è·å–å‚æ•°å¯¹è±¡
        
        Args:
            param_set: å‚æ•°é›†åç§°
            
        Returns:
            GarchParameterså¯¹è±¡
        """
        if param_set not in cls.OPTIMIZED_PARAMS:
            raise ValueError(f"æœªçŸ¥çš„å‚æ•°é›†: {param_set}. å¯ç”¨é€‰é¡¹: {list(cls.OPTIMIZED_PARAMS.keys())}")
        
        params_dict = cls.OPTIMIZED_PARAMS[param_set]
        params = gc.GarchParameters()
        params.mu = params_dict['mu']
        params.omega = params_dict['omega']
        params.alpha = params_dict['alpha']
        params.beta = params_dict['beta']
        params.nu = params_dict['nu']
        
        return params
    
    @classmethod
    def compare_with_arch(cls, data: np.ndarray, param_set: str = 'default') -> Dict:
        """
        ä¸archåº“è¿›è¡Œå¯¹æ¯”éªŒè¯
        
        Args:
            data: æ”¶ç›Šç‡æ•°æ®
            param_set: å‚æ•°é›†åç§°
            
        Returns:
            å¯¹æ¯”ç»“æœå­—å…¸
        """
        # archåº“ä¼°è®¡
        try:
            arch_model_obj = arch_model(data, vol='Garch', p=1, q=1, dist='ged', rescale=False)
            arch_result = arch_model_obj.fit(disp='off', show_warning=False)
            arch_likelihood = arch_result.loglikelihood
            arch_params = {
                'mu': arch_result.params['mu'],
                'omega': arch_result.params['omega'],
                'alpha': arch_result.params['alpha[1]'],
                'beta': arch_result.params['beta[1]'],
                'nu': arch_result.params['nu']
            }
        except Exception as e:
            return {'error': f'archåº“ä¼°è®¡å¤±è´¥: {e}'}
        
        # garch_libè®¡ç®—
        calc = cls.create_calculator(param_set)
        calc.add_returns(data.tolist())
        
        garch_params = cls.OPTIMIZED_PARAMS[param_set]
        garch_likelihood = calc.calculate_log_likelihood()
        
        # è®¡ç®—å·®å¼‚
        param_diffs = {
            'mu': abs(garch_params['mu'] - arch_params['mu']),
            'omega': abs(garch_params['omega'] - arch_params['omega']),
            'alpha': abs(garch_params['alpha'] - arch_params['alpha']),
            'beta': abs(garch_params['beta'] - arch_params['beta']),
            'nu': abs(garch_params['nu'] - arch_params['nu'])
        }
        
        likelihood_diff = abs(garch_likelihood - arch_likelihood)
        
        return {
            'arch_params': arch_params,
            'arch_likelihood': arch_likelihood,
            'garch_params': garch_params,
            'garch_likelihood': garch_likelihood,
            'param_differences': param_diffs,
            'likelihood_difference': likelihood_diff,
            'improvement_over_arch': garch_likelihood > arch_likelihood
        }
    
    @classmethod
    def rolling_forecast_brett(cls, param_set: str = 'default', 
                              window_size: int = 200,
                              data_points: int = 500) -> Dict:
        """
        é’ˆå¯¹brett.csvçš„æ»šåŠ¨é¢„æµ‹
        
        Args:
            param_set: å‚æ•°é›†åç§°
            window_size: æ»šåŠ¨çª—å£å¤§å°
            data_points: ä½¿ç”¨çš„æ•°æ®ç‚¹æ•°
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        # è¯»å–brett.csvæ•°æ®
        df = pd.read_csv('brett.csv')
        returns = df['c_scaled'].values[:data_points]
        
        garch_predictions = []
        arch_predictions = []
        prediction_indices = []
        
        print(f"ğŸ”„ ä½¿ç”¨{param_set}å‚æ•°é›†è¿›è¡Œæ»šåŠ¨é¢„æµ‹")
        print(f"   æ•°æ®ç‚¹: {len(returns)}, çª—å£å¤§å°: {window_size}")
        
        success_count = 0
        total_attempts = 0
        
        for i in range(window_size, len(returns)):
            total_attempts += 1
            window_data = returns[i-window_size:i]
            
            try:
                # ä½¿ç”¨ä¼˜åŒ–å‚æ•°çš„garch_libé¢„æµ‹
                calc = cls.create_calculator(param_set, window_size + 10)
                calc.add_returns(window_data.tolist())
                
                garch_forecast = calc.forecast_volatility(1)
                garch_vol = garch_forecast.volatility
                garch_predictions.append(garch_vol)
                
                # archåº“é¢„æµ‹ï¼ˆä½œä¸ºåŸºå‡†ï¼‰
                arch_model_obj = arch_model(window_data, vol='Garch', p=1, q=1, dist='ged', rescale=False)
                arch_result = arch_model_obj.fit(disp='off', show_warning=False)
                arch_forecast = arch_result.forecast(horizon=1, reindex=False)
                arch_vol = np.sqrt(arch_forecast.variance.values[-1, 0])
                arch_predictions.append(arch_vol)
                
                prediction_indices.append(i)
                success_count += 1
                
                # è¿›åº¦æ˜¾ç¤º
                if total_attempts % 50 == 0:
                    progress = total_attempts / (len(returns) - window_size) * 100
                    print(f"   è¿›åº¦: {progress:.1f}% - garch_lib: {garch_vol:.4f}, arch: {arch_vol:.4f}")
                    
            except Exception as e:
                print(f"   é¢„æµ‹å¤±è´¥ at index {i}: {str(e)}")
                continue
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        if len(garch_predictions) > 0:
            garch_arr = np.array(garch_predictions)
            arch_arr = np.array(arch_predictions)
            
            correlation = np.corrcoef(garch_arr, arch_arr)[0, 1] if len(garch_arr) > 1 else 0
            mae = np.mean(np.abs(garch_arr - arch_arr))
            rmse = np.sqrt(np.mean((garch_arr - arch_arr)**2))
            mape = np.mean(np.abs((garch_arr - arch_arr) / arch_arr)) * 100
            
            return {
                'param_set': param_set,
                'success_count': success_count,
                'total_attempts': total_attempts,
                'success_rate': success_count / total_attempts,
                'garch_predictions': garch_predictions,
                'arch_predictions': arch_predictions,
                'prediction_indices': prediction_indices,
                'correlation': correlation,
                'mae': mae,
                'rmse': rmse,
                'mape': mape,
                'garch_mean': garch_arr.mean(),
                'arch_mean': arch_arr.mean(),
                'garch_std': garch_arr.std(),
                'arch_std': arch_arr.std()
            }
        else:
            return {'error': 'æ²¡æœ‰æˆåŠŸçš„é¢„æµ‹'}
    
    @classmethod
    def quick_grid_search(cls, data: np.ndarray, 
                         omega_range: Tuple[float, float] = (10.0, 25.0),
                         alpha_range: Tuple[float, float] = (0.15, 0.35),
                         beta_range: Tuple[float, float] = (0.60, 0.80),
                         grid_points: int = 5) -> Dict:
        """
        å¿«é€Ÿç½‘æ ¼æœç´¢ï¼ˆç”¨äºå¾®è°ƒå‚æ•°ï¼‰
        
        Args:
            data: æ”¶ç›Šç‡æ•°æ®
            omega_range: omegaå‚æ•°èŒƒå›´
            alpha_range: alphaå‚æ•°èŒƒå›´
            beta_range: betaå‚æ•°èŒƒå›´
            grid_points: æ¯ä¸ªå‚æ•°çš„ç½‘æ ¼ç‚¹æ•°
            
        Returns:
            æœç´¢ç»“æœ
        """
        # å…ˆç”¨archåº“ä¼°è®¡muå’Œnu
        try:
            arch_model_obj = arch_model(data, vol='Garch', p=1, q=1, dist='ged', rescale=False)
            arch_result = arch_model_obj.fit(disp='off', show_warning=False)
            mu = arch_result.params['mu']
            nu = arch_result.params['nu']
            arch_likelihood = arch_result.loglikelihood
        except:
            mu = data.mean()
            nu = 2.0
            arch_likelihood = -np.inf
        
        # ç½‘æ ¼æœç´¢
        omega_values = np.linspace(omega_range[0], omega_range[1], grid_points)
        alpha_values = np.linspace(alpha_range[0], alpha_range[1], grid_points)
        beta_values = np.linspace(beta_range[0], beta_range[1], grid_points)
        
        best_likelihood = -np.inf
        best_params = None
        results = []
        
        print(f"ğŸ” å¿«é€Ÿç½‘æ ¼æœç´¢: {grid_points}Â³ = {grid_points**3} ç»„åˆ")
        
        total_combinations = grid_points ** 3
        combination_count = 0
        
        for omega in omega_values:
            for alpha in alpha_values:
                for beta in beta_values:
                    combination_count += 1
                    
                    # æ£€æŸ¥å¹³ç¨³æ€§çº¦æŸ
                    if alpha + beta >= 0.999:
                        continue
                    
                    try:
                        calc = gc.GarchCalculator(history_size=len(data) + 10)
                        calc.add_returns(data.tolist())
                        
                        params = gc.GarchParameters()
                        params.mu = mu
                        params.omega = omega
                        params.alpha = alpha
                        params.beta = beta
                        params.nu = nu
                        
                        calc.set_parameters(params)
                        likelihood = calc.calculate_log_likelihood()
                        
                        if np.isfinite(likelihood):
                            result = {
                                'omega': omega, 'alpha': alpha, 'beta': beta,
                                'mu': mu, 'nu': nu, 'likelihood': likelihood
                            }
                            results.append(result)
                            
                            if likelihood > best_likelihood:
                                best_likelihood = likelihood
                                best_params = result.copy()
                                
                    except:
                        continue
                    
                    if combination_count % 25 == 0:
                        progress = combination_count / total_combinations * 100
                        print(f"   è¿›åº¦: {progress:.1f}%")
        
        return {
            'best_params': best_params,
            'best_likelihood': best_likelihood,
            'arch_likelihood': arch_likelihood,
            'total_results': len(results),
            'improvement': best_likelihood > arch_likelihood if arch_likelihood != -np.inf else True
        }
    
    @classmethod
    def show_available_params(cls) -> None:
        """æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„å‚æ•°é›†"""
        print("ğŸ“‹ å¯ç”¨çš„å‚æ•°é›†:")
        print("=" * 60)
        
        for name, params in cls.OPTIMIZED_PARAMS.items():
            print(f"\nğŸ¯ {name}:")
            print(f"   omega: {params['omega']:.6f}")
            print(f"   alpha: {params['alpha']:.6f}")
            print(f"   beta: {params['beta']:.6f}")
            print(f"   nu: {params['nu']:.6f}")
            if 'likelihood' in params:
                print(f"   ä¼¼ç„¶å€¼: {params['likelihood']:.6f}")
            print(f"   è¯´æ˜: {params['description']}")


def main():
    """æ¼”ç¤ºä½¿ç”¨æ–¹æ³•"""
    print("ğŸš€ Brettä¼˜åŒ–GARCHå‚æ•°å·¥å…·æ¼”ç¤º")
    print("=" * 60)
    
    # æ˜¾ç¤ºå¯ç”¨å‚æ•°é›†
    BrettOptimizedGarch.show_available_params()
    
    # è¯»å–æ•°æ®
    df = pd.read_csv('brett.csv')
    returns = df['c_scaled'].values[:300]
    
    print(f"\nğŸ“Š ä½¿ç”¨æ•°æ®: {len(returns)} ä¸ªç‚¹")
    
    # æµ‹è¯•é»˜è®¤å‚æ•°ä¸archåº“çš„å¯¹æ¯”
    print(f"\nğŸ” é»˜è®¤å‚æ•°ä¸archåº“å¯¹æ¯”:")
    comparison = BrettOptimizedGarch.compare_with_arch(returns, 'default')
    
    if 'error' not in comparison:
        print(f"   ä¼¼ç„¶å€¼å·®å¼‚: {comparison['likelihood_difference']:.6f}")
        print(f"   å‚æ•°å·®å¼‚:")
        for param, diff in comparison['param_differences'].items():
            print(f"     {param}: {diff:.6f}")
        print(f"   garch_libæ˜¯å¦æ›´ä¼˜: {comparison['improvement_over_arch']}")
    
    # å¿«é€Ÿç½‘æ ¼æœç´¢å¾®è°ƒ
    print(f"\nğŸ” å¿«é€Ÿç½‘æ ¼æœç´¢å¾®è°ƒ:")
    grid_result = BrettOptimizedGarch.quick_grid_search(returns, grid_points=4)
    
    if grid_result['best_params']:
        best = grid_result['best_params']
        print(f"   æœ€ä¼˜å‚æ•°: Ï‰={best['omega']:.4f}, Î±={best['alpha']:.4f}, Î²={best['beta']:.4f}")
        print(f"   ä¼¼ç„¶å€¼: {best['likelihood']:.6f}")
        print(f"   æ”¹è¿›ç¨‹åº¦: {grid_result['improvement']}")


if __name__ == "__main__":
    main() 