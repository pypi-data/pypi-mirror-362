#!/usr/bin/env python3
"""
å¤šè‚¡ç¥¨GARCH(1,1)-GEDæ¨¡å‹ç»¼åˆéªŒè¯è„šæœ¬
ä½¿ç”¨yfinanceè·å–å¤šåªè‚¡ç¥¨çš„é•¿æœŸå†å²æ•°æ®ï¼Œå…¨é¢æ¯”è¾ƒgarch_libå’ŒPython archåº“çš„è¡¨ç°

ğŸ”„ æ›´æ–°ï¼šç°åœ¨garch_libä¸archåº“ä½¿ç”¨å®Œå…¨ä¸€è‡´çš„è¾“å…¥ï¼ˆç›´æ¥ä½¿ç”¨æ”¶ç›Šç‡ï¼‰
ä¸å†éœ€è¦ä»·æ ¼è½¬æ¢å’Œç¼©æ”¾ï¼Œæä¾›æ›´ç²¾ç¡®çš„æ¯”è¾ƒç»“æœ
"""

import numpy as np
import pandas as pd
import time
import warnings
import sys
import os
import yfinance as yf
from datetime import datetime, timedelta
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor, as_completed
import json

warnings.filterwarnings('ignore')
sys.path.append('.')

try:
    from arch import arch_model
    HAS_ARCH = True
    print("âœ“ Successfully imported arch library")
except ImportError:
    HAS_ARCH = False
    print("âŒ Failed to import arch library")

try:
    import garch_lib as gc
    HAS_GARCH_LIB = True
    print("âœ“ Successfully imported garch_calculator")
except ImportError:
    HAS_GARCH_LIB = False
    print("âŒ Failed to import garch_calculator")

# å®šä¹‰è¦æµ‹è¯•çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆåŒ…å«ä¸åŒè¡Œä¸šå’Œæ³¢åŠ¨ç‡ç‰¹å¾ï¼‰
STOCK_SYMBOLS = {
    'GS': 'é«˜ç››é›†å›¢ (é‡‘è)',
    'AAPL': 'è‹¹æœå…¬å¸ (ç§‘æŠ€)',
    'MSFT': 'å¾®è½¯å…¬å¸ (ç§‘æŠ€)', 
    'JPM': 'æ‘©æ ¹å¤§é€š (é‡‘è)',
    'NVDA': 'è‹±ä¼Ÿè¾¾ (åŠå¯¼ä½“)',
    'TSLA': 'ç‰¹æ–¯æ‹‰ (æ±½è½¦)',
    'META': 'Metaå¹³å° (ç¤¾äº¤åª’ä½“)',
    'GOOGL': 'è°·æ­Œ (ç§‘æŠ€)',
    'AMZN': 'äºšé©¬é€Š (ç”µå•†)',
    'BAC': 'ç¾å›½é“¶è¡Œ (é‡‘è)',
    'XOM': 'åŸƒå…‹æ£®ç¾å­š (èƒ½æº)',
    'JNJ': 'å¼ºç”Ÿå…¬å¸ (åŒ»ç–—)',
    'V': 'Visa (é‡‘èæœåŠ¡)',
    'PG': 'å®æ´å…¬å¸ (æ¶ˆè´¹å“)',
    'HD': 'å®¶å¾—å® (é›¶å”®)'
}

class StockDataManager:
    """è‚¡ç¥¨æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, period="5y", interval="1d"):
        self.period = period
        self.interval = interval
        self.cache = {}
    
    def download_stock_data(self, symbol):
        """ä¸‹è½½å•åªè‚¡ç¥¨æ•°æ®"""
        if symbol in self.cache:
            return self.cache[symbol]
        
        try:
            stock = yf.Ticker(symbol)
            data = stock.history(period=self.period, interval=self.interval)
            
            if data.empty:
                print(f"âŒ {symbol}: æœªèƒ½è·å–åˆ°æ•°æ®")
                return None
            
            # æ•°æ®æ¸…ç†
            data = data.dropna()
            if len(data) < 500:  # è‡³å°‘éœ€è¦500ä¸ªæ•°æ®ç‚¹
                print(f"âš ï¸  {symbol}: æ•°æ®ç‚¹ä¸è¶³ ({len(data)})")
                return None
            
            print(f"âœ“ {symbol}: {len(data)} ä¸ªæ•°æ®ç‚¹, æ—¶é—´èŒƒå›´: {data.index[0].date()} åˆ° {data.index[-1].date()}")
            
            self.cache[symbol] = data
            return data
            
        except Exception as e:
            print(f"âŒ {symbol}: ä¸‹è½½å¤±è´¥ - {e}")
            return None
    
    def prepare_returns(self, stock_data, return_type="log"):
        """å‡†å¤‡æ”¶ç›Šç‡æ•°æ®"""
        prices = stock_data['Close'].dropna()
        
        if return_type == "log":
            returns = np.log(prices / prices.shift(1)).dropna()
        else:
            returns = (prices / prices.shift(1) - 1).dropna()
        
        # å»é™¤æç«¯å¼‚å¸¸å€¼ï¼ˆè¶…è¿‡6ä¸ªæ ‡å‡†å·®ï¼‰
        mean_return = returns.mean()
        std_return = returns.std()
        
        # ç»Ÿè®¡å¼‚å¸¸å€¼
        outliers_mask = np.abs(returns - mean_return) > 6 * std_return
        outliers_count = outliers_mask.sum()
        
        if outliers_count > 0:
            print(f"   å»é™¤ {outliers_count} ä¸ªæç«¯å¼‚å¸¸å€¼")
            returns = returns[~outliers_mask]
        
        # ä¸­å¿ƒåŒ–å¤„ç†
        returns = returns - returns.mean()
        
        return returns.values

class GarchModelTester:
    """GARCHæ¨¡å‹æµ‹è¯•å™¨"""
    
    def __init__(self, test_ratio=0.15):  # å‡å°‘æµ‹è¯•é›†æ¯”ä¾‹ï¼Œå¢åŠ è®­ç»ƒé›†
        self.test_ratio = test_ratio
    
    def test_arch_lib(self, returns, symbol="UNKNOWN"):
        """æµ‹è¯•Python archåº“"""
        if not HAS_ARCH:
            return None
            
        try:
            # åˆ†å‰²æ•°æ® - 85%è®­ç»ƒï¼Œ15%æµ‹è¯•
            split_point = int(len(returns) * (1 - self.test_ratio))
            train_returns = returns[:split_point]
            test_returns = returns[split_point:]
            
            start_time = time.time()
            
            # åˆ›å»ºå¹¶æ‹ŸåˆGARCH(1,1)-GEDæ¨¡å‹
            model = arch_model(train_returns, vol='GARCH', p=1, q=1, dist='ged', rescale=False)
            fitted_model = model.fit(disp='off', show_warning=False, options={'maxiter': 1000})
            fit_time = time.time() - start_time
            
            # è·å–å‚æ•°
            params = fitted_model.params
            
            # æ ·æœ¬å†…æ³¢åŠ¨ç‡
            start_vol_time = time.time()
            insample_volatility = fitted_model.conditional_volatility
            
            # æ ·æœ¬å¤–é¢„æµ‹
            forecast_horizon = len(test_returns)
            try:
                forecast = fitted_model.forecast(horizon=forecast_horizon, start=split_point)
                if forecast.variance.values.shape[0] > 0:
                    forecast_volatility = np.sqrt(forecast.variance.values[-1, :])
                else:
                    last_vol = insample_volatility[-1] if len(insample_volatility) > 0 else np.std(train_returns)
                    forecast_volatility = np.full(forecast_horizon, last_vol)
            except:
                last_vol = insample_volatility[-1] if len(insample_volatility) > 0 else np.std(train_returns)
                forecast_volatility = np.full(forecast_horizon, last_vol)
            
            vol_prediction_time = time.time() - start_vol_time
            
            # è®¡ç®—å®é™…æ³¢åŠ¨ç‡ï¼ˆæ»šåŠ¨æ ‡å‡†å·®ï¼‰
            window_size = min(20, len(test_returns) // 3)  # æ›´å¤§çš„çª—å£
            actual_volatility = []
            for i in range(len(test_returns)):
                if i < window_size:
                    actual_vol = np.std(test_returns[:i+1]) if i > 0 else np.std(train_returns[-window_size:])
                else:
                    actual_vol = np.std(test_returns[max(0, i-window_size):i+1])
                actual_volatility.append(actual_vol)
            actual_volatility = np.array(actual_volatility)
            
            result = {
                'library': 'arch',
                'symbol': symbol,
                'omega': params['omega'],
                'alpha': params['alpha[1]'],
                'beta': params['beta[1]'],
                'nu': params['nu'],
                'log_likelihood': fitted_model.loglikelihood,
                'aic': fitted_model.aic,
                'bic': fitted_model.bic,
                'fit_time': fit_time,
                'vol_prediction_time': vol_prediction_time,
                'converged': fitted_model.convergence_flag == 0,
                'train_size': len(train_returns),
                'test_size': len(test_returns),
                'persistence': params['alpha[1]'] + params['beta[1]'],
                'unconditional_vol': np.sqrt(params['omega'] / (1 - params['alpha[1]'] - params['beta[1]'])),
                'insample_volatility': insample_volatility,
                'forecast_volatility': forecast_volatility,
                'actual_volatility': actual_volatility
            }
            
            # è®¡ç®—é¢„æµ‹ç²¾åº¦æŒ‡æ ‡
            if len(forecast_volatility) == len(actual_volatility):
                result['forecast_mse'] = mean_squared_error(actual_volatility, forecast_volatility)
                result['forecast_mae'] = mean_absolute_error(actual_volatility, forecast_volatility)
                result['forecast_rmse'] = np.sqrt(result['forecast_mse'])
                
                # è®¡ç®—æ›´å¤šé¢„æµ‹ç²¾åº¦æŒ‡æ ‡
                result['forecast_mape'] = np.mean(np.abs((actual_volatility - forecast_volatility) / actual_volatility)) * 100
                result['forecast_r2'] = 1 - (np.sum((actual_volatility - forecast_volatility)**2) / 
                                            np.sum((actual_volatility - np.mean(actual_volatility))**2))
            
            return result
            
        except Exception as e:
            print(f"âŒ {symbol} archåº“æµ‹è¯•å¤±è´¥: {e}")
            return None
    
    def test_garch_lib(self, returns, symbol="UNKNOWN"):
        """æµ‹è¯•garch_libå®ç° - ç°åœ¨ä¸archåº“ä½¿ç”¨å®Œå…¨ä¸€è‡´çš„è¾“å…¥"""
        if not HAS_GARCH_LIB:
            return None
            
        try:
            # åˆ†å‰²æ•°æ® - 85%è®­ç»ƒï¼Œ15%æµ‹è¯•
            split_point = int(len(returns) * (1 - self.test_ratio))
            train_returns = returns[:split_point]
            test_returns = returns[split_point:]
            
            start_time = time.time()
            
            # åˆ›å»ºè®¡ç®—å™¨
            min_samples = min(100, len(train_returns) // 5)
            calc = gc.GarchCalculator(history_size=len(train_returns)+200, min_samples=min_samples)
            
            # ç›´æ¥æ·»åŠ æ”¶ç›Šç‡æ•°æ® - ä¸archåº“å®Œå…¨ä¸€è‡´ï¼
            calc.add_returns(train_returns.tolist())
            
            # ä¼°è®¡å‚æ•°
            result_obj = calc.estimate_parameters()
            fit_time = time.time() - start_time
            
            params = result_obj.parameters
            
            # æ ·æœ¬å†…æ³¢åŠ¨ç‡é¢„æµ‹
            start_vol_time = time.time()
            try:
                variance_series = calc.get_variance_series()
                if len(variance_series) > 0:
                    insample_volatility = np.sqrt(variance_series)
                else:
                    current_vol = calc.get_current_volatility()
                    insample_volatility = np.full(len(train_returns), current_vol)
            except:
                current_vol = calc.get_current_volatility()
                insample_volatility = np.full(len(train_returns), current_vol)
            
            # æ ·æœ¬å¤–é¢„æµ‹
            forecast_volatility = []
            
            for i in range(len(test_returns)):
                try:
                    # é¢„æµ‹ä¸‹ä¸€æœŸæ³¢åŠ¨ç‡
                    forecast_obj = calc.forecast_volatility(1)
                    if forecast_obj.volatility > 0 and np.isfinite(forecast_obj.volatility):
                        forecast_volatility.append(forecast_obj.volatility)
                    else:
                        current_vol = calc.get_current_volatility()
                        forecast_volatility.append(current_vol)
                    
                    # æ·»åŠ å®é™…æ”¶ç›Šç‡å¹¶æ›´æ–°æ¨¡å‹ï¼ˆä¸€æ­¥é¢„æµ‹ï¼‰
                    calc.add_return(test_returns[i])
                    calc.update_model()
                    
                except Exception as e:
                    try:
                        current_vol = calc.get_current_volatility()
                        forecast_volatility.append(current_vol)
                    except:
                        forecast_volatility.append(np.std(train_returns))
                    break
                
            forecast_volatility = np.array(forecast_volatility)
            vol_prediction_time = time.time() - start_vol_time
            
            # è®¡ç®—å®é™…æ³¢åŠ¨ç‡ï¼ˆæ»šåŠ¨æ ‡å‡†å·®ï¼‰
            window_size = min(20, len(test_returns) // 3)
            actual_volatility = []
            for i in range(len(test_returns)):
                if i < window_size:
                    actual_vol = np.std(test_returns[:i+1]) if i > 0 else np.std(train_returns[-window_size:])
                else:
                    actual_vol = np.std(test_returns[max(0, i-window_size):i+1])
                actual_volatility.append(actual_vol)
            actual_volatility = np.array(actual_volatility)
            
            result = {
                'library': 'garch_lib',
                'symbol': symbol,
                'omega': params.omega,
                'alpha': params.alpha,
                'beta': params.beta,
                'nu': params.nu,
                'log_likelihood': result_obj.log_likelihood,
                'aic': result_obj.aic,
                'bic': result_obj.bic,
                'fit_time': fit_time,
                'vol_prediction_time': vol_prediction_time,
                'converged': result_obj.converged,
                'iterations': result_obj.iterations,
                'train_size': len(train_returns),
                'test_size': len(test_returns),
                'persistence': params.alpha + params.beta,
                'unconditional_vol': np.sqrt(params.omega / (1 - params.alpha - params.beta)) if (params.alpha + params.beta) < 1 else np.inf,
                'insample_volatility': insample_volatility,
                'forecast_volatility': forecast_volatility,
                'actual_volatility': actual_volatility
            }
            
            # è®¡ç®—é¢„æµ‹ç²¾åº¦æŒ‡æ ‡
            if len(forecast_volatility) == len(actual_volatility):
                result['forecast_mse'] = mean_squared_error(actual_volatility, forecast_volatility)
                result['forecast_mae'] = mean_absolute_error(actual_volatility, forecast_volatility)
                result['forecast_rmse'] = np.sqrt(result['forecast_mse'])
                result['forecast_mape'] = np.mean(np.abs((actual_volatility - forecast_volatility) / actual_volatility)) * 100
                result['forecast_r2'] = 1 - (np.sum((actual_volatility - forecast_volatility)**2) / 
                                            np.sum((actual_volatility - np.mean(actual_volatility))**2))
            elif len(forecast_volatility) > 0 and len(actual_volatility) > 0:
                min_len = min(len(forecast_volatility), len(actual_volatility))
                result['forecast_mse'] = mean_squared_error(actual_volatility[:min_len], forecast_volatility[:min_len])
                result['forecast_mae'] = mean_absolute_error(actual_volatility[:min_len], forecast_volatility[:min_len])
                result['forecast_rmse'] = np.sqrt(result['forecast_mse'])
                result['forecast_mape'] = np.mean(np.abs((actual_volatility[:min_len] - forecast_volatility[:min_len]) / actual_volatility[:min_len])) * 100
                result['forecast_r2'] = 1 - (np.sum((actual_volatility[:min_len] - forecast_volatility[:min_len])**2) / 
                                            np.sum((actual_volatility[:min_len] - np.mean(actual_volatility[:min_len]))**2))
            
            return result
                
        except Exception as e:
            print(f"âŒ {symbol} garch_libæµ‹è¯•å¤±è´¥: {e}")
            return None

def test_single_stock(symbol, description, data_manager, tester):
    """æµ‹è¯•å•åªè‚¡ç¥¨"""
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ {symbol} - {description}")
    print('='*80)
    
    # ä¸‹è½½æ•°æ®
    stock_data = data_manager.download_stock_data(symbol)
    if stock_data is None:
        return None
    
    # å‡†å¤‡æ”¶ç›Šç‡æ•°æ®
    returns = data_manager.prepare_returns(stock_data, return_type="log")
    
    if len(returns) < 500:
        print(f"âŒ {symbol}: æ•°æ®ç‚¹å¤ªå°‘ ({len(returns)})")
        return None
    
    print(f"ğŸ“Š æ”¶ç›Šç‡ç»Ÿè®¡:")
    print(f"   æ•°æ®ç‚¹æ•°: {len(returns)}")
    print(f"   å‡å€¼: {returns.mean():.8f}")
    print(f"   æ ‡å‡†å·®: {returns.std():.6f}")
    print(f"   ååº¦: {pd.Series(returns).skew():.4f}")
    print(f"   å³°åº¦: {pd.Series(returns).kurtosis():.4f}")
    print(f"   è®­ç»ƒé›†: {int(len(returns) * 0.85)} ç‚¹")
    print(f"   æµ‹è¯•é›†: {len(returns) - int(len(returns) * 0.85)} ç‚¹")
    
    # æµ‹è¯•ä¸¤ä¸ªåº“
    arch_result = tester.test_arch_lib(returns, symbol)
    garch_result = tester.test_garch_lib(returns, symbol)
    
    if arch_result:
        print(f"\nâœ… {symbol} - Python archåº“æµ‹è¯•å®Œæˆ")
        print(f"   å‚æ•°: Ï‰={arch_result['omega']:.6f}, Î±={arch_result['alpha']:.4f}, Î²={arch_result['beta']:.4f}, Î½={arch_result['nu']:.4f}")
        print(f"   æ”¶æ•›: {'æ˜¯' if arch_result['converged'] else 'å¦'}, æ—¶é—´: {arch_result['fit_time']:.3f}ç§’")
        if 'forecast_rmse' in arch_result:
            print(f"   é¢„æµ‹RMSE: {arch_result['forecast_rmse']:.6f}")
    
    if garch_result:
        print(f"\nâœ… {symbol} - garch_libæµ‹è¯•å®Œæˆ (ä½¿ç”¨æ”¶ç›Šç‡è¾“å…¥)")
        print(f"   å‚æ•°: Ï‰={garch_result['omega']:.6f}, Î±={garch_result['alpha']:.4f}, Î²={garch_result['beta']:.4f}, Î½={garch_result['nu']:.4f}")
        print(f"   æ”¶æ•›: {'æ˜¯' if garch_result['converged'] else 'å¦'}, è¿­ä»£: {garch_result.get('iterations', 'N/A')}, æ—¶é—´: {garch_result['fit_time']:.3f}ç§’")
        if 'forecast_rmse' in garch_result:
            print(f"   é¢„æµ‹RMSE: {garch_result['forecast_rmse']:.6f}")
    
    return {
        'symbol': symbol,
        'description': description,
        'data_points': len(returns),
        'returns_stats': {
            'mean': returns.mean(),
            'std': returns.std(),
            'skewness': pd.Series(returns).skew(),
            'kurtosis': pd.Series(returns).kurtosis()
        },
        'arch_result': arch_result,
        'garch_result': garch_result
    }

def generate_comprehensive_report(all_results):
    """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
    print(f"\n\n{'='*100}")
    print("ğŸ“Š å¤šè‚¡ç¥¨GARCHæ¨¡å‹ç»¼åˆéªŒè¯æŠ¥å‘Š")
    print('='*100)
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    valid_results = [r for r in all_results if r and r['arch_result'] and r['garch_result']]
    
    if not valid_results:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ¯”è¾ƒç»“æœ")
        return
    
    print(f"ğŸ“ˆ æˆåŠŸæµ‹è¯•çš„è‚¡ç¥¨æ•°é‡: {len(valid_results)}")
    print(f"ğŸ“Š æ€»æ•°æ®ç‚¹: {sum(r['data_points'] for r in valid_results):,}")
    
    # 1. å‚æ•°ä¸€è‡´æ€§åˆ†æ
    print(f"\n{'='*60}")
    print("1. å‚æ•°ä¼°è®¡ä¸€è‡´æ€§åˆ†æ")
    print('='*60)
    
    param_errors = []
    convergence_stats = {'arch_converged': 0, 'garch_converged': 0, 'both_converged': 0}
    
    for result in valid_results:
        arch_res = result['arch_result']
        garch_res = result['garch_result']
        
        # æ”¶æ•›æ€§ç»Ÿè®¡
        if arch_res['converged']:
            convergence_stats['arch_converged'] += 1
        if garch_res['converged']:
            convergence_stats['garch_converged'] += 1
        if arch_res['converged'] and garch_res['converged']:
            convergence_stats['both_converged'] += 1
        
        # å‚æ•°å·®å¼‚
        params = ['omega', 'alpha', 'beta', 'nu']
        stock_param_errors = []
        for param in params:
            arch_val = arch_res[param]
            garch_val = garch_res[param]
            rel_diff = abs(garch_val - arch_val) / abs(arch_val) * 100 if abs(arch_val) > 0 else 0
            stock_param_errors.append(rel_diff)
        
        param_errors.append({
            'symbol': result['symbol'],
            'omega_error': stock_param_errors[0],
            'alpha_error': stock_param_errors[1],
            'beta_error': stock_param_errors[2],
            'nu_error': stock_param_errors[3],
            'avg_error': np.mean(stock_param_errors)
        })
    
    # å‚æ•°è¯¯å·®ç»Ÿè®¡
    df_errors = pd.DataFrame(param_errors)
    print(f"\nå‚æ•°ä¼°è®¡ç›¸å¯¹è¯¯å·®ç»Ÿè®¡ (%):")
    print(f"{'å‚æ•°':<8} {'å¹³å‡':<8} {'ä¸­ä½æ•°':<8} {'æ ‡å‡†å·®':<8} {'æœ€å¤§å€¼':<8}")
    print("-" * 48)
    for param in ['omega', 'alpha', 'beta', 'nu', 'avg']:
        col = f"{param}_error"
        print(f"{param:<8} {df_errors[col].mean():<8.2f} {df_errors[col].median():<8.2f} {df_errors[col].std():<8.2f} {df_errors[col].max():<8.2f}")
    
    # æ”¶æ•›æ€§ç»Ÿè®¡
    print(f"\næ”¶æ•›æ€§ç»Ÿè®¡:")
    print(f"archåº“æ”¶æ•›ç‡: {convergence_stats['arch_converged']}/{len(valid_results)} ({convergence_stats['arch_converged']/len(valid_results)*100:.1f}%)")
    print(f"garch_libæ”¶æ•›ç‡: {convergence_stats['garch_converged']}/{len(valid_results)} ({convergence_stats['garch_converged']/len(valid_results)*100:.1f}%)")
    print(f"ä¸¤è€…éƒ½æ”¶æ•›: {convergence_stats['both_converged']}/{len(valid_results)} ({convergence_stats['both_converged']/len(valid_results)*100:.1f}%)")
    
    # 2. é¢„æµ‹ç²¾åº¦åˆ†æ
    print(f"\n{'='*60}")
    print("2. é¢„æµ‹ç²¾åº¦å¯¹æ¯”åˆ†æ")
    print('='*60)
    
    prediction_stats = []
    for result in valid_results:
        arch_res = result['arch_result']
        garch_res = result['garch_result']
        
        if 'forecast_rmse' in arch_res and 'forecast_rmse' in garch_res:
            rmse_improvement = (arch_res['forecast_rmse'] - garch_res['forecast_rmse']) / arch_res['forecast_rmse'] * 100
            mae_improvement = (arch_res['forecast_mae'] - garch_res['forecast_mae']) / arch_res['forecast_mae'] * 100
            
            prediction_stats.append({
                'symbol': result['symbol'],
                'arch_rmse': arch_res['forecast_rmse'],
                'garch_rmse': garch_res['forecast_rmse'],
                'rmse_improvement': rmse_improvement,
                'mae_improvement': mae_improvement,
                'arch_r2': arch_res.get('forecast_r2', 0),
                'garch_r2': garch_res.get('forecast_r2', 0)
            })
    
    if prediction_stats:
        df_pred = pd.DataFrame(prediction_stats)
        print(f"\né¢„æµ‹ç²¾åº¦æ”¹å–„ç»Ÿè®¡ (æ­£æ•°è¡¨ç¤ºgarch_libæ›´å¥½):")
        print(f"RMSEæ”¹å–„ - å¹³å‡: {df_pred['rmse_improvement'].mean():.2f}%, ä¸­ä½æ•°: {df_pred['rmse_improvement'].median():.2f}%")
        print(f"MAEæ”¹å–„ - å¹³å‡: {df_pred['mae_improvement'].mean():.2f}%, ä¸­ä½æ•°: {df_pred['mae_improvement'].median():.2f}%")
        
        better_count = (df_pred['rmse_improvement'] > 0).sum()
        worse_count = (df_pred['rmse_improvement'] < -5).sum()
        similar_count = len(df_pred) - better_count - worse_count
        
        print(f"\ngarch_libé¢„æµ‹æ›´å¥½: {better_count}/{len(df_pred)} ({better_count/len(df_pred)*100:.1f}%)")
        print(f"é¢„æµ‹ç²¾åº¦ç›¸ä¼¼: {similar_count}/{len(df_pred)} ({similar_count/len(df_pred)*100:.1f}%)")
        print(f"arché¢„æµ‹æ›´å¥½: {worse_count}/{len(df_pred)} ({worse_count/len(df_pred)*100:.1f}%)")
    
    # 3. æ€§èƒ½åˆ†æ
    print(f"\n{'='*60}")
    print("3. è®¡ç®—æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print('='*60)
    
    performance_stats = []
    for result in valid_results:
        arch_res = result['arch_result']
        garch_res = result['garch_result']
        
        fit_speedup = arch_res['fit_time'] / garch_res['fit_time'] if garch_res['fit_time'] > 0 else 0
        vol_speedup = arch_res['vol_prediction_time'] / garch_res['vol_prediction_time'] if garch_res['vol_prediction_time'] > 0 else 0
        
        performance_stats.append({
            'symbol': result['symbol'],
            'arch_fit_time': arch_res['fit_time'],
            'garch_fit_time': garch_res['fit_time'],
            'fit_speedup': fit_speedup,
            'vol_speedup': vol_speedup
        })
    
    df_perf = pd.DataFrame(performance_stats)
    print(f"\næ€§èƒ½æå‡ç»Ÿè®¡:")
    print(f"æ‹Ÿåˆé€Ÿåº¦æå‡ - å¹³å‡: {df_perf['fit_speedup'].mean():.2f}x, ä¸­ä½æ•°: {df_perf['fit_speedup'].median():.2f}x")
    print(f"é¢„æµ‹é€Ÿåº¦æå‡ - å¹³å‡: {df_perf['vol_speedup'].mean():.2f}x, ä¸­ä½æ•°: {df_perf['vol_speedup'].median():.2f}x")
    
    # 4. æŒ‰è¡Œä¸šåˆ†æ
    print(f"\n{'='*60}")
    print("4. æŒ‰è¡Œä¸š/ç‰¹å¾åˆ†ç»„åˆ†æ")
    print('='*60)
    
    # æ ¹æ®è‚¡ç¥¨ç‰¹å¾åˆ†ç»„
    industry_groups = {
        'é‡‘è': ['GS', 'JPM', 'BAC', 'V'],
        'ç§‘æŠ€': ['AAPL', 'MSFT', 'GOOGL', 'META'],
        'é«˜æ³¢åŠ¨': ['NVDA', 'TSLA'],
        'æ¶ˆè´¹/èƒ½æº': ['AMZN', 'XOM', 'JNJ', 'PG', 'HD']
    }
    
    for industry, symbols in industry_groups.items():
        industry_results = [r for r in valid_results if r['symbol'] in symbols]
        if not industry_results:
            continue
        
        print(f"\n{industry}æ¿å— ({len(industry_results)}åªè‚¡ç¥¨):")
        
        avg_param_error = np.mean([np.mean([
            abs(r['garch_result'][p] - r['arch_result'][p]) / abs(r['arch_result'][p]) * 100 
            if abs(r['arch_result'][p]) > 0 else 0
            for p in ['omega', 'alpha', 'beta', 'nu']
        ]) for r in industry_results])
        
        if any('forecast_rmse' in r['arch_result'] and 'forecast_rmse' in r['garch_result'] for r in industry_results):
            avg_rmse_improvement = np.mean([
                (r['arch_result']['forecast_rmse'] - r['garch_result']['forecast_rmse']) / r['arch_result']['forecast_rmse'] * 100
                for r in industry_results 
                if 'forecast_rmse' in r['arch_result'] and 'forecast_rmse' in r['garch_result']
            ])
            print(f"   å¹³å‡å‚æ•°è¯¯å·®: {avg_param_error:.2f}%")
            print(f"   å¹³å‡RMSEæ”¹å–„: {avg_rmse_improvement:.2f}%")
        else:
            print(f"   å¹³å‡å‚æ•°è¯¯å·®: {avg_param_error:.2f}%")
    
    # 5. è¯¦ç»†å¯¹æ¯”è¡¨
    print(f"\n{'='*60}")
    print("5. å„è‚¡ç¥¨è¯¦ç»†å¯¹æ¯”è¡¨")
    print('='*60)
    
    print(f"{'è‚¡ç¥¨':<6} {'å‚æ•°è¯¯å·®%':<10} {'RMSEæ”¹å–„%':<10} {'æ‹Ÿåˆæ—¶é—´æ¯”':<10} {'æ”¶æ•›çŠ¶æ€':<15}")
    print("-" * 65)
    
    for result in valid_results:
        arch_res = result['arch_result']
        garch_res = result['garch_result']
        
        avg_param_error = np.mean([
            abs(garch_res[p] - arch_res[p]) / abs(arch_res[p]) * 100 
            if abs(arch_res[p]) > 0 else 0
            for p in ['omega', 'alpha', 'beta', 'nu']
        ])
        
        if 'forecast_rmse' in arch_res and 'forecast_rmse' in garch_res:
            rmse_improvement = (arch_res['forecast_rmse'] - garch_res['forecast_rmse']) / arch_res['forecast_rmse'] * 100
        else:
            rmse_improvement = 0
        
        fit_ratio = garch_res['fit_time'] / arch_res['fit_time'] if arch_res['fit_time'] > 0 else 0
        
        convergence = f"{'A' if arch_res['converged'] else 'a'}{'G' if garch_res['converged'] else 'g'}"
        
        print(f"{result['symbol']:<6} {avg_param_error:<10.2f} {rmse_improvement:<10.2f} {fit_ratio:<10.2f} {convergence:<15}")
    
    return {
        'total_stocks': len(valid_results),
        'convergence_stats': convergence_stats,
        'param_errors': df_errors,
        'prediction_stats': df_pred if prediction_stats else None,
        'performance_stats': df_perf
    }

def save_comprehensive_results(all_results, summary_stats):
    """ä¿å­˜ç»¼åˆç»“æœ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_results = []
    for result in all_results:
        if result and result['arch_result'] and result['garch_result']:
            detailed_results.append({
                'symbol': result['symbol'],
                'description': result['description'],
                'data_points': result['data_points'],
                'returns_mean': result['returns_stats']['mean'],
                'returns_std': result['returns_stats']['std'],
                'returns_skewness': result['returns_stats']['skewness'],
                'returns_kurtosis': result['returns_stats']['kurtosis'],
                
                # archç»“æœ
                'arch_omega': result['arch_result']['omega'],
                'arch_alpha': result['arch_result']['alpha'],
                'arch_beta': result['arch_result']['beta'],
                'arch_nu': result['arch_result']['nu'],
                'arch_log_likelihood': result['arch_result']['log_likelihood'],
                'arch_aic': result['arch_result']['aic'],
                'arch_bic': result['arch_result']['bic'],
                'arch_fit_time': result['arch_result']['fit_time'],
                'arch_converged': result['arch_result']['converged'],
                'arch_forecast_rmse': result['arch_result'].get('forecast_rmse', np.nan),
                'arch_forecast_r2': result['arch_result'].get('forecast_r2', np.nan),
                
                # garch_libç»“æœ
                'garch_omega': result['garch_result']['omega'],
                'garch_alpha': result['garch_result']['alpha'],
                'garch_beta': result['garch_result']['beta'],
                'garch_nu': result['garch_result']['nu'],
                'garch_log_likelihood': result['garch_result']['log_likelihood'],
                'garch_aic': result['garch_result']['aic'],
                'garch_bic': result['garch_result']['bic'],
                'garch_fit_time': result['garch_result']['fit_time'],
                'garch_converged': result['garch_result']['converged'],
                'garch_iterations': result['garch_result'].get('iterations', np.nan),
                'garch_forecast_rmse': result['garch_result'].get('forecast_rmse', np.nan),
                'garch_forecast_r2': result['garch_result'].get('forecast_r2', np.nan),
                
                # æ¯”è¾ƒæŒ‡æ ‡
                'param_avg_error': np.mean([
                    abs(result['garch_result'][p] - result['arch_result'][p]) / abs(result['arch_result'][p]) * 100 
                    if abs(result['arch_result'][p]) > 0 else 0
                    for p in ['omega', 'alpha', 'beta', 'nu']
                ]),
                'rmse_improvement': (result['arch_result'].get('forecast_rmse', 0) - 
                                   result['garch_result'].get('forecast_rmse', 0)) / 
                                   result['arch_result'].get('forecast_rmse', 1) * 100,
                'fit_speedup': result['arch_result']['fit_time'] / result['garch_result']['fit_time'] 
                              if result['garch_result']['fit_time'] > 0 else 0
            })
    
    # ä¿å­˜åˆ°CSV
    if detailed_results:
        df_detailed = pd.DataFrame(detailed_results)
        csv_file = f"multi_stock_garch_validation_{timestamp}.csv"
        df_detailed.to_csv(csv_file, index=False)
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {csv_file}")
    
    # ä¿å­˜æ±‡æ€»ç»Ÿè®¡
    summary_file = f"validation_summary_{timestamp}.json"
    with open(summary_file, 'w') as f:
        json.dump({
            'timestamp': timestamp,
            'total_stocks_tested': len(all_results),
            'successful_comparisons': len(detailed_results),
            'convergence_stats': summary_stats['convergence_stats'] if summary_stats else {},
            'param_error_stats': summary_stats['param_errors'].describe().to_dict() if summary_stats and 'param_errors' in summary_stats else {},
            'stocks_list': list(STOCK_SYMBOLS.keys())
        }, f, indent=2, default=str)
    
    print(f"ğŸ’¾ æ±‡æ€»ç»Ÿè®¡å·²ä¿å­˜åˆ°: {summary_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 100)
    print("ğŸ¦ å¤šè‚¡ç¥¨GARCH(1,1)-GEDæ¨¡å‹ç»¼åˆéªŒè¯ç³»ç»Ÿ")
    print("ğŸ”„ æ›´æ–°ï¼šgarch_libç°åœ¨ä¸archåº“ä½¿ç”¨å®Œå…¨ä¸€è‡´çš„è¾“å…¥")
    print("=" * 100)
    print(f"æµ‹è¯•è‚¡ç¥¨æ•°é‡: {len(STOCK_SYMBOLS)}")
    print(f"æ•°æ®å‘¨æœŸ: 5å¹´å†å²æ•°æ®")
    print(f"è®­ç»ƒ/æµ‹è¯•æ¯”ä¾‹: 85%/15%")
    print(f"è¾“å…¥æ ¼å¼: ç›´æ¥ä½¿ç”¨æ”¶ç›Šç‡æ•°æ® (ä¸archåº“ä¸€è‡´)")
    print()
    
    # æ£€æŸ¥ä¾èµ–
    if not HAS_ARCH and not HAS_GARCH_LIB:
        print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•GARCHåº“ï¼Œè¯·å®‰è£…archæˆ–ç¼–è¯‘garch_lib")
        return
    
    try:
        # åˆå§‹åŒ–ç®¡ç†å™¨
        data_manager = StockDataManager(period="5y", interval="1d")
        tester = GarchModelTester(test_ratio=0.15)
        
        # æŒ‰æ‰¹æ¬¡æµ‹è¯•è‚¡ç¥¨ï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰
        all_results = []
        batch_size = 5
        stock_items = list(STOCK_SYMBOLS.items())
        
        for i in range(0, len(stock_items), batch_size):
            batch = stock_items[i:i+batch_size]
            print(f"\nğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(stock_items)-1)//batch_size + 1}")
            
            # ä¸²è¡Œå¤„ç†æ¯åªè‚¡ç¥¨ï¼ˆé¿å…å¹¶å‘é—®é¢˜ï¼‰
            for symbol, description in batch:
                result = test_single_stock(symbol, description, data_manager, tester)
                all_results.append(result)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        summary_stats = generate_comprehensive_report(all_results)
        
        # ä¿å­˜ç»“æœ
        save_comprehensive_results(all_results, summary_stats)
        
        print(f"\nâœ… å¤šè‚¡ç¥¨éªŒè¯å®Œæˆ! æ€»å…±æµ‹è¯•äº† {len([r for r in all_results if r])} åªè‚¡ç¥¨")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­éªŒè¯è¿‡ç¨‹")
    except Exception as e:
        print(f"\nâŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 