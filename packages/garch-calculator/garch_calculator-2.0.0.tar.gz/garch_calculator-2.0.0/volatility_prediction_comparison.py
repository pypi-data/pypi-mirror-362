#!/usr/bin/env python3
"""
ç½‘æ ¼æœç´¢å‚æ•° vs archåº“GARCH(1,1)-GED æ³¢åŠ¨ç‡é¢„æµ‹å¯¹æ¯”ç¨‹åº
ä¸“é—¨é’ˆå¯¹brett.csvæ•°æ®è¿›è¡Œè¯¦ç»†çš„é¢„æµ‹æ€§èƒ½è¯„ä¼°
"""

import garch_lib as gc
import pandas as pd
import numpy as np
from arch import arch_model
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple
import json
import time
from brett_optimized_garch import BrettOptimizedGarch

class VolatilityPredictionComparison:
    """æ³¢åŠ¨ç‡é¢„æµ‹å¯¹æ¯”ç±»"""
    
    def __init__(self, data: np.ndarray, test_name: str = "brett_comparison"):
        """
        åˆå§‹åŒ–å¯¹æ¯”æµ‹è¯•
        
        Args:
            data: æ”¶ç›Šç‡æ•°æ®
            test_name: æµ‹è¯•åç§°
        """
        self.data = data
        self.test_name = test_name
        self.results = {}
        
    def run_grid_search_optimization(self, grid_points: int = 6) -> Dict:
        """
        è¿è¡Œç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°
        
        Args:
            grid_points: ç½‘æ ¼æœç´¢ç‚¹æ•°
            
        Returns:
            ç½‘æ ¼æœç´¢ç»“æœ
        """
        print("ğŸ” æ‰§è¡Œç½‘æ ¼æœç´¢å‚æ•°ä¼˜åŒ–...")
        
        # ä½¿ç”¨æ›´ç²¾ç»†çš„ç½‘æ ¼æœç´¢
        grid_result = BrettOptimizedGarch.quick_grid_search(
            self.data, 
            omega_range=(10.0, 30.0),
            alpha_range=(0.10, 0.40), 
            beta_range=(0.55, 0.85),
            grid_points=grid_points
        )
        
        if grid_result['best_params']:
            print(f"âœ… ç½‘æ ¼æœç´¢å®Œæˆ")
            print(f"   æœ€ä¼˜å‚æ•°: Ï‰={grid_result['best_params']['omega']:.4f}, "
                  f"Î±={grid_result['best_params']['alpha']:.4f}, "
                  f"Î²={grid_result['best_params']['beta']:.4f}")
            print(f"   æœ€ä¼˜ä¼¼ç„¶å€¼: {grid_result['best_likelihood']:.6f}")
            
            if grid_result['arch_likelihood'] != -np.inf:
                improvement = grid_result['best_likelihood'] - grid_result['arch_likelihood']
                print(f"   ç›¸å¯¹archåº“æ”¹è¿›: {improvement:.6f}")
        
        return grid_result
    
    def rolling_forecast_comparison(self, window_size: int = 200, 
                                  forecast_horizon: int = 1,
                                  use_optimized_params: bool = True) -> Dict:
        """
        æ»šåŠ¨çª—å£é¢„æµ‹å¯¹æ¯”
        
        Args:
            window_size: æ»šåŠ¨çª—å£å¤§å°
            forecast_horizon: é¢„æµ‹æ­¥é•¿
            use_optimized_params: æ˜¯å¦ä½¿ç”¨ç½‘æ ¼æœç´¢ä¼˜åŒ–çš„å‚æ•°
            
        Returns:
            å¯¹æ¯”ç»“æœå­—å…¸
        """
        print(f"\nğŸ”„ æ»šåŠ¨çª—å£é¢„æµ‹å¯¹æ¯”")
        print(f"   çª—å£å¤§å°: {window_size}, é¢„æµ‹æ­¥é•¿: {forecast_horizon}")
        print(f"   æ•°æ®æ€»é•¿åº¦: {len(self.data)}")
        
        # å¦‚æœä½¿ç”¨ä¼˜åŒ–å‚æ•°ï¼Œå…ˆè¿›è¡Œç½‘æ ¼æœç´¢
        if use_optimized_params:
            grid_result = self.run_grid_search_optimization()
            if not grid_result['best_params']:
                print("âŒ ç½‘æ ¼æœç´¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                use_optimized_params = False
        
        # å­˜å‚¨é¢„æµ‹ç»“æœ
        garch_lib_predictions = []
        arch_lib_predictions = []
        prediction_indices = []
        garch_lib_likelihoods = []
        arch_lib_likelihoods = []
        
        # å­˜å‚¨å‚æ•°æ¼”åŒ–ï¼ˆå¦‚æœä¸ä½¿ç”¨å›ºå®šä¼˜åŒ–å‚æ•°ï¼‰
        garch_lib_params_history = []
        arch_lib_params_history = []
        
        successful_predictions = 0
        total_attempts = 0
        
        start_time = time.time()
        
        for i in range(window_size, len(self.data)):
            total_attempts += 1
            window_data = self.data[i-window_size:i]
            
            try:
                # === ARCHåº“é¢„æµ‹ï¼ˆåŸºå‡†ï¼‰ ===
                arch_model_obj = arch_model(window_data, vol='Garch', p=1, q=1, dist='ged', rescale=False)
                arch_result = arch_model_obj.fit(disp='off', show_warning=False)
                
                # æ£€æŸ¥æ”¶æ•›
                if arch_result.convergence_flag != 0:
                    continue
                    
                # archåº“é¢„æµ‹
                arch_forecast = arch_result.forecast(horizon=forecast_horizon, reindex=False)
                arch_vol = np.sqrt(arch_forecast.variance.values[-1, 0])
                arch_lib_predictions.append(arch_vol)
                arch_lib_likelihoods.append(arch_result.loglikelihood)
                
                # è®°å½•archåº“å‚æ•°
                arch_params = {
                    'omega': arch_result.params['omega'],
                    'alpha': arch_result.params['alpha[1]'],
                    'beta': arch_result.params['beta[1]'],
                    'nu': arch_result.params['nu']
                }
                arch_lib_params_history.append(arch_params)
                
                # === GARCH_LIBé¢„æµ‹ ===
                calc = gc.GarchCalculator(history_size=window_size + 10)
                calc.add_returns(window_data.tolist())
                
                if use_optimized_params:
                    # ä½¿ç”¨ç½‘æ ¼æœç´¢çš„æœ€ä¼˜å‚æ•°
                    best_params = grid_result['best_params']
                    params = gc.GarchParameters()
                    params.mu = best_params['mu']
                    params.omega = best_params['omega']
                    params.alpha = best_params['alpha']
                    params.beta = best_params['beta']
                    params.nu = best_params['nu']
                    calc.set_parameters(params)
                    
                    # è®°å½•ä½¿ç”¨çš„å‚æ•°
                    garch_params = {
                        'omega': best_params['omega'],
                        'alpha': best_params['alpha'],
                        'beta': best_params['beta'],
                        'nu': best_params['nu']
                    }
                else:
                    # è®©garch_libè‡ªå·±ä¼°è®¡å‚æ•°
                    estimation_result = calc.estimate_parameters()
                    if not estimation_result.converged:
                        continue
                    garch_params = {
                        'omega': estimation_result.parameters.omega,
                        'alpha': estimation_result.parameters.alpha,
                        'beta': estimation_result.parameters.beta,
                        'nu': estimation_result.parameters.nu
                    }
                
                garch_lib_params_history.append(garch_params)
                
                # garch_libé¢„æµ‹
                garch_forecast = calc.forecast_volatility(forecast_horizon)
                garch_vol = garch_forecast.volatility
                garch_lib_predictions.append(garch_vol)
                
                # è®¡ç®—ä¼¼ç„¶å€¼
                garch_likelihood = calc.calculate_log_likelihood()
                garch_lib_likelihoods.append(garch_likelihood)
                
                prediction_indices.append(i)
                successful_predictions += 1
                
                # è¿›åº¦æ˜¾ç¤º
                if total_attempts % 50 == 0:
                    progress = total_attempts / (len(self.data) - window_size) * 100
                    elapsed = time.time() - start_time
                    eta = elapsed * (len(self.data) - window_size - total_attempts) / total_attempts
                    print(f"   è¿›åº¦: {progress:.1f}% (ETA: {eta:.1f}s) - "
                          f"garch_lib: {garch_vol:.4f}, arch: {arch_vol:.4f}, "
                          f"å·®å¼‚: {abs(garch_vol - arch_vol):.4f}")
                
            except Exception as e:
                if total_attempts <= 5:  # åªæ˜¾ç¤ºå‰å‡ ä¸ªé”™è¯¯
                    print(f"   é¢„æµ‹å¤±è´¥ at index {i}: {str(e)}")
                continue
        
        elapsed_time = time.time() - start_time
        
        print(f"\nâœ… æ»šåŠ¨é¢„æµ‹å®Œæˆ!")
        print(f"   è€—æ—¶: {elapsed_time:.2f}ç§’")
        print(f"   æˆåŠŸé¢„æµ‹: {successful_predictions}/{total_attempts} ({successful_predictions/total_attempts:.2%})")
        
        return {
            'garch_lib_predictions': garch_lib_predictions,
            'arch_lib_predictions': arch_lib_predictions,
            'prediction_indices': prediction_indices,
            'garch_lib_likelihoods': garch_lib_likelihoods,
            'arch_lib_likelihoods': arch_lib_likelihoods,
            'garch_lib_params_history': garch_lib_params_history,
            'arch_lib_params_history': arch_lib_params_history,
            'successful_predictions': successful_predictions,
            'total_attempts': total_attempts,
            'success_rate': successful_predictions / total_attempts,
            'elapsed_time': elapsed_time,
            'use_optimized_params': use_optimized_params,
            'grid_search_result': grid_result if use_optimized_params else None
        }
    
    def calculate_comparison_metrics(self, forecast_results: Dict) -> Dict:
        """
        è®¡ç®—è¯¦ç»†çš„å¯¹æ¯”æŒ‡æ ‡
        
        Args:
            forecast_results: é¢„æµ‹ç»“æœ
            
        Returns:
            å¯¹æ¯”æŒ‡æ ‡å­—å…¸
        """
        garch_preds = np.array(forecast_results['garch_lib_predictions'])
        arch_preds = np.array(forecast_results['arch_lib_predictions'])
        
        # åŸºæœ¬ç»Ÿè®¡æŒ‡æ ‡
        metrics = {
            # é¢„æµ‹æ€§èƒ½æŒ‡æ ‡
            'correlation': np.corrcoef(garch_preds, arch_preds)[0, 1],
            'mae': np.mean(np.abs(garch_preds - arch_preds)),
            'rmse': np.sqrt(np.mean((garch_preds - arch_preds)**2)),
            'mape': np.mean(np.abs((garch_preds - arch_preds) / arch_preds)) * 100,
            'bias': np.mean(garch_preds - arch_preds),
            
            # åˆ†å¸ƒç‰¹å¾
            'garch_lib_mean': garch_preds.mean(),
            'arch_lib_mean': arch_preds.mean(),
            'garch_lib_std': garch_preds.std(),
            'arch_lib_std': arch_preds.std(),
            'garch_lib_min': garch_preds.min(),
            'arch_lib_min': arch_preds.min(),
            'garch_lib_max': garch_preds.max(),
            'arch_lib_max': arch_preds.max(),
            
            # ä¼¼ç„¶å€¼å¯¹æ¯”
            'garch_lib_avg_likelihood': np.mean(forecast_results['garch_lib_likelihoods']),
            'arch_lib_avg_likelihood': np.mean(forecast_results['arch_lib_likelihoods']),
            
            # ç›¸å¯¹æ€§èƒ½
            'mean_relative_error': np.mean((garch_preds - arch_preds) / arch_preds) * 100,
            'accuracy_within_5pct': np.mean(np.abs((garch_preds - arch_preds) / arch_preds) < 0.05) * 100,
            'accuracy_within_10pct': np.mean(np.abs((garch_preds - arch_preds) / arch_preds) < 0.10) * 100,
            'accuracy_within_20pct': np.mean(np.abs((garch_preds - arch_preds) / arch_preds) < 0.20) * 100,
        }
        
        # æ·»åŠ åˆ†ä½æ•°å¯¹æ¯”
        for q in [0.05, 0.25, 0.5, 0.75, 0.95]:
            metrics[f'garch_lib_q{int(q*100)}'] = np.quantile(garch_preds, q)
            metrics[f'arch_lib_q{int(q*100)}'] = np.quantile(arch_preds, q)
        
        return metrics
    
    def analyze_parameter_differences(self, forecast_results: Dict) -> Dict:
        """
        åˆ†æå‚æ•°å·®å¼‚
        
        Args:
            forecast_results: é¢„æµ‹ç»“æœ
            
        Returns:
            å‚æ•°åˆ†æç»“æœ
        """
        if not forecast_results['use_optimized_params']:
            # å¦‚æœä½¿ç”¨åŠ¨æ€å‚æ•°ä¼°è®¡ï¼Œåˆ†æå‚æ•°æ¼”åŒ–
            garch_params = forecast_results['garch_lib_params_history']
            arch_params = forecast_results['arch_lib_params_history']
            
            param_analysis = {}
            for param_name in ['omega', 'alpha', 'beta', 'nu']:
                garch_values = [p[param_name] for p in garch_params]
                arch_values = [p[param_name] for p in arch_params]
                
                param_analysis[param_name] = {
                    'garch_lib_mean': np.mean(garch_values),
                    'arch_lib_mean': np.mean(arch_values),
                    'garch_lib_std': np.std(garch_values),
                    'arch_lib_std': np.std(arch_values),
                    'mean_difference': np.mean(garch_values) - np.mean(arch_values),
                    'correlation': np.corrcoef(garch_values, arch_values)[0, 1] if len(garch_values) > 1 else 0
                }
            
            return param_analysis
        else:
            # å¦‚æœä½¿ç”¨å›ºå®šä¼˜åŒ–å‚æ•°ï¼Œä¸archåº“å¹³å‡å‚æ•°å¯¹æ¯”
            grid_params = forecast_results['grid_search_result']['best_params']
            arch_params = forecast_results['arch_lib_params_history']
            
            param_analysis = {}
            for param_name in ['omega', 'alpha', 'beta', 'nu']:
                arch_values = [p[param_name] for p in arch_params]
                arch_mean = np.mean(arch_values)
                
                param_analysis[param_name] = {
                    'grid_search_value': grid_params[param_name],
                    'arch_lib_mean': arch_mean,
                    'arch_lib_std': np.std(arch_values),
                    'difference': grid_params[param_name] - arch_mean,
                    'relative_difference': (grid_params[param_name] - arch_mean) / arch_mean * 100
                }
            
            return param_analysis
    
    def generate_report(self, forecast_results: Dict, metrics: Dict, param_analysis: Dict) -> None:
        """
        ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        
        Args:
            forecast_results: é¢„æµ‹ç»“æœ
            metrics: å¯¹æ¯”æŒ‡æ ‡
            param_analysis: å‚æ•°åˆ†æ
        """
        print(f"\nğŸ“Š æ³¢åŠ¨ç‡é¢„æµ‹å¯¹æ¯”æŠ¥å‘Š")
        print("=" * 80)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ”§ æµ‹è¯•é…ç½®:")
        print(f"   æ•°æ®é›†: {self.test_name}")
        print(f"   æ•°æ®ç‚¹æ•°: {len(self.data)}")
        print(f"   æˆåŠŸé¢„æµ‹: {forecast_results['successful_predictions']}")
        print(f"   ä½¿ç”¨ä¼˜åŒ–å‚æ•°: {'æ˜¯' if forecast_results['use_optimized_params'] else 'å¦'}")
        
        # é¢„æµ‹æ€§èƒ½å¯¹æ¯”
        print(f"\nğŸ“ˆ é¢„æµ‹æ€§èƒ½å¯¹æ¯”:")
        print(f"   ç›¸å…³ç³»æ•°: {metrics['correlation']:.4f}")
        print(f"   å¹³å‡ç»å¯¹è¯¯å·®: {metrics['mae']:.6f}")
        print(f"   å‡æ–¹æ ¹è¯¯å·®: {metrics['rmse']:.6f}")
        print(f"   å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®: {metrics['mape']:.2f}%")
        print(f"   åå·® (garch_lib - arch): {metrics['bias']:.6f}")
        print(f"   å¹³å‡ç›¸å¯¹è¯¯å·®: {metrics['mean_relative_error']:.2f}%")
        
        # ç²¾åº¦ç»Ÿè®¡
        print(f"\nğŸ¯ ç²¾åº¦ç»Ÿè®¡:")
        print(f"   5%ä»¥å†…ç²¾åº¦: {metrics['accuracy_within_5pct']:.1f}%")
        print(f"   10%ä»¥å†…ç²¾åº¦: {metrics['accuracy_within_10pct']:.1f}%")
        print(f"   20%ä»¥å†…ç²¾åº¦: {metrics['accuracy_within_20pct']:.1f}%")
        
        # åˆ†å¸ƒå¯¹æ¯”
        print(f"\nğŸ“Š åˆ†å¸ƒç‰¹å¾å¯¹æ¯”:")
        print(f"   {'ç»Ÿè®¡é‡':<15} {'garch_lib':<12} {'archåº“':<12} {'å·®å¼‚':<10}")
        print("-" * 55)
        stats = ['mean', 'std', 'min', 'max']
        for stat in stats:
            garch_val = metrics[f'garch_lib_{stat}']
            arch_val = metrics[f'arch_lib_{stat}']
            diff = garch_val - arch_val
            print(f"   {stat:<15} {garch_val:<12.4f} {arch_val:<12.4f} {diff:<10.4f}")
        
        # åˆ†ä½æ•°å¯¹æ¯”
        print(f"\nğŸ“ˆ åˆ†ä½æ•°å¯¹æ¯”:")
        print(f"   {'åˆ†ä½æ•°':<10} {'garch_lib':<12} {'archåº“':<12} {'å·®å¼‚':<10}")
        print("-" * 50)
        for q in [5, 25, 50, 75, 95]:
            garch_val = metrics[f'garch_lib_q{q}']
            arch_val = metrics[f'arch_lib_q{q}']
            diff = garch_val - arch_val
            print(f"   Q{q}%{'':<7} {garch_val:<12.4f} {arch_val:<12.4f} {diff:<10.4f}")
        
        # ä¼¼ç„¶å€¼å¯¹æ¯”
        print(f"\nğŸ” ä¼¼ç„¶å€¼å¯¹æ¯”:")
        print(f"   garch_libå¹³å‡ä¼¼ç„¶å€¼: {metrics['garch_lib_avg_likelihood']:.4f}")
        print(f"   archåº“å¹³å‡ä¼¼ç„¶å€¼: {metrics['arch_lib_avg_likelihood']:.4f}")
        print(f"   ä¼¼ç„¶å€¼å·®å¼‚: {metrics['garch_lib_avg_likelihood'] - metrics['arch_lib_avg_likelihood']:.4f}")
        
        # å‚æ•°åˆ†æ
        print(f"\nâš™ï¸  å‚æ•°åˆ†æ:")
        if forecast_results['use_optimized_params']:
            print(f"   ä½¿ç”¨ç½‘æ ¼æœç´¢å›ºå®šå‚æ•° vs archåº“åŠ¨æ€å‚æ•°:")
            for param, analysis in param_analysis.items():
                print(f"   {param}:")
                print(f"      ç½‘æ ¼æœç´¢å€¼: {analysis['grid_search_value']:.6f}")
                print(f"      archåº“å‡å€¼: {analysis['arch_lib_mean']:.6f}")
                print(f"      å·®å¼‚: {analysis['difference']:.6f} ({analysis['relative_difference']:.2f}%)")
        else:
            print(f"   garch_libåŠ¨æ€å‚æ•° vs archåº“åŠ¨æ€å‚æ•°:")
            for param, analysis in param_analysis.items():
                print(f"   {param}: garch_lib={analysis['garch_lib_mean']:.4f}Â±{analysis['garch_lib_std']:.4f}, "
                      f"arch={analysis['arch_lib_mean']:.4f}Â±{analysis['arch_lib_std']:.4f}, "
                      f"ç›¸å…³æ€§={analysis['correlation']:.3f}")
    
    def save_results(self, forecast_results: Dict, metrics: Dict, param_analysis: Dict) -> None:
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f'volatility_prediction_comparison_{self.test_name}_{timestamp}.json'
        
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        results_to_save = {
            'test_name': self.test_name,
            'test_timestamp': timestamp,
            'forecast_results': {
                'garch_lib_predictions': forecast_results['garch_lib_predictions'],
                'arch_lib_predictions': forecast_results['arch_lib_predictions'],
                'prediction_indices': forecast_results['prediction_indices'],
                'garch_lib_likelihoods': forecast_results['garch_lib_likelihoods'],
                'arch_lib_likelihoods': forecast_results['arch_lib_likelihoods'],
                'successful_predictions': forecast_results['successful_predictions'],
                'total_attempts': forecast_results['total_attempts'],
                'success_rate': forecast_results['success_rate'],
                'elapsed_time': forecast_results['elapsed_time'],
                'use_optimized_params': forecast_results['use_optimized_params']
            },
            'comparison_metrics': metrics,
            'parameter_analysis': param_analysis
        }
        
        with open(filename, 'w') as f:
            json.dump(results_to_save, f, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„å¯¹æ¯”æµ‹è¯•"""
    print("ğŸš€ ç½‘æ ¼æœç´¢å‚æ•° vs archåº“GARCH(1,1)-GED æ³¢åŠ¨ç‡é¢„æµ‹å¯¹æ¯”")
    print("=" * 80)
    
    # è¯»å–brett.csvæ•°æ®
    df = pd.read_csv('brett.csv')
    
    # ä½¿ç”¨ä¸åŒçš„æ•°æ®å­é›†è¿›è¡Œæµ‹è¯•
    test_configs = [
        {
            'name': 'brett_full_500',
            'data': df['c_scaled'].values[:500],
            'window_size': 200,
            'description': 'å‰500ä¸ªæ•°æ®ç‚¹ï¼Œçª—å£200'
        },
        {
            'name': 'brett_recent_300', 
            'data': df['c_scaled'].values[200:500],
            'window_size': 150,
            'description': 'ä¸­é—´300ä¸ªæ•°æ®ç‚¹ï¼Œçª—å£150'
        }
    ]
    
    for config in test_configs:
        print(f"\n{'='*60}")
        print(f"ğŸ” æµ‹è¯•é…ç½®: {config['name']}")
        print(f"   æè¿°: {config['description']}")
        print(f"   æ•°æ®é•¿åº¦: {len(config['data'])}")
        
        # åˆ›å»ºå¯¹æ¯”æµ‹è¯•å®ä¾‹
        comparison = VolatilityPredictionComparison(config['data'], config['name'])
        
        # æµ‹è¯•1: ä½¿ç”¨ç½‘æ ¼æœç´¢ä¼˜åŒ–å‚æ•°
        print(f"\nğŸ¯ æµ‹è¯•1: ç½‘æ ¼æœç´¢ä¼˜åŒ–å‚æ•° vs archåº“")
        forecast_results_opt = comparison.rolling_forecast_comparison(
            window_size=config['window_size'],
            use_optimized_params=True
        )
        
        if forecast_results_opt['successful_predictions'] > 0:
            metrics_opt = comparison.calculate_comparison_metrics(forecast_results_opt)
            param_analysis_opt = comparison.analyze_parameter_differences(forecast_results_opt)
            comparison.generate_report(forecast_results_opt, metrics_opt, param_analysis_opt)
            comparison.save_results(forecast_results_opt, metrics_opt, param_analysis_opt)
        
        print(f"\n" + "="*60)
        print(f"ğŸ¯ æµ‹è¯•2: garch_libåŠ¨æ€å‚æ•°ä¼°è®¡ vs archåº“")
        
        # æµ‹è¯•2: ä½¿ç”¨garch_libåŠ¨æ€å‚æ•°ä¼°è®¡
        forecast_results_dyn = comparison.rolling_forecast_comparison(
            window_size=config['window_size'],
            use_optimized_params=False
        )
        
        if forecast_results_dyn['successful_predictions'] > 0:
            metrics_dyn = comparison.calculate_comparison_metrics(forecast_results_dyn)
            param_analysis_dyn = comparison.analyze_parameter_differences(forecast_results_dyn)
            comparison.generate_report(forecast_results_dyn, metrics_dyn, param_analysis_dyn)
            comparison.save_results(forecast_results_dyn, metrics_dyn, param_analysis_dyn)
        
        # å¯¹æ¯”ä¸¤ç§æ–¹æ³•
        if (forecast_results_opt['successful_predictions'] > 0 and 
            forecast_results_dyn['successful_predictions'] > 0):
            
            print(f"\nğŸ† ä¸¤ç§æ–¹æ³•æ€§èƒ½å¯¹æ¯”:")
            print(f"   {'æŒ‡æ ‡':<20} {'ç½‘æ ¼æœç´¢':<12} {'åŠ¨æ€ä¼°è®¡':<12} {'ä¼˜åŠ¿':<10}")
            print("-" * 60)
            
            comparisons = [
                ('ç›¸å…³ç³»æ•°', metrics_opt['correlation'], metrics_dyn['correlation']),
                ('MAE', metrics_opt['mae'], metrics_dyn['mae']),
                ('RMSE', metrics_opt['rmse'], metrics_dyn['rmse']),
                ('MAPE (%)', metrics_opt['mape'], metrics_dyn['mape']),
                ('10%å†…ç²¾åº¦ (%)', metrics_opt['accuracy_within_10pct'], metrics_dyn['accuracy_within_10pct'])
            ]
            
            for metric_name, opt_val, dyn_val in comparisons:
                if metric_name == 'ç›¸å…³ç³»æ•°' or 'ç²¾åº¦' in metric_name:
                    better = "ç½‘æ ¼æœç´¢" if opt_val > dyn_val else "åŠ¨æ€ä¼°è®¡"
                else:
                    better = "ç½‘æ ¼æœç´¢" if opt_val < dyn_val else "åŠ¨æ€ä¼°è®¡"
                
                print(f"   {metric_name:<20} {opt_val:<12.4f} {dyn_val:<12.4f} {better:<10}")


if __name__ == "__main__":
    main() 