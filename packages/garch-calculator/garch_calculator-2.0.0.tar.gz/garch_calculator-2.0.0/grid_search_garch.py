#!/usr/bin/env python3
"""
é’ˆå¯¹brett.csvæ•°æ®çš„GARCHå‚æ•°ç½‘æ ¼æœç´¢å·¥å…·
ç›®æ ‡ï¼šæ‰¾åˆ°ä¸archåº“å°½å¯èƒ½æ¥è¿‘çš„å‚æ•°ç»„åˆ
"""

import garch_lib as gc
import pandas as pd
import numpy as np
from arch import arch_model
import itertools
import time
from typing import Dict, List, Tuple, Optional
import json

class GarchGridSearch:
    """GARCHå‚æ•°ç½‘æ ¼æœç´¢ç±»"""
    
    def __init__(self, data: np.ndarray, verbose: bool = True):
        """
        åˆå§‹åŒ–ç½‘æ ¼æœç´¢
        
        Args:
            data: æ”¶ç›Šç‡æ•°æ®
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
        """
        self.data = data
        self.verbose = verbose
        self.results = []
        
        # é¦–å…ˆç”¨archåº“ä¼°è®¡åŸºå‡†å‚æ•°
        self._estimate_arch_baseline()
        
    def _estimate_arch_baseline(self):
        """ä½¿ç”¨archåº“ä¼°è®¡åŸºå‡†å‚æ•°"""
        try:
            arch_model_obj = arch_model(self.data, vol='Garch', p=1, q=1, dist='ged', rescale=False)
            arch_result = arch_model_obj.fit(disp='off', show_warning=False)
            
            self.arch_params = {
                'mu': arch_result.params['mu'],
                'omega': arch_result.params['omega'],
                'alpha': arch_result.params['alpha[1]'],
                'beta': arch_result.params['beta[1]'],
                'nu': arch_result.params['nu']
            }
            self.arch_likelihood = arch_result.loglikelihood
            
            if self.verbose:
                print("ğŸ¯ archåº“åŸºå‡†å‚æ•°:")
                print(f"  mu: {self.arch_params['mu']:.6f}")
                print(f"  omega: {self.arch_params['omega']:.6f}")
                print(f"  alpha: {self.arch_params['alpha']:.6f}")
                print(f"  beta: {self.arch_params['beta']:.6f}")
                print(f"  nu: {self.arch_params['nu']:.6f}")
                print(f"  ä¼¼ç„¶å€¼: {self.arch_likelihood:.6f}")
                
        except Exception as e:
            print(f"âŒ archåº“ä¼°è®¡å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤å‚æ•°
            self.arch_params = {'mu': 0.0, 'omega': 20.0, 'alpha': 0.3, 'beta': 0.6, 'nu': 2.0}
            self.arch_likelihood = -np.inf
    
    def define_search_ranges(self, range_type: str = 'coarse') -> Dict[str, np.ndarray]:
        """
        å®šä¹‰æœç´¢èŒƒå›´
        
        Args:
            range_type: 'coarse' ç²—æœç´¢, 'fine' ç²¾æœç´¢, 'adaptive' è‡ªé€‚åº”
            
        Returns:
            å‚æ•°æœç´¢èŒƒå›´å­—å…¸
        """
        if range_type == 'coarse':
            # ç²—æœç´¢ï¼šè¦†ç›–è¾ƒå¤§èŒƒå›´
            ranges = {
                'mu': np.linspace(self.arch_params['mu'] - 5.0, self.arch_params['mu'] + 5.0, 5),
                'omega': np.linspace(5.0, 60.0, 8),  # åŸºäºbrett.csvè§‚å¯Ÿåˆ°çš„èŒƒå›´
                'alpha': np.linspace(0.05, 0.8, 8),
                'beta': np.linspace(0.05, 0.8, 8),
                'nu': np.linspace(1.2, 4.0, 6)
            }
        elif range_type == 'fine':
            # ç²¾æœç´¢ï¼šå›´ç»•archå‚æ•°çš„ç»†è‡´æœç´¢
            mu_range = max(3.0, abs(self.arch_params['mu']) * 0.2)
            omega_range = max(5.0, self.arch_params['omega'] * 0.3)
            
            ranges = {
                'mu': np.linspace(self.arch_params['mu'] - mu_range, 
                                self.arch_params['mu'] + mu_range, 7),
                'omega': np.linspace(max(1.0, self.arch_params['omega'] - omega_range),
                                   self.arch_params['omega'] + omega_range, 9),
                'alpha': np.linspace(max(0.01, self.arch_params['alpha'] - 0.2),
                                   min(0.9, self.arch_params['alpha'] + 0.2), 9),
                'beta': np.linspace(max(0.01, self.arch_params['beta'] - 0.2),
                                  min(0.9, self.arch_params['beta'] + 0.2), 9),
                'nu': np.linspace(max(1.1, self.arch_params['nu'] - 0.8),
                                min(5.0, self.arch_params['nu'] + 0.8), 7)
            }
        else:  # adaptive
            # è‡ªé€‚åº”ï¼šåŸºäºæ•°æ®ç‰¹å¾è°ƒæ•´èŒƒå›´
            data_var = np.var(self.data)
            data_mean = np.mean(self.data)
            
            ranges = {
                'mu': np.linspace(data_mean - 3*np.sqrt(data_var), 
                                data_mean + 3*np.sqrt(data_var), 6),
                'omega': np.linspace(1.0, data_var * 2, 10),
                'alpha': np.linspace(0.02, 0.85, 12),
                'beta': np.linspace(0.02, 0.85, 12), 
                'nu': np.linspace(1.2, 4.0, 8)
            }
            
        # ç¡®ä¿å¹³ç¨³æ€§çº¦æŸåœ¨æœç´¢è¿‡ç¨‹ä¸­å¾—åˆ°è€ƒè™‘
        # æˆ‘ä»¬åœ¨è¯„ä¼°æ—¶æ£€æŸ¥ alpha + beta < 1
        
        return ranges
    
    def _evaluate_parameters(self, mu: float, omega: float, alpha: float, 
                           beta: float, nu: float) -> Optional[float]:
        """
        è¯„ä¼°ç»™å®šå‚æ•°ç»„åˆçš„ä¼¼ç„¶å€¼
        
        Returns:
            ä¼¼ç„¶å€¼ï¼Œå¦‚æœå‚æ•°æ— æ•ˆåˆ™è¿”å›None
        """
        # æ£€æŸ¥å‚æ•°çº¦æŸ
        if not (omega > 0 and alpha >= 0 and beta >= 0 and nu > 1.0):
            return None
            
        # å¹³ç¨³æ€§çº¦æŸ
        if alpha + beta >= 0.999:
            return None
            
        try:
            # ä½¿ç”¨garch_libè®¡ç®—ä¼¼ç„¶å€¼
            calc = gc.GarchCalculator(history_size=len(self.data) + 10)
            calc.add_returns(self.data.tolist())
            
            params = gc.GarchParameters()
            params.mu = mu
            params.omega = omega
            params.alpha = alpha
            params.beta = beta
            params.nu = nu
            
            calc.set_parameters(params)
            likelihood = calc.calculate_log_likelihood()
            
            if np.isfinite(likelihood) and likelihood > -1e6:
                return likelihood
            else:
                return None
                
        except Exception:
            return None
    
    def grid_search(self, range_type: str = 'coarse', max_combinations: int = 50000) -> Dict:
        """
        æ‰§è¡Œç½‘æ ¼æœç´¢
        
        Args:
            range_type: æœç´¢èŒƒå›´ç±»å‹
            max_combinations: æœ€å¤§æœç´¢ç»„åˆæ•°
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        ranges = self.define_search_ranges(range_type)
        
        # è®¡ç®—æ€»ç»„åˆæ•°
        total_combinations = np.prod([len(r) for r in ranges.values()])
        
        if self.verbose:
            print(f"\nğŸ” å¼€å§‹{range_type}ç½‘æ ¼æœç´¢")
            print(f"  æœç´¢èŒƒå›´: {range_type}")
            print(f"  æ€»ç»„åˆæ•°: {total_combinations:,}")
            for param, values in ranges.items():
                print(f"  {param}: [{values.min():.3f}, {values.max():.3f}] ({len(values)}ä¸ªç‚¹)")
            
        if total_combinations > max_combinations:
            print(f"âš ï¸  ç»„åˆæ•°è¿‡å¤šï¼Œè‡ªåŠ¨é™é‡‡æ ·åˆ° {max_combinations:,} ä¸ªç»„åˆ")
            # éšæœºé‡‡æ ·
            sample_indices = np.random.choice(total_combinations, max_combinations, replace=False)
        else:
            sample_indices = None
            
        # æ‰§è¡Œæœç´¢
        best_likelihood = -np.inf
        best_params = None
        current_combination = 0
        start_time = time.time()
        
        param_combinations = itertools.product(*ranges.values())
        
        for i, (mu, omega, alpha, beta, nu) in enumerate(param_combinations):
            if sample_indices is not None and i not in sample_indices:
                continue
                
            likelihood = self._evaluate_parameters(mu, omega, alpha, beta, nu)
            
            if likelihood is not None:
                result = {
                    'mu': mu, 'omega': omega, 'alpha': alpha, 'beta': beta, 'nu': nu,
                    'likelihood': likelihood,
                    'param_distance': self._calculate_param_distance(mu, omega, alpha, beta, nu)
                }
                self.results.append(result)
                
                if likelihood > best_likelihood:
                    best_likelihood = likelihood
                    best_params = result.copy()
                    
            current_combination += 1
            
            # è¿›åº¦æ˜¾ç¤º
            if self.verbose and current_combination % 1000 == 0:
                elapsed = time.time() - start_time
                rate = current_combination / elapsed
                eta = (max_combinations - current_combination) / rate if rate > 0 else 0
                print(f"  è¿›åº¦: {current_combination:,}/{max_combinations:,} "
                      f"({current_combination/max_combinations*100:.1f}%) "
                      f"ETA: {eta:.1f}s")
                
        elapsed_time = time.time() - start_time
        
        if self.verbose:
            print(f"\nâœ… ç½‘æ ¼æœç´¢å®Œæˆ!")
            print(f"  è€—æ—¶: {elapsed_time:.2f}ç§’")
            print(f"  æœ‰æ•ˆç»„åˆ: {len(self.results):,}")
            
        return {
            'best_params': best_params,
            'best_likelihood': best_likelihood,
            'total_evaluated': len(self.results),
            'search_time': elapsed_time,
            'arch_likelihood': self.arch_likelihood
        }
    
    def _calculate_param_distance(self, mu: float, omega: float, alpha: float, 
                                beta: float, nu: float) -> float:
        """è®¡ç®—ä¸archåº“å‚æ•°çš„è·ç¦»"""
        distances = [
            abs(mu - self.arch_params['mu']) / max(abs(self.arch_params['mu']), 1.0),
            abs(omega - self.arch_params['omega']) / self.arch_params['omega'],
            abs(alpha - self.arch_params['alpha']) / self.arch_params['alpha'],
            abs(beta - self.arch_params['beta']) / max(self.arch_params['beta'], 0.1),
            abs(nu - self.arch_params['nu']) / self.arch_params['nu']
        ]
        return np.mean(distances)
    
    def get_top_results(self, n: int = 10, sort_by: str = 'likelihood') -> List[Dict]:
        """
        è·å–æœ€ä½³ç»“æœ
        
        Args:
            n: è¿”å›å‰nä¸ªç»“æœ
            sort_by: æ’åºä¾æ® ('likelihood' æˆ– 'param_distance')
            
        Returns:
            æœ€ä½³ç»“æœåˆ—è¡¨
        """
        if not self.results:
            return []
            
        if sort_by == 'likelihood':
            sorted_results = sorted(self.results, key=lambda x: x['likelihood'], reverse=True)
        else:  # param_distance
            sorted_results = sorted(self.results, key=lambda x: x['param_distance'])
            
        return sorted_results[:n]
    
    def analyze_results(self) -> None:
        """åˆ†ææœç´¢ç»“æœ"""
        if not self.results:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æœç´¢ç»“æœ")
            return
            
        print("\nğŸ“Š æœç´¢ç»“æœåˆ†æ")
        print("=" * 80)
        
        # æœ€ä½³ä¼¼ç„¶å€¼ç»“æœ
        best_likelihood_result = max(self.results, key=lambda x: x['likelihood'])
        print(f"\nğŸ¯ æœ€ä½³ä¼¼ç„¶å€¼å‚æ•°:")
        print(f"  mu: {best_likelihood_result['mu']:.6f}")
        print(f"  omega: {best_likelihood_result['omega']:.6f}")
        print(f"  alpha: {best_likelihood_result['alpha']:.6f}")
        print(f"  beta: {best_likelihood_result['beta']:.6f}")
        print(f"  nu: {best_likelihood_result['nu']:.6f}")
        print(f"  ä¼¼ç„¶å€¼: {best_likelihood_result['likelihood']:.6f}")
        print(f"  ä¸archåº“ä¼¼ç„¶å€¼å·®å¼‚: {abs(best_likelihood_result['likelihood'] - self.arch_likelihood):.6f}")
        
        # æœ€æ¥è¿‘archå‚æ•°çš„ç»“æœ
        closest_param_result = min(self.results, key=lambda x: x['param_distance'])
        print(f"\nğŸ¯ æœ€æ¥è¿‘archåº“çš„å‚æ•°:")
        print(f"  mu: {closest_param_result['mu']:.6f}")
        print(f"  omega: {closest_param_result['omega']:.6f}")
        print(f"  alpha: {closest_param_result['alpha']:.6f}")
        print(f"  beta: {closest_param_result['beta']:.6f}")
        print(f"  nu: {closest_param_result['nu']:.6f}")
        print(f"  ä¼¼ç„¶å€¼: {closest_param_result['likelihood']:.6f}")
        print(f"  å‚æ•°è·ç¦»: {closest_param_result['param_distance']:.6f}")
        
        # ç»Ÿè®¡åˆ†æ
        likelihoods = [r['likelihood'] for r in self.results]
        distances = [r['param_distance'] for r in self.results]
        
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  ä¼¼ç„¶å€¼èŒƒå›´: [{min(likelihoods):.3f}, {max(likelihoods):.3f}]")
        print(f"  ä¼¼ç„¶å€¼å‡å€¼: {np.mean(likelihoods):.3f}")
        print(f"  å‚æ•°è·ç¦»å‡å€¼: {np.mean(distances):.3f}")
        print(f"  åœ¨archä¼¼ç„¶å€¼Â±1.0å†…çš„å‚æ•°ç»„åˆ: {sum(1 for ll in likelihoods if abs(ll - self.arch_likelihood) <= 1.0)}")
        
    def save_results(self, filename: str) -> None:
        """ä¿å­˜æœç´¢ç»“æœåˆ°æ–‡ä»¶"""
        result_data = {
            'arch_params': self.arch_params,
            'arch_likelihood': self.arch_likelihood,
            'search_results': self.results,
            'best_likelihood': max(self.results, key=lambda x: x['likelihood']) if self.results else None,
            'closest_params': min(self.results, key=lambda x: x['param_distance']) if self.results else None
        }
        
        with open(filename, 'w') as f:
            json.dump(result_data, f, indent=2)
            
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")


def main():
    """ä¸»å‡½æ•°ï¼šé’ˆå¯¹brett.csvè¿›è¡Œç½‘æ ¼æœç´¢"""
    
    print("ğŸš€ brett.csv GARCHå‚æ•°ç½‘æ ¼æœç´¢")
    print("=" * 60)
    
    # è¯»å–æ•°æ®
    df = pd.read_csv('brett.csv')
    returns = df['c_scaled'].values[:500]  # ä½¿ç”¨å‰500ä¸ªæ•°æ®ç‚¹
    
    print(f"ğŸ“Š æ•°æ®ä¿¡æ¯:")
    print(f"  æ•°æ®ç‚¹æ•°: {len(returns)}")
    print(f"  å‡å€¼: {returns.mean():.6f}")
    print(f"  æ ‡å‡†å·®: {returns.std():.6f}")
    
    # åˆ›å»ºç½‘æ ¼æœç´¢å¯¹è±¡
    grid_search = GarchGridSearch(returns, verbose=True)
    
    # æ‰§è¡Œç²—æœç´¢
    print("\n" + "="*60)
    coarse_result = grid_search.grid_search(range_type='coarse', max_combinations=20000)
    grid_search.analyze_results()
    
    # åŸºäºç²—æœç´¢ç»“æœè¿›è¡Œç²¾æœç´¢
    if coarse_result['best_params']:
        print("\n" + "="*60)
        print("ğŸ” åŸºäºæœ€ä½³ç»“æœè¿›è¡Œç²¾ç»†æœç´¢...")
        
        # æ›´æ–°arch_paramsä¸ºç²—æœç´¢çš„æœ€ä½³ç»“æœï¼Œç”¨äºç²¾æœç´¢
        best = coarse_result['best_params']
        grid_search.arch_params = {
            'mu': best['mu'],
            'omega': best['omega'], 
            'alpha': best['alpha'],
            'beta': best['beta'],
            'nu': best['nu']
        }
        
        # æ¸…ç©ºä¹‹å‰çš„ç»“æœ
        grid_search.results = []
        
        fine_result = grid_search.grid_search(range_type='fine', max_combinations=15000)
        grid_search.analyze_results()
    
    # ä¿å­˜ç»“æœ
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    grid_search.save_results(f'brett_garch_grid_search_{timestamp}.json')
    
    # æ˜¾ç¤ºæœ€ä½³å‚æ•°çš„æ¨èä½¿ç”¨æ–¹å¼
    if grid_search.results:
        best = max(grid_search.results, key=lambda x: x['likelihood'])
        print(f"\nğŸ’¡ æ¨èçš„GARCHå‚æ•°ï¼ˆåŸºäºç½‘æ ¼æœç´¢ï¼‰:")
        print(f"   omega = {best['omega']:.6f}")
        print(f"   alpha = {best['alpha']:.6f}")
        print(f"   beta = {best['beta']:.6f}")
        print(f"   nu = {best['nu']:.6f}")
        print(f"   ä¼¼ç„¶å€¼ = {best['likelihood']:.6f}")
        
        print(f"\nğŸ“ ä½¿ç”¨ç¤ºä¾‹:")
        print(f"   params = gc.GarchParameters()")
        print(f"   params.mu = {best['mu']:.6f}")
        print(f"   params.omega = {best['omega']:.6f}")
        print(f"   params.alpha = {best['alpha']:.6f}")
        print(f"   params.beta = {best['beta']:.6f}")
        print(f"   params.nu = {best['nu']:.6f}")
        print(f"   calc.set_parameters(params)")


if __name__ == "__main__":
    main() 