#!/usr/bin/env python3
import os
import glob
import pandas as pd
import numpy as np
import time
from datetime import datetime
import sys
import traceback

# å¯¼å…¥éªŒè¯æ¨¡å—
from validate_aave import main as validate_single

def find_data_files():
    """æŸ¥æ‰¾æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
    pattern = "../garch_pro_service/backtest_data/bitget_*_USDT_*_data.npz"
    files = glob.glob(pattern)
    
    if not files:
        # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
        pattern = "./garch_pro_service/backtest_data/bitget_*_USDT_*_data.npz"
        files = glob.glob(pattern)
    
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ•°æ®æ–‡ä»¶")
    return sorted(files)

def extract_symbol_from_path(file_path):
    """ä»æ–‡ä»¶è·¯å¾„æå–å¸ç§åç§°"""
    basename = os.path.basename(file_path)
    parts = basename.split('_')
    if len(parts) >= 2:
        return parts[1]
    return "UNKNOWN"

def run_batch_validation():
    """æ‰¹é‡è¿è¡ŒéªŒè¯"""
    print("ğŸš€ å¼€å§‹æ‰¹é‡éªŒè¯æ‰€æœ‰æ•°æ®æ–‡ä»¶")
    print("=" * 80)
    
    data_files = find_data_files()
    if not data_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
        return
    
    results = []
    failed_files = []
    total_start_time = time.time()
    
    for i, file_path in enumerate(data_files, 1):
        symbol = extract_symbol_from_path(file_path)
        print(f"\nğŸ“‹ [{i}/{len(data_files)}] å¤„ç† {symbol}")
        print("-" * 60)
        
        try:
            file_start_time = time.time()
            arch_result, garch_result = validate_single(file_path)
            file_time = time.time() - file_start_time
            
            if arch_result and garch_result:
                # è®¡ç®—å„ç§æŒ‡æ ‡
                param_errors = []
                params = ['omega', 'alpha', 'beta', 'nu']
                for param in params:
                    arch_val = arch_result[param]
                    garch_val = garch_result[param]
                    rel_diff = abs(garch_val - arch_val) / abs(arch_val) * 100 if abs(arch_val) > 0 else 0
                    param_errors.append(rel_diff)
                
                avg_param_error = np.mean(param_errors)
                ll_diff = garch_result['log_likelihood'] - arch_result['log_likelihood']
                
                # é¢„æµ‹ç²¾åº¦æ¯”è¾ƒ
                forecast_comparison = {}
                if 'forecast_rmse' in arch_result and 'forecast_rmse' in garch_result:
                    arch_rmse = arch_result['forecast_rmse']
                    garch_rmse = garch_result['forecast_rmse']
                    rmse_diff = garch_rmse - arch_rmse
                    rmse_rel_diff = rmse_diff / arch_rmse * 100 if arch_rmse > 0 else 0
                    
                    arch_mae = arch_result['forecast_mae']
                    garch_mae = garch_result['forecast_mae']
                    mae_diff = garch_mae - arch_mae
                    mae_rel_diff = mae_diff / arch_mae * 100 if arch_mae > 0 else 0
                    
                    forecast_comparison = {
                        'arch_rmse': arch_rmse,
                        'garch_rmse': garch_rmse,
                        'rmse_diff': rmse_diff,
                        'rmse_rel_diff': rmse_rel_diff,
                        'arch_mae': arch_mae,
                        'garch_mae': garch_mae,
                        'mae_diff': mae_diff,
                        'mae_rel_diff': mae_rel_diff
                    }
                
                result_record = {
                    'symbol': symbol,
                    'file_path': file_path,
                    'success': True,
                    'file_time': file_time,
                    'arch_converged': arch_result['converged'],
                    'garch_converged': garch_result['converged'],
                    'arch_fit_time': arch_result['fit_time'],
                    'garch_fit_time': garch_result['fit_time'],
                    'arch_vol_time': arch_result['vol_prediction_time'],
                    'garch_vol_time': garch_result['vol_prediction_time'],
                    'fit_speedup': arch_result['fit_time'] / garch_result['fit_time'] if garch_result['fit_time'] > 0 else 0,
                    'vol_speedup': arch_result['vol_prediction_time'] / garch_result['vol_prediction_time'] if garch_result['vol_prediction_time'] > 0 else 0,
                    'avg_param_error': avg_param_error,
                    'll_diff': ll_diff,
                    'arch_omega': arch_result['omega'],
                    'garch_omega': garch_result['omega'],
                    'arch_alpha': arch_result['alpha'],
                    'garch_alpha': garch_result['alpha'],
                    'arch_beta': arch_result['beta'],
                    'garch_beta': garch_result['beta'],
                    'arch_nu': arch_result['nu'],
                    'garch_nu': garch_result['nu'],
                    'train_size': arch_result['train_size'],
                    'test_size': arch_result['test_size'],
                    **forecast_comparison
                }
                
                results.append(result_record)
                print(f"âœ… {symbol} éªŒè¯æˆåŠŸ (è€—æ—¶: {file_time:.2f}ç§’)")
                
            else:
                failed_files.append((symbol, file_path, "æ¨¡å‹æœªæ”¶æ•›æˆ–è¿è¡Œå¤±è´¥"))
                print(f"âŒ {symbol} éªŒè¯å¤±è´¥")
                
        except Exception as e:
            error_msg = str(e)
            failed_files.append((symbol, file_path, error_msg))
            print(f"âŒ {symbol} éªŒè¯å‡ºé”™: {error_msg}")
            # print(traceback.format_exc())
    
    total_time = time.time() - total_start_time
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    generate_summary_report(results, failed_files, total_time)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    save_detailed_results(results, failed_files)

def generate_summary_report(results, failed_files, total_time):
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    print("\n\n" + "="*100)
    print("ğŸ“Š æ‰¹é‡éªŒè¯æ±‡æ€»æŠ¥å‘Š")
    print("="*100)
    
    total_files = len(results) + len(failed_files)
    success_rate = len(results) / total_files * 100 if total_files > 0 else 0
    
    print(f"æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"æˆåŠŸéªŒè¯: {len(results)} ({success_rate:.1f}%)")
    print(f"å¤±è´¥æ–‡ä»¶: {len(failed_files)}")
    print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"å¹³å‡æ¯æ–‡ä»¶: {total_time/total_files:.2f}ç§’" if total_files > 0 else "")
    
    if failed_files:
        print(f"\nâŒ å¤±è´¥çš„æ–‡ä»¶:")
        for symbol, file_path, error in failed_files:
            print(f"  - {symbol}: {error}")
    
    if not results:
        print("\nâŒ æ²¡æœ‰æˆåŠŸçš„éªŒè¯ç»“æœ")
        return
    
    # è½¬æ¢ä¸ºDataFrameè¿›è¡Œç»Ÿè®¡
    df = pd.DataFrame(results)
    
    print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
    print(f"  å¹³å‡æ‹Ÿåˆé€Ÿåº¦æå‡: {df['fit_speedup'].mean():.2f}x")
    print(f"  å¹³å‡é¢„æµ‹é€Ÿåº¦æå‡: {df['vol_speedup'].mean():.2f}x" if 'vol_speedup' in df.columns else "  é¢„æµ‹é€Ÿåº¦: N/A")
    print(f"  å¹³å‡å‚æ•°è¯¯å·®: {df['avg_param_error'].mean():.2f}%")
    
    if 'rmse_rel_diff' in df.columns:
        print(f"\nğŸ¯ é¢„æµ‹ç²¾åº¦ç»Ÿè®¡:")
        better_count = (df['rmse_rel_diff'] < 0).sum()
        worse_count = (df['rmse_rel_diff'] > 5).sum()  # è¶…è¿‡5%è®¤ä¸ºæ˜æ˜¾æ›´å·®
        similar_count = len(df) - better_count - worse_count
        
        print(f"  garch_libé¢„æµ‹æ›´å¥½: {better_count} ({better_count/len(df)*100:.1f}%)")
        print(f"  é¢„æµ‹ç²¾åº¦ç›¸ä¼¼: {similar_count} ({similar_count/len(df)*100:.1f}%)")
        print(f"  arché¢„æµ‹æ›´å¥½: {worse_count} ({worse_count/len(df)*100:.1f}%)")
        print(f"  å¹³å‡RMSEç›¸å¯¹å·®å¼‚: {df['rmse_rel_diff'].mean():.2f}%")
    
    print(f"\nğŸ”§ å‚æ•°ä¸€è‡´æ€§:")
    consistency_levels = {
        'high': (df['avg_param_error'] < 5).sum(),
        'medium': ((df['avg_param_error'] >= 5) & (df['avg_param_error'] < 10)).sum(),
        'low': (df['avg_param_error'] >= 10).sum()
    }
    
    print(f"  é«˜åº¦ä¸€è‡´(<5%): {consistency_levels['high']} ({consistency_levels['high']/len(df)*100:.1f}%)")
    print(f"  åŸºæœ¬ä¸€è‡´(5-10%): {consistency_levels['medium']} ({consistency_levels['medium']/len(df)*100:.1f}%)")
    print(f"  æœ‰å·®å¼‚(>10%): {consistency_levels['low']} ({consistency_levels['low']/len(df)*100:.1f}%)")
    
    # æ‰¾å‡ºæœ€å¥½å’Œæœ€å·®çš„æ¡ˆä¾‹
    if len(df) > 0:
        print(f"\nğŸ† è¡¨ç°æœ€å¥½çš„å¸ç§:")
        if 'rmse_rel_diff' in df.columns:
            best_forecast = df.loc[df['rmse_rel_diff'].idxmin()]
            print(f"  é¢„æµ‹ç²¾åº¦æœ€ä½³: {best_forecast['symbol']} (RMSEæ”¹å–„: {best_forecast['rmse_rel_diff']:.2f}%)")
        
        fastest = df.loc[df['fit_speedup'].idxmax()]
        print(f"  æ‹Ÿåˆé€Ÿåº¦æœ€å¿«: {fastest['symbol']} (æå‡: {fastest['fit_speedup']:.2f}x)")
        
        most_consistent = df.loc[df['avg_param_error'].idxmin()]
        print(f"  å‚æ•°æœ€ä¸€è‡´: {most_consistent['symbol']} (è¯¯å·®: {most_consistent['avg_param_error']:.2f}%)")
        
        print(f"\nâš ï¸  éœ€è¦å…³æ³¨çš„å¸ç§:")
        if 'rmse_rel_diff' in df.columns:
            worst_forecast = df.loc[df['rmse_rel_diff'].idxmax()]
            print(f"  é¢„æµ‹ç²¾åº¦æœ€å·®: {worst_forecast['symbol']} (RMSEå·®å¼‚: {worst_forecast['rmse_rel_diff']:.2f}%)")
        
        least_consistent = df.loc[df['avg_param_error'].idxmax()]
        print(f"  å‚æ•°å·®å¼‚æœ€å¤§: {least_consistent['symbol']} (è¯¯å·®: {least_consistent['avg_param_error']:.2f}%)")

def save_detailed_results(results, failed_files):
    """ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜æˆåŠŸçš„ç»“æœ
    if results:
        df = pd.DataFrame(results)
        csv_file = f"batch_validation_results_{timestamp}.csv"
        df.to_csv(csv_file, index=False)
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {csv_file}")
    
    # ä¿å­˜å¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨
    if failed_files:
        failed_df = pd.DataFrame(failed_files, columns=['symbol', 'file_path', 'error'])
        failed_csv = f"batch_validation_failed_{timestamp}.csv"
        failed_df.to_csv(failed_csv, index=False)
        print(f"ğŸ’¾ å¤±è´¥æ–‡ä»¶åˆ—è¡¨å·²ä¿å­˜åˆ°: {failed_csv}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” GARCHåº“æ‰¹é‡éªŒè¯å·¥å…·")
    print("å¯¹æ¯”garch_libå’ŒPython archåº“åœ¨æ‰€æœ‰å¯ç”¨æ•°æ®ä¸Šçš„è¡¨ç°")
    print()
    
    try:
        run_batch_validation()
        print(f"\nâœ… æ‰¹é‡éªŒè¯å®Œæˆ!")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­éªŒè¯è¿‡ç¨‹")
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main() 