import garch_lib as gc
import pandas as pd
import numpy as np
from arch import arch_model
import matplotlib.pyplot as plt
from datetime import datetime

# 1. è¯»å– CSV æ–‡ä»¶
print("ğŸ“Š è¯»å– brett.csv æ–‡ä»¶...")
df = pd.read_csv('brett.csv')

# 2. æå– c_scaled åˆ—ä½œä¸ºæ”¶ç›Šç‡æ•°æ®
returns = df['c_scaled'].values
print(f"   æ•°æ®æ€»é‡: {len(returns)} ä¸ªæ•°æ®ç‚¹")
print(f"   æ•°æ®èŒƒå›´: {returns.min():.6f} åˆ° {returns.max():.6f}")

# 3. è®¾ç½®æ»šåŠ¨çª—å£å‚æ•°
window_size = 200  # çª—å£å¤§å°
min_periods = window_size  

# å­˜å‚¨é¢„æµ‹ç»“æœ
garch_lib_predictions = []
arch_lib_predictions = []
prediction_dates = []

print(f"\nğŸ”„ å¼€å§‹æ»šåŠ¨é¢„æµ‹ (çª—å£å¤§å°: {window_size})")
print("ç­–ç•¥: ä½¿ç”¨archåº“ä¼°è®¡å‚æ•°ï¼Œgarch_libè¿›è¡Œé¢„æµ‹")
print("=" * 60)

# 4. æ»šåŠ¨é¢„æµ‹
for i in range(window_size, len(returns)):
    # è·å–å½“å‰çª—å£çš„æ•°æ®
    window_data = returns[i-window_size:i]
    
    try:
        # === ä½¿ç”¨ arch åº“ä¼°è®¡å‚æ•° ===
        arch_model_obj = arch_model(window_data, vol='Garch', p=1, q=1, dist='ged', rescale=False)
        arch_result = arch_model_obj.fit(disp='off', show_warning=False)
        
        # è·å–å‡å€¼å‚æ•°
        mu = arch_result.params['mu']
        
        # ä½¿ç”¨å»å‡å€¼çš„æ®‹å·®
        residuals = window_data - mu
        
        # === ä½¿ç”¨ garch_lib è¿›è¡Œé¢„æµ‹ï¼ˆä½¿ç”¨archåº“çš„å‚æ•°ï¼‰===
        calc = gc.GarchCalculator(history_size=window_size + 10)
        calc.add_returns(residuals.tolist())
        
        # ç›´æ¥ä½¿ç”¨archåº“çš„å‚æ•°
        arch_params = gc.GarchParameters()
        arch_params.omega = arch_result.params['omega']
        arch_params.alpha = arch_result.params['alpha[1]']
        arch_params.beta = arch_result.params['beta[1]']
        arch_params.nu = arch_result.params['nu']
        calc.set_parameters(arch_params)
        
        # ä½¿ç”¨garch_libè¿›è¡Œé¢„æµ‹
        garch_lib_forecast = calc.forecast_volatility(1)
        garch_lib_vol = garch_lib_forecast.volatility
        garch_lib_predictions.append(garch_lib_vol)
        
        # archåº“é¢„æµ‹
        arch_forecast = arch_result.forecast(horizon=1, reindex=False)
        arch_predictions = np.sqrt(arch_forecast.variance.values[-1, :])
        arch_lib_predictions.append(arch_predictions[0])
        
        prediction_dates.append(i)
        
        # æ¯100ä¸ªé¢„æµ‹ç‚¹è¾“å‡ºä¸€æ¬¡è¿›åº¦
        if (i - window_size + 1) % 100 == 0:
            progress = (i - window_size + 1) / (len(returns) - window_size) * 100
            print(f"è¿›åº¦: {progress:.1f}% ({i - window_size + 1}/{len(returns) - window_size})")
            print(f"  archå‚æ•°: Ï‰={arch_result.params['omega']:.6f}, Î±={arch_result.params['alpha[1]']:.6f}")
            print(f"            Î²={arch_result.params['beta[1]']:.6f}, Î½={arch_result.params['nu']:.6f}")
            print(f"  garch_libé¢„æµ‹: {garch_lib_vol:.6f}, archåº“é¢„æµ‹: {arch_predictions[0]:.6f}")
            print(f"  å·®å¼‚: {garch_lib_vol - arch_predictions[0]:.6f}")
            
    except Exception as e:
        print(f"é¢„æµ‹å¤±è´¥ at index {i}: {str(e)}")
        continue

print(f"\nâœ… æ»šåŠ¨é¢„æµ‹å®Œæˆ!")
print(f"   æˆåŠŸé¢„æµ‹: {len(garch_lib_predictions)} ä¸ªç‚¹")

# 5. ç»“æœå¯¹æ¯”åˆ†æ
if len(garch_lib_predictions) > 0 and len(arch_lib_predictions) > 0:
    garch_lib_arr = np.array(garch_lib_predictions)
    arch_lib_arr = np.array(arch_lib_predictions)
    
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœç»Ÿè®¡å¯¹æ¯”:")
    print("=" * 60)
    print(f"{'æŒ‡æ ‡':<20} {'garch_lib':<15} {'archåº“':<15} {'å·®å¼‚':<10}")
    print("-" * 60)
    print(f"{'å¹³å‡å€¼':<20} {garch_lib_arr.mean():<15.6f} {arch_lib_arr.mean():<15.6f} {abs(garch_lib_arr.mean() - arch_lib_arr.mean()):<10.6f}")
    print(f"{'æ ‡å‡†å·®':<20} {garch_lib_arr.std():<15.6f} {arch_lib_arr.std():<15.6f} {abs(garch_lib_arr.std() - arch_lib_arr.std()):<10.6f}")
    print(f"{'æœ€å°å€¼':<20} {garch_lib_arr.min():<15.6f} {arch_lib_arr.min():<15.6f} {abs(garch_lib_arr.min() - arch_lib_arr.min()):<10.6f}")
    print(f"{'æœ€å¤§å€¼':<20} {garch_lib_arr.max():<15.6f} {arch_lib_arr.max():<15.6f} {abs(garch_lib_arr.max() - arch_lib_arr.max()):<10.6f}")
    
    # è®¡ç®—ç›¸å…³ç³»æ•°
    correlation = np.corrcoef(garch_lib_arr, arch_lib_arr)[0, 1]
    print(f"{'ç›¸å…³ç³»æ•°':<20} {correlation:<30.6f}")
    
    # è®¡ç®—RMSEå’ŒMAE
    rmse = np.sqrt(np.mean((garch_lib_arr - arch_lib_arr)**2))
    mae = np.mean(np.abs(garch_lib_arr - arch_lib_arr))
    print(f"{'RMSE':<20} {rmse:<30.6f}")
    print(f"{'MAE':<20} {mae:<30.6f}")
    
    # è®¡ç®—ç›¸å¯¹è¯¯å·®
    mape = np.mean(np.abs((garch_lib_arr - arch_lib_arr) / arch_lib_arr)) * 100
    print(f"{'MAPE (%)':<20} {mape:<30.2f}")
    
    # è®¡ç®—é¢„æµ‹è´¨é‡æŒ‡æ ‡
    abs_errors = np.abs(garch_lib_arr - arch_lib_arr)
    good_predictions = np.sum(abs_errors < 1.0)  # æ›´ä¸¥æ ¼çš„æ ‡å‡†
    excellent_predictions = np.sum(abs_errors < 0.5)
    print(f"{'ç»å¯¹è¯¯å·®<1çš„æ¯”ä¾‹':<20} {good_predictions/len(abs_errors)*100:<30.1f}%")
    print(f"{'ç»å¯¹è¯¯å·®<0.5çš„æ¯”ä¾‹':<20} {excellent_predictions/len(abs_errors)*100:<30.1f}%")
    
    # 6. ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSV
    results_df = pd.DataFrame({
        'prediction_index': prediction_dates,
        'garch_lib_volatility': garch_lib_predictions,
        'arch_lib_volatility': arch_lib_predictions,
        'difference': garch_lib_arr - arch_lib_arr,
        'relative_error': (garch_lib_arr - arch_lib_arr) / arch_lib_arr * 100
    })
    
    results_df.to_csv('volatility_predictions_comparison_arch_params.csv', index=False)
    print(f"\nğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: volatility_predictions_comparison_arch_params.csv")
    
    # 7. æ˜¾ç¤ºæœ€è¿‘å‡ ä¸ªé¢„æµ‹ç»“æœ
    print(f"\nğŸ” æœ€è¿‘15ä¸ªé¢„æµ‹ç»“æœ:")
    print("-" * 90)
    print(f"{'ç´¢å¼•':<8} {'garch_lib':<15} {'archåº“':<15} {'å·®å¼‚':<15} {'ç›¸å¯¹è¯¯å·®%':<12}")
    print("-" * 90)
    for i in range(max(0, len(results_df)-15), len(results_df)):
        row = results_df.iloc[i]
        print(f"{int(row['prediction_index']):<8} {row['garch_lib_volatility']:<15.6f} {row['arch_lib_volatility']:<15.6f} {row['difference']:<15.6f} {row['relative_error']:<12.2f}%")

    # 8. åˆ†æå·®å¼‚åˆ†å¸ƒ
    print(f"\nğŸ“ˆ å·®å¼‚åˆ†æ:")
    print(f"  å¹³å‡ç»å¯¹å·®å¼‚: {mae:.6f}")
    print(f"  å·®å¼‚æ ‡å‡†å·®: {np.std(abs_errors):.6f}")
    print(f"  æœ€å¤§å·®å¼‚: {np.max(abs_errors):.6f}")
    print(f"  æœ€å°å·®å¼‚: {np.min(abs_errors):.6f}")
    
    # å·®å¼‚åˆ†å¸ƒ
    small_diff = np.sum(abs_errors < 0.1)
    medium_diff = np.sum((abs_errors >= 0.1) & (abs_errors < 1.0))
    large_diff = np.sum(abs_errors >= 1.0)
    
    print(f"\nğŸ“Š å·®å¼‚åˆ†å¸ƒ:")
    print(f"  å·®å¼‚<0.1: {small_diff} ({small_diff/len(abs_errors)*100:.1f}%)")
    print(f"  å·®å¼‚0.1-1.0: {medium_diff} ({medium_diff/len(abs_errors)*100:.1f}%)")
    print(f"  å·®å¼‚>1.0: {large_diff} ({large_diff/len(abs_errors)*100:.1f}%)")

else:
    print("âŒ é¢„æµ‹å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œå¯¹æ¯”åˆ†æ") 