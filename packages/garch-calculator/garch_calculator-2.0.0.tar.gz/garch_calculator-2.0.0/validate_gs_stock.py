#!/usr/bin/env python3
"""
é«˜ç››(GS)è‚¡ç¥¨æ•°æ®GARCHæ¨¡å‹éªŒè¯è„šæœ¬
ä½¿ç”¨yfinanceè·å–çœŸå®è‚¡ç¥¨æ•°æ®ï¼Œæ¯”è¾ƒgarch_libå’ŒPython archåº“çš„è¡¨ç°
"""

import numpy as np
import pandas as pd
import time
import warnings
import sys
import os
import yfinance as yf
from datetime import datetime, timedelta
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')
sys.path.append('.')

try:
    from arch import arch_model
    HAS_ARCH = True
    print("âœ“ Successfully imported arch library")
except ImportError:
    HAS_ARCH = False
    print("âŒ Failed to import arch library")

try:
    import garch_calculator as gc
    HAS_GARCH_LIB = True
    print("âœ“ Successfully imported garch_calculator")
except ImportError:
    HAS_GARCH_LIB = False
    print("âŒ Failed to import garch_calculator")

def download_gs_data(period="5y", interval="1d"):
    """ä¸‹è½½é«˜ç››è‚¡ç¥¨æ•°æ®"""
    print(f"ğŸ“Š ä¸‹è½½é«˜ç››(GS)è‚¡ç¥¨æ•°æ®...")
    print(f"   æœŸé—´: {period}, é—´éš”: {interval}")
    
    try:
        # åˆ›å»ºè‚¡ç¥¨å¯¹è±¡
        gs = yf.Ticker("GS")
        
        # ä¸‹è½½å†å²æ•°æ®
        data = gs.history(period=period, interval=interval)
        
        if data.empty:
            print("âŒ æœªèƒ½è·å–åˆ°æ•°æ®")
            return None
        
        print(f"âœ“ æˆåŠŸè·å–æ•°æ®ï¼Œæ—¶é—´èŒƒå›´: {data.index[0]} åˆ° {data.index[-1]}")
        print(f"âœ“ æ•°æ®ç‚¹æ•°: {len(data)}")
        print(f"âœ“ ä»·æ ¼èŒƒå›´: ${data['Close'].min():.2f} - ${data['Close'].max():.2f}")
        
        return data
    
    except Exception as e:
        print(f"âŒ ä¸‹è½½æ•°æ®å¤±è´¥: {e}")
        return None

def prepare_returns_data(stock_data, return_type="log"):
    """å‡†å¤‡æ”¶ç›Šç‡æ•°æ®"""
    print(f"\nğŸ“ˆ å‡†å¤‡æ”¶ç›Šç‡æ•°æ® (ç±»å‹: {return_type})")
    
    # ä½¿ç”¨æ”¶ç›˜ä»·
    prices = stock_data['Close'].dropna()
    
    if return_type == "log":
        # å¯¹æ•°æ”¶ç›Šç‡
        returns = np.log(prices / prices.shift(1)).dropna()
    else:
        # ç®€å•æ”¶ç›Šç‡
        returns = (prices / prices.shift(1) - 1).dropna()
    
    # å»é™¤æç«¯å¼‚å¸¸å€¼ï¼ˆè¶…è¿‡5ä¸ªæ ‡å‡†å·®ï¼‰
    mean_return = returns.mean()
    std_return = returns.std()
    returns = returns[np.abs(returns - mean_return) <= 5 * std_return]
    
    # ä¸­å¿ƒåŒ–å¤„ç†ï¼ˆå»é™¤å‡å€¼ï¼‰
    returns = returns - returns.mean()
    
    print(f"âœ“ æ”¶ç›Šç‡ç»Ÿè®¡:")
    print(f"   æ•°æ®ç‚¹æ•°: {len(returns)}")
    print(f"   å‡å€¼: {returns.mean():.8f}")
    print(f"   æ ‡å‡†å·®: {returns.std():.6f}")
    print(f"   ååº¦: {returns.skew():.4f}")
    print(f"   å³°åº¦: {returns.kurtosis():.4f}")
    print(f"   æœ€å°å€¼: {returns.min():.6f}")
    print(f"   æœ€å¤§å€¼: {returns.max():.6f}")
    
    return returns.values

def test_arch_lib(returns, test_ratio=0.2):
    """æµ‹è¯•Python archåº“"""
    if not HAS_ARCH:
        print("\nâŒ è·³è¿‡archåº“æµ‹è¯• - åº“æœªå®‰è£…")
        return None
        
    print("\n" + "="*60)
    print("ğŸ Python archåº“æµ‹è¯•")
    print("="*60)
    
    start_time = time.time()
    
    try:
        # åˆ†å‰²æ•°æ®
        split_point = int(len(returns) * (1 - test_ratio))
        train_returns = returns[:split_point]
        test_returns = returns[split_point:]
        
        print(f"è®­ç»ƒæ•°æ®: {len(train_returns)} ç‚¹")
        print(f"æµ‹è¯•æ•°æ®: {len(test_returns)} ç‚¹")
        
        # åˆ›å»ºå¹¶æ‹ŸåˆGARCH(1,1)-GEDæ¨¡å‹
        print("\nğŸ”§ æ‹ŸåˆGARCH(1,1)-GEDæ¨¡å‹...")
        model = arch_model(train_returns, vol='GARCH', p=1, q=1, dist='ged', rescale=False)
        fitted_model = model.fit(disp='off', show_warning=False)
        fit_time = time.time() - start_time
        
        # è·å–å‚æ•°
        params = fitted_model.params
        
        print(f"âœ“ æ¨¡å‹æ‹Ÿåˆå®Œæˆ (è€—æ—¶: {fit_time:.4f}ç§’)")
        print(f"âœ“ æ”¶æ•›çŠ¶æ€: {fitted_model.convergence_flag == 0}")
        
        # æ ·æœ¬å†…æ³¢åŠ¨ç‡é¢„æµ‹
        start_vol_time = time.time()
        insample_volatility = fitted_model.conditional_volatility
        
        # æ ·æœ¬å¤–é¢„æµ‹
        forecast_horizon = len(test_returns)
        try:
            forecast = fitted_model.forecast(horizon=forecast_horizon, start=split_point)
            if forecast.variance.values.shape[0] > 0:
                forecast_volatility = np.sqrt(forecast.variance.values[-1, :])
            else:
                # å¤‡ç”¨æ–¹æ¡ˆ
                last_vol = insample_volatility[-1] if len(insample_volatility) > 0 else np.std(train_returns)
                forecast_volatility = np.full(forecast_horizon, last_vol)
        except Exception as e:
            print(f"âš ï¸  é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {e}")
            last_vol = insample_volatility[-1] if len(insample_volatility) > 0 else np.std(train_returns)
            forecast_volatility = np.full(forecast_horizon, last_vol)
        
        vol_prediction_time = time.time() - start_vol_time
        
        # è®¡ç®—å®é™…æ³¢åŠ¨ç‡ï¼ˆrolling stdï¼‰
        window_size = 10
        actual_volatility = []
        for i in range(len(test_returns)):
            if i < window_size:
                actual_vol = np.std(test_returns[:i+1]) if i > 0 else np.std(train_returns[-window_size:])
            else:
                actual_vol = np.std(test_returns[i-window_size:i])
            actual_volatility.append(actual_vol)
        actual_volatility = np.array(actual_volatility)
        
        result = {
            'library': 'arch',
            'omega': params['omega'],
            'alpha': params['alpha[1]'],
            'beta': params['beta[1]'],
            'nu': params['nu'],
            'log_likelihood': fitted_model.loglikelihood,
            'aic': fitted_model.aic,
            'bic': fitted_model.bic,
            'fit_time': fit_time,
            'vol_prediction_time': vol_prediction_time,
            'converged': fitted_model.convergence_flag == 0,
            'insample_volatility': insample_volatility,
            'forecast_volatility': forecast_volatility,
            'actual_volatility': actual_volatility,
            'train_size': len(train_returns),
            'test_size': len(test_returns)
        }
        
        # è®¡ç®—é¢„æµ‹ç²¾åº¦
        if len(forecast_volatility) == len(actual_volatility):
            result['forecast_mse'] = mean_squared_error(actual_volatility, forecast_volatility)
            result['forecast_mae'] = mean_absolute_error(actual_volatility, forecast_volatility)
            result['forecast_rmse'] = np.sqrt(result['forecast_mse'])
        
        print(f"âœ“ å‚æ•°ä¼°è®¡:")
        print(f"   Ï‰ (omega): {result['omega']:.8f}")
        print(f"   Î± (alpha): {result['alpha']:.6f}")
        print(f"   Î² (beta):  {result['beta']:.6f}")
        print(f"   Î½ (nu):    {result['nu']:.6f}")
        print(f"âœ“ å¯¹æ•°ä¼¼ç„¶: {result['log_likelihood']:.6f}")
        print(f"âœ“ AIC: {result['aic']:.6f}")
        print(f"âœ“ BIC: {result['bic']:.6f}")
        if 'forecast_rmse' in result:
            print(f"âœ“ æ³¢åŠ¨ç‡é¢„æµ‹RMSE: {result['forecast_rmse']:.6f}")
        
        return result
        
    except Exception as e:
        print(f"âŒ archåº“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_garch_lib(returns, test_ratio=0.2):
    """æµ‹è¯•garch_libå®ç°"""
    if not HAS_GARCH_LIB:
        print("\nâŒ è·³è¿‡garch_libæµ‹è¯• - åº“æœªå®‰è£…")
        return None
        
    print("\n" + "="*60)
    print("âš¡ garch_libæµ‹è¯•")
    print("="*60)
    
    start_time = time.time()
    
    try:
        # åˆ†å‰²æ•°æ®
        split_point = int(len(returns) * (1 - test_ratio))
        train_returns = returns[:split_point]
        test_returns = returns[split_point:]
        
        print(f"è®­ç»ƒæ•°æ®: {len(train_returns)} ç‚¹")
        print(f"æµ‹è¯•æ•°æ®: {len(test_returns)} ç‚¹")
        
        # åˆ›å»ºè®¡ç®—å™¨
        min_samples = min(50, len(train_returns) // 3)
        calc = gc.GarchCalculator(history_size=len(train_returns)+100, min_samples=min_samples)
        print(f"GarchCalculatoråˆå§‹åŒ–: history_size={len(train_returns)+100}, min_samples={min_samples}")
        
        # å°†æ”¶ç›Šç‡è½¬æ¢ä¸ºä»·æ ¼åºåˆ—
        base_price = 100.0
        train_prices = np.zeros(len(train_returns) + 1)
        train_prices[0] = base_price
        
        # æ•°å€¼ç¨³å®šæ€§å¤„ç†
        returns_std = np.std(train_returns)
        if returns_std > 1.0:
            scale_factor = 0.5 / returns_std
        elif returns_std < 0.001:
            scale_factor = 0.01 / returns_std
        else:
            scale_factor = 1.0
        
        scaled_returns = train_returns * scale_factor
        
        # ç”Ÿæˆä»·æ ¼åºåˆ—
        for i in range(len(train_returns)):
            clamped_return = np.clip(scaled_returns[i], -0.49, 2.0)
            new_price = train_prices[i] * (1 + clamped_return)
            
            if new_price <= 0 or not np.isfinite(new_price):
                new_price = train_prices[i] * (1 + np.sign(clamped_return) * 0.001)
            
            train_prices[i+1] = new_price
        
        print(f"ç¼©æ”¾å› å­: {scale_factor:.6f}")
        print(f"ä»·æ ¼åºåˆ—èŒƒå›´: [{np.min(train_prices):.6f}, {np.max(train_prices):.6f}]")
        
        # æ·»åŠ è®­ç»ƒæ•°æ®å¹¶ä¼°è®¡å‚æ•°
        print("\nğŸ”§ æ‹ŸåˆGARCH(1,1)-GEDæ¨¡å‹...")
        calc.add_price_points(train_prices.tolist())
        print(f"æ•°æ®ç‚¹æ•°é‡: {calc.get_data_size()}, è¶³å¤Ÿæ•°æ®: {calc.has_enough_data()}")
        
        result_obj = calc.estimate_parameters()
        fit_time = time.time() - start_time
        
        print(f"âœ“ æ¨¡å‹æ‹Ÿåˆå®Œæˆ (è€—æ—¶: {fit_time:.4f}ç§’)")
        print(f"âœ“ æ”¶æ•›çŠ¶æ€: {result_obj.converged}")
        print(f"âœ“ è¿­ä»£æ¬¡æ•°: {result_obj.iterations}")
        
        if not result_obj.converged:
            print("âš ï¸  æ¨¡å‹æœªå®Œå…¨æ”¶æ•›ï¼Œä½†ç»§ç»­ä½¿ç”¨ä¼°è®¡å‚æ•°")
        
        params = result_obj.parameters
        
        # æ ·æœ¬å†…æ³¢åŠ¨ç‡é¢„æµ‹
        start_vol_time = time.time()
        try:
            variance_series = calc.get_variance_series()
            if len(variance_series) > 0:
                insample_volatility = np.sqrt(variance_series)
            else:
                current_vol = calc.get_current_volatility()
                insample_volatility = np.full(len(train_prices), current_vol)
        except:
            current_vol = calc.get_current_volatility()
            insample_volatility = np.full(len(train_prices), current_vol)
        
        # æ ·æœ¬å¤–é¢„æµ‹
        forecast_volatility = []
        test_prices = np.zeros(len(test_returns) + 1)
        test_prices[0] = train_prices[-1]
        scaled_test_returns = test_returns * scale_factor
        
        for i in range(len(test_returns)):
            try:
                forecast_obj = calc.forecast_volatility(1)
                if forecast_obj.volatility > 0 and np.isfinite(forecast_obj.volatility):
                    forecast_volatility.append(forecast_obj.volatility)
                else:
                    current_vol = calc.get_current_volatility()
                    forecast_volatility.append(current_vol)
                    
                test_prices[i+1] = test_prices[i] * (1 + scaled_test_returns[i])
                if test_prices[i+1] <= 0:
                    test_prices[i+1] = test_prices[i] * 0.999
                calc.add_price_point(test_prices[i+1])
                calc.update_model()
                
            except Exception as e:
                print(f"âš ï¸  é¢„æµ‹æ­¥éª¤ {i+1} å‡ºé”™: {e}")
                try:
                    current_vol = calc.get_current_volatility()
                    forecast_volatility.append(current_vol)
                except:
                    forecast_volatility.append(np.std(scaled_returns))
                break
            
        forecast_volatility = np.array(forecast_volatility)
        vol_prediction_time = time.time() - start_vol_time
        
        # è®¡ç®—å®é™…æ³¢åŠ¨ç‡
        window_size = 10
        actual_volatility = []
        for i in range(len(test_returns)):
            if i < window_size:
                actual_vol = np.std(test_returns[:i+1]) if i > 0 else np.std(train_returns[-window_size:])
            else:
                actual_vol = np.std(test_returns[i-window_size:i])
            actual_volatility.append(actual_vol)
        actual_volatility = np.array(actual_volatility)
        
        result = {
            'library': 'garch_lib',
            'omega': params.omega,
            'alpha': params.alpha,
            'beta': params.beta,
            'nu': params.nu,
            'log_likelihood': result_obj.log_likelihood,
            'aic': result_obj.aic,
            'bic': result_obj.bic,
            'fit_time': fit_time,
            'vol_prediction_time': vol_prediction_time,
            'converged': result_obj.converged,
            'iterations': result_obj.iterations,
            'insample_volatility': insample_volatility,
            'forecast_volatility': forecast_volatility,
            'actual_volatility': actual_volatility,
            'train_size': len(train_returns),
            'test_size': len(test_returns)
        }
        
        # è®¡ç®—é¢„æµ‹ç²¾åº¦
        if len(forecast_volatility) == len(actual_volatility):
            result['forecast_mse'] = mean_squared_error(actual_volatility, forecast_volatility)
            result['forecast_mae'] = mean_absolute_error(actual_volatility, forecast_volatility)
            result['forecast_rmse'] = np.sqrt(result['forecast_mse'])
        elif len(forecast_volatility) > 0 and len(actual_volatility) > 0:
            min_len = min(len(forecast_volatility), len(actual_volatility))
            print(f"âš ï¸  é¢„æµ‹é•¿åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨å‰{min_len}ä¸ªç‚¹è¿›è¡Œè¯„ä¼°")
            result['forecast_mse'] = mean_squared_error(actual_volatility[:min_len], forecast_volatility[:min_len])
            result['forecast_mae'] = mean_absolute_error(actual_volatility[:min_len], forecast_volatility[:min_len])
            result['forecast_rmse'] = np.sqrt(result['forecast_mse'])
        
        print(f"âœ“ å‚æ•°ä¼°è®¡:")
        print(f"   Ï‰ (omega): {result['omega']:.8f}")
        print(f"   Î± (alpha): {result['alpha']:.6f}")
        print(f"   Î² (beta):  {result['beta']:.6f}")
        print(f"   Î½ (nu):    {result['nu']:.6f}")
        print(f"âœ“ å¯¹æ•°ä¼¼ç„¶: {result['log_likelihood']:.6f}")
        print(f"âœ“ AIC: {result['aic']:.6f}")
        print(f"âœ“ BIC: {result['bic']:.6f}")
        if 'forecast_rmse' in result:
            print(f"âœ“ æ³¢åŠ¨ç‡é¢„æµ‹RMSE: {result['forecast_rmse']:.6f}")
        
        return result
            
    except Exception as e:
        print(f"âŒ garch_libæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def compare_results(arch_result, garch_result):
    """æ¯”è¾ƒä¸¤ç§å®ç°çš„ç»“æœ"""
    print("\n" + "="*80)
    print("ğŸ” ç»“æœå¯¹æ¯”åˆ†æ")
    print("="*80)
    
    if arch_result is None and garch_result is None:
        print("âŒ ä¸¤ä¸ªåº“éƒ½æœªèƒ½æˆåŠŸè¿è¡Œ")
        return
    elif arch_result is None:
        print("âš ï¸  åªæœ‰garch_libæˆåŠŸè¿è¡Œ")
        return
    elif garch_result is None:
        print("âš ï¸  åªæœ‰Python archåº“æˆåŠŸè¿è¡Œ")
        return
    
    # å‚æ•°å¯¹æ¯”
    print("\nğŸ“Š å‚æ•°å¯¹æ¯”:")
    print(f"{'å‚æ•°':<8} {'Python arch':<15} {'garch_lib':<15} {'ç»å¯¹å·®å¼‚':<12} {'ç›¸å¯¹å·®å¼‚(%)':<12}")
    print("-" * 72)
    
    params = ['omega', 'alpha', 'beta', 'nu']
    param_errors = []
    
    for param in params:
        arch_val = arch_result[param]
        garch_val = garch_result[param]
        abs_diff = abs(garch_val - arch_val)
        rel_diff = abs_diff / abs(arch_val) * 100 if abs(arch_val) > 0 else 0
        param_errors.append(rel_diff)
        
        print(f"{param:<8} {arch_val:<15.8f} {garch_val:<15.8f} {abs_diff:<12.2e} {rel_diff:<12.2f}")
    
    avg_param_error = np.mean(param_errors)
    print(f"{'å¹³å‡':<8} {'':<15} {'':<15} {'':<12} {avg_param_error:<12.2f}")
    
    # æ¨¡å‹æ‹Ÿåˆè´¨é‡å¯¹æ¯”
    print(f"\nğŸ“ˆ æ¨¡å‹æ‹Ÿåˆè´¨é‡:")
    ll_diff = garch_result['log_likelihood'] - arch_result['log_likelihood']
    aic_diff = garch_result['aic'] - arch_result['aic']
    bic_diff = garch_result['bic'] - arch_result['bic']
    
    print(f"{'æŒ‡æ ‡':<15} {'Python arch':<15} {'garch_lib':<15} {'å·®å¼‚':<15}")
    print("-" * 65)
    print(f"{'å¯¹æ•°ä¼¼ç„¶':<15} {arch_result['log_likelihood']:<15.6f} {garch_result['log_likelihood']:<15.6f} {ll_diff:<15.6f}")
    print(f"{'AIC':<15} {arch_result['aic']:<15.6f} {garch_result['aic']:<15.6f} {aic_diff:<15.6f}")
    print(f"{'BIC':<15} {arch_result['bic']:<15.6f} {garch_result['bic']:<15.6f} {bic_diff:<15.6f}")
    
    # æ€§èƒ½å¯¹æ¯”
    print(f"\nâš¡ æ€§èƒ½å¯¹æ¯”:")
    fit_speedup = arch_result['fit_time'] / garch_result['fit_time'] if garch_result['fit_time'] > 0 else 0
    vol_speedup = arch_result['vol_prediction_time'] / garch_result['vol_prediction_time'] if garch_result['vol_prediction_time'] > 0 else 0
    
    print(f"{'æŒ‡æ ‡':<20} {'Python arch':<15} {'garch_lib':<15} {'æå‡å€æ•°':<15}")
    print("-" * 70)
    print(f"{'æ‹Ÿåˆæ—¶é—´(ç§’)':<20} {arch_result['fit_time']:<15.4f} {garch_result['fit_time']:<15.4f} {fit_speedup:<15.2f}")
    print(f"{'é¢„æµ‹æ—¶é—´(ç§’)':<20} {arch_result['vol_prediction_time']:<15.4f} {garch_result['vol_prediction_time']:<15.4f} {vol_speedup:<15.2f}")
    
    # é¢„æµ‹ç²¾åº¦å¯¹æ¯”
    if 'forecast_rmse' in arch_result and 'forecast_rmse' in garch_result:
        print(f"\nğŸ¯ é¢„æµ‹ç²¾åº¦å¯¹æ¯”:")
        arch_rmse = arch_result['forecast_rmse']
        garch_rmse = garch_result['forecast_rmse']
        rmse_diff = garch_rmse - arch_rmse
        rmse_rel_diff = rmse_diff / arch_rmse * 100 if arch_rmse > 0 else 0
        
        arch_mae = arch_result['forecast_mae']
        garch_mae = garch_result['forecast_mae']
        mae_diff = garch_mae - arch_mae
        mae_rel_diff = mae_diff / arch_mae * 100 if arch_mae > 0 else 0
        
        print(f"{'æŒ‡æ ‡':<15} {'Python arch':<15} {'garch_lib':<15} {'å·®å¼‚':<15} {'ç›¸å¯¹å·®å¼‚(%)':<15}")
        print("-" * 80)
        print(f"{'RMSE':<15} {arch_rmse:<15.6f} {garch_rmse:<15.6f} {rmse_diff:<15.6f} {rmse_rel_diff:<15.2f}")
        print(f"{'MAE':<15} {arch_mae:<15.6f} {garch_mae:<15.6f} {mae_diff:<15.6f} {mae_rel_diff:<15.2f}")
        
        if rmse_rel_diff < -1:
            print(f"âœ… garch_libçš„é¢„æµ‹ç²¾åº¦æ›´å¥½ (RMSEæ”¹å–„{-rmse_rel_diff:.1f}%)")
        elif rmse_rel_diff > 1:
            print(f"âš ï¸  archçš„é¢„æµ‹ç²¾åº¦æ›´å¥½ (RMSEå·®å¼‚{rmse_rel_diff:.1f}%)")
        else:
            print(f"ğŸ¤ ä¸¤ä¸ªåº“çš„é¢„æµ‹ç²¾åº¦ç›¸è¿‘")
    
    # æ”¶æ•›æ€§å¯¹æ¯”
    print(f"\nğŸ”„ æ”¶æ•›æ€§:")
    print(f"Python archæ”¶æ•›: {'âœ…' if arch_result['converged'] else 'âŒ'}")
    print(f"garch_libæ”¶æ•›:   {'âœ…' if garch_result['converged'] else 'âŒ'}")
    if 'iterations' in garch_result:
        print(f"garch_libè¿­ä»£æ¬¡æ•°: {garch_result['iterations']}")
    
    # æ€»ç»“
    print(f"\nğŸ“‹ æ€»ç»“:")
    if avg_param_error < 5:
        print(f"âœ… å‚æ•°ä¼°è®¡é«˜åº¦ä¸€è‡´ (å¹³å‡è¯¯å·®: {avg_param_error:.2f}%)")
    elif avg_param_error < 10:
        print(f"ğŸŸ¡ å‚æ•°ä¼°è®¡åŸºæœ¬ä¸€è‡´ (å¹³å‡è¯¯å·®: {avg_param_error:.2f}%)")
    else:
        print(f"âš ï¸  å‚æ•°ä¼°è®¡å­˜åœ¨å·®å¼‚ (å¹³å‡è¯¯å·®: {avg_param_error:.2f}%)")
    
    print(f"âš¡ garch_libæ‹Ÿåˆé€Ÿåº¦æå‡: {fit_speedup:.1f}å€")
    print(f"âš¡ garch_libé¢„æµ‹é€Ÿåº¦æå‡: {vol_speedup:.1f}å€")

def save_results(arch_result, garch_result, stock_data):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜è¯¦ç»†æ¯”è¾ƒç»“æœ
    results_summary = {
        'timestamp': timestamp,
        'stock': 'GS',
        'data_period': f"{stock_data.index[0]} to {stock_data.index[-1]}",
        'total_points': len(stock_data),
        'arch_result': arch_result,
        'garch_result': garch_result
    }
    
    # ä¿å­˜ä¸ºCSVæ ¼å¼
    if arch_result and garch_result:
        comparison_data = {
            'metric': ['omega', 'alpha', 'beta', 'nu', 'log_likelihood', 'aic', 'bic', 'fit_time', 'vol_prediction_time'],
            'arch_value': [
                arch_result['omega'], arch_result['alpha'], arch_result['beta'], arch_result['nu'],
                arch_result['log_likelihood'], arch_result['aic'], arch_result['bic'],
                arch_result['fit_time'], arch_result['vol_prediction_time']
            ],
            'garch_lib_value': [
                garch_result['omega'], garch_result['alpha'], garch_result['beta'], garch_result['nu'],
                garch_result['log_likelihood'], garch_result['aic'], garch_result['bic'],
                garch_result['fit_time'], garch_result['vol_prediction_time']
            ]
        }
        
        df = pd.DataFrame(comparison_data)
        csv_file = f"gs_stock_validation_{timestamp}.csv"
        df.to_csv(csv_file, index=False)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {csv_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ¦ é«˜ç››(GS)è‚¡ç¥¨ GARCH(1,1)-GED æ¨¡å‹éªŒè¯")
    print("=" * 80)
    print("æ¯”è¾ƒ garch_lib å’Œ Python arch åº“åœ¨çœŸå®è‚¡ç¥¨æ•°æ®ä¸Šçš„è¡¨ç°")
    print()
    
    # æ£€æŸ¥ä¾èµ–
    if not HAS_ARCH and not HAS_GARCH_LIB:
        print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•GARCHåº“ï¼Œè¯·å®‰è£…archæˆ–ç¼–è¯‘garch_lib")
        return
    
    try:
        # ä¸‹è½½è‚¡ç¥¨æ•°æ®
        stock_data = download_gs_data(period="2y", interval="1d")  # 2å¹´çš„æ—¥æ•°æ®
        if stock_data is None:
            return
        
        # å‡†å¤‡æ”¶ç›Šç‡æ•°æ®
        returns = prepare_returns_data(stock_data, return_type="log")
        
        if len(returns) < 100:
            print(f"âŒ æ•°æ®ç‚¹å¤ªå°‘ ({len(returns)}), éœ€è¦è‡³å°‘100ä¸ªç‚¹")
            return
        
        # è¿è¡Œä¸¤ä¸ªåº“çš„æµ‹è¯•
        arch_result = test_arch_lib(returns, test_ratio=0.2)
        garch_result = test_garch_lib(returns, test_ratio=0.2)
        
        # æ¯”è¾ƒç»“æœ
        compare_results(arch_result, garch_result)
        
        # ä¿å­˜ç»“æœ
        save_results(arch_result, garch_result, stock_data)
        
        print(f"\nâœ… é«˜ç››è‚¡ç¥¨éªŒè¯å®Œæˆ!")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­éªŒè¯è¿‡ç¨‹")
    except Exception as e:
        print(f"\nâŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 