import numpy as np
import pandas as pd
from scipy.special import gamma
import math
from arch import arch_model

# è¯»å–æ•°æ®
df = pd.read_csv('brett.csv')
returns = df['c_scaled'].values[:300]

# ä½¿ç”¨archåº“ä¼°è®¡å‚æ•°
arch_model_obj = arch_model(returns, vol='Garch', p=1, q=1, dist='ged', rescale=False)
arch_result = arch_model_obj.fit(disp='off', show_warning=False)

# è·å–å‚æ•°å’Œæ•°æ®
mu = arch_result.params['mu']
omega = arch_result.params['omega']
alpha = arch_result.params['alpha[1]']
beta = arch_result.params['beta[1]']
nu = arch_result.params['nu']

residuals = returns - mu
arch_cond_vol = arch_result.conditional_volatility

print("ğŸ”§ ä¿®å¤GEDä¼¼ç„¶å‡½æ•°")
print("=" * 60)
print(f"ç›®æ ‡ä¼¼ç„¶å€¼: {arch_result.loglikelihood:.6f}")

# å°è¯•ä¸åŒçš„GEDå®ç°ï¼ŒåŸºäºarchåº“çš„æºç 
def ged_likelihood_corrected(residuals, sigma, nu):
    """åŸºäºarchåº“æºç çš„æ­£ç¡®GEDå®ç°"""
    # archåº“ä½¿ç”¨çš„GEDå‚æ•°åŒ–
    # å‚è€ƒ: https://github.com/bashtage/arch/blob/main/arch/univariate/distribution.py
    
    # è®¡ç®—æ ‡å‡†åŒ–å› å­
    g1 = gamma(1.0 / nu)
    g3 = gamma(3.0 / nu)
    lam = np.sqrt(g1 / g3)
    
    # å¯¹æ•°ä¼¼ç„¶è®¡ç®—
    # log f(z) = log(nu) - log(2) - log(lam) - log(Î“(1/Î½)) - log(Ïƒ) - 0.5 * |z/lam|^Î½
    # å…¶ä¸­ z = Îµ/Ïƒ
    
    log_likelihood = 0.0
    
    for i in range(len(residuals)):
        eps = residuals[i]
        sig = sigma[i]
        
        # æ ‡å‡†åŒ–æ®‹å·®
        z = eps / sig
        
        # è®¡ç®— |z/Î»|^Î½
        abs_z_lam_pow_nu = np.power(np.abs(z / lam), nu)
        
        # å¯¹æ•°ä¼¼ç„¶è´¡çŒ®
        ll_i = (np.log(nu) - np.log(2.0) - np.log(lam) - math.lgamma(1.0/nu) 
                - np.log(sig) - 0.5 * abs_z_lam_pow_nu)
        
        log_likelihood += ll_i
    
    return log_likelihood

def ged_likelihood_v2(residuals, sigma, nu):
    """å¦ä¸€ç§å¯èƒ½çš„å®ç°"""
    # ä¸åŒçš„æ ‡å‡†åŒ–æ–¹å¼
    lam = np.sqrt(gamma(1.0/nu) / gamma(3.0/nu))
    
    log_likelihood = 0.0
    
    for i in range(len(residuals)):
        eps = residuals[i]
        sig = sigma[i]
        
        # æ ‡å‡†åŒ–æ®‹å·® (ä¸åŒçš„æ–¹å¼)
        z = eps / (lam * sig)
        
        # è®¡ç®— |z|^Î½
        abs_z_pow_nu = np.power(np.abs(z), nu)
        
        # å¯¹æ•°ä¼¼ç„¶è´¡çŒ®
        ll_i = (np.log(nu) - np.log(2.0) - np.log(lam) - math.lgamma(1.0/nu) 
                - np.log(sig) - 0.5 * abs_z_pow_nu)
        
        log_likelihood += ll_i
    
    return log_likelihood

def ged_likelihood_v3(residuals, sigma, nu):
    """ç¬¬ä¸‰ç§å®ç° - åŸºäºæ ‡å‡†GEDå…¬å¼"""
    # æ ‡å‡†GEDå¯†åº¦å‡½æ•°
    # f(x) = Î½/(2^(1+1/Î½) * Î“(1/Î½) * Ïƒ) * exp(-0.5 * |x/Ïƒ|^Î½ / Î»^Î½)
    # å…¶ä¸­ Î» = (Î“(1/Î½)/Î“(3/Î½))^(1/2)
    
    lam = np.sqrt(gamma(1.0/nu) / gamma(3.0/nu))
    
    log_likelihood = 0.0
    
    for i in range(len(residuals)):
        eps = residuals[i]
        sig = sigma[i]
        
        # æ ‡å‡†åŒ–æ®‹å·®
        z = eps / sig
        
        # è®¡ç®— |z|^Î½ / Î»^Î½
        abs_z_pow_nu_over_lam_nu = np.power(np.abs(z), nu) / np.power(lam, nu)
        
        # å¯¹æ•°ä¼¼ç„¶è´¡çŒ®
        ll_i = (np.log(nu) - (1.0 + 1.0/nu) * np.log(2.0) - math.lgamma(1.0/nu) 
                - np.log(sig) - 0.5 * abs_z_pow_nu_over_lam_nu)
        
        log_likelihood += ll_i
    
    return log_likelihood

# æµ‹è¯•ä¸åŒå®ç°
print(f"\nğŸ§ª æµ‹è¯•ä¿®å¤çš„GEDå®ç°:")

# ä½¿ç”¨archåº“çš„æ¡ä»¶æ³¢åŠ¨ç‡
ll_v1 = ged_likelihood_corrected(residuals, arch_cond_vol, nu)
ll_v2 = ged_likelihood_v2(residuals, arch_cond_vol, nu)
ll_v3 = ged_likelihood_v3(residuals, arch_cond_vol, nu)

print(f"å®ç°v1: {ll_v1:.6f} (å·®å¼‚: {abs(ll_v1 - arch_result.loglikelihood):.6f})")
print(f"å®ç°v2: {ll_v2:.6f} (å·®å¼‚: {abs(ll_v2 - arch_result.loglikelihood):.6f})")
print(f"å®ç°v3: {ll_v3:.6f} (å·®å¼‚: {abs(ll_v3 - arch_result.loglikelihood):.6f})")

# æ‰¾åˆ°æœ€ä½³å®ç°
best_impl = min([(ll_v1, 'v1'), (ll_v2, 'v2'), (ll_v3, 'v3')], 
                key=lambda x: abs(x[0] - arch_result.loglikelihood))

print(f"\nâœ… æœ€ä½³å®ç°: {best_impl[1]} (ä¼¼ç„¶å€¼: {best_impl[0]:.6f})")

# éªŒè¯æ¡ä»¶æ–¹å·®è®¡ç®—
def calculate_garch_variances_exact(residuals, omega, alpha, beta):
    """ç²¾ç¡®çš„GARCHæ¡ä»¶æ–¹å·®è®¡ç®—"""
    n = len(residuals)
    sigma2 = np.zeros(n)
    
    # åˆå§‹æ–¹å·® - å°è¯•ä¸åŒçš„åˆå§‹åŒ–æ–¹æ³•
    sigma2[0] = omega / (1 - alpha - beta)  # æ— æ¡ä»¶æ–¹å·®
    
    for t in range(1, n):
        sigma2[t] = omega + alpha * residuals[t-1]**2 + beta * sigma2[t-1]
        # ç¡®ä¿æ–¹å·®ä¸ºæ­£
        sigma2[t] = max(sigma2[t], 1e-8)
    
    return sigma2

# é‡æ–°è®¡ç®—æ¡ä»¶æ–¹å·®
manual_var_exact = calculate_garch_variances_exact(residuals, omega, alpha, beta)
manual_vol_exact = np.sqrt(manual_var_exact)

print(f"\nğŸ“Š ç²¾ç¡®æ¡ä»¶æ–¹å·®å¯¹æ¯”:")
print(f"archåº“æ–¹å·®å‡å€¼: {(arch_cond_vol**2).mean():.8f}")
print(f"æ‰‹åŠ¨è®¡ç®—æ–¹å·®å‡å€¼: {manual_var_exact.mean():.8f}")
print(f"æ–¹å·®å·®å¼‚: {np.abs((arch_cond_vol**2) - manual_var_exact).mean():.8f}")
print(f"æœ€å¤§æ–¹å·®å·®å¼‚: {np.abs((arch_cond_vol**2) - manual_var_exact).max():.8f}")

# ä½¿ç”¨ç²¾ç¡®çš„æ¡ä»¶æ–¹å·®é‡æ–°æµ‹è¯•
if best_impl[1] == 'v1':
    ll_exact = ged_likelihood_corrected(residuals, manual_vol_exact, nu)
elif best_impl[1] == 'v2':
    ll_exact = ged_likelihood_v2(residuals, manual_vol_exact, nu)
else:
    ll_exact = ged_likelihood_v3(residuals, manual_vol_exact, nu)

print(f"\nä½¿ç”¨ç²¾ç¡®æ¡ä»¶æ–¹å·®çš„ä¼¼ç„¶å€¼: {ll_exact:.6f} (å·®å¼‚: {abs(ll_exact - arch_result.loglikelihood):.6f})")

# åˆ†ææ®‹å·®çš„ç»Ÿè®¡ç‰¹æ€§
print(f"\nğŸ“ˆ æ®‹å·®ç»Ÿè®¡åˆ†æ:")
print(f"æ®‹å·®å‡å€¼: {residuals.mean():.6f}")
print(f"æ®‹å·®æ ‡å‡†å·®: {residuals.std():.6f}")
print(f"æ®‹å·®ååº¦: {pd.Series(residuals).skew():.4f}")
print(f"æ®‹å·®å³°åº¦: {pd.Series(residuals).kurtosis():.4f}")

# æ£€æŸ¥æç«¯å€¼çš„å½±å“
extreme_mask = np.abs(residuals) > 3 * np.std(residuals)
print(f"æç«¯å€¼æ•°é‡: {np.sum(extreme_mask)}")
if np.sum(extreme_mask) > 0:
    print(f"æç«¯å€¼: {residuals[extreme_mask]}")
    
    # è®¡ç®—å»é™¤æç«¯å€¼åçš„ä¼¼ç„¶
    residuals_clean = residuals[~extreme_mask]
    sigma_clean = arch_cond_vol[~extreme_mask]
    
    if best_impl[1] == 'v1':
        ll_clean = ged_likelihood_corrected(residuals_clean, sigma_clean, nu)
    elif best_impl[1] == 'v2':
        ll_clean = ged_likelihood_v2(residuals_clean, sigma_clean, nu)
    else:
        ll_clean = ged_likelihood_v3(residuals_clean, sigma_clean, nu)
    
    print(f"å»é™¤æç«¯å€¼åçš„ä¼¼ç„¶å€¼: {ll_clean:.6f}")

print(f"\nğŸ’¡ ä¿®å¤å»ºè®®:")
print(f"1. ä½¿ç”¨å®ç°{best_impl[1]}ä½œä¸ºGEDä¼¼ç„¶å‡½æ•°")
print(f"2. æ”¹è¿›æ¡ä»¶æ–¹å·®è®¡ç®—çš„æ•°å€¼ç²¾åº¦")
print(f"3. å¤„ç†æç«¯å€¼ä»¥æé«˜æ•°å€¼ç¨³å®šæ€§") 