import garch_lib as gc
import pandas as pd
import numpy as np
from arch import arch_model
import matplotlib.pyplot as plt
from datetime import datetime

# 1. è¯»å– CSV æ–‡ä»¶
print("ðŸ“Š è¯»å– brett.csv æ–‡ä»¶...")
df = pd.read_csv('brett.csv')

# 2. æå– c_scaled åˆ—ä½œä¸ºæ”¶ç›ŠçŽ‡æ•°æ®
returns = df['c_scaled'].values
print(f"   æ•°æ®æ€»é‡: {len(returns)} ä¸ªæ•°æ®ç‚¹")
print(f"   æ•°æ®èŒƒå›´: {returns.min():.6f} åˆ° {returns.max():.6f}")

# 3. è®¾ç½®æ»šåŠ¨çª—å£å‚æ•°
window_size = 500  # å®žç›˜åº”ç”¨çš„æ ‡å‡†çª—å£å¤§å°
min_periods = window_size  

# å­˜å‚¨é¢„æµ‹ç»“æžœ
garch_lib_predictions = []
arch_lib_predictions = []
prediction_dates = []

print(f"\nðŸ”„ å¼€å§‹æ»šåŠ¨é¢„æµ‹ (çª—å£å¤§å°: {window_size})")
print("=" * 60)

# 4. æ»šåŠ¨é¢„æµ‹
for i in range(window_size, len(returns)):
    # èŽ·å–å½“å‰çª—å£çš„æ•°æ®
    window_data = returns[i-window_size:i]
    
    try:
        # === ä½¿ç”¨ garch_lib è¿›è¡Œé¢„æµ‹ ===
        calc = gc.GarchCalculator(history_size=window_size + 10)
        # å…³é”®ä¿®æ”¹ï¼šä¸ä½¿ç”¨ç¼©æ”¾ï¼Œç›´æŽ¥ä½¿ç”¨åŽŸå§‹æ•°æ®
        calc.add_returns(window_data.tolist())
        garch_lib_result = calc.estimate_parameters()
        
        # æ£€æŸ¥ä¼°è®¡æ˜¯å¦æ”¶æ•›
        if not garch_lib_result.converged:
            print(f"è­¦å‘Š: garch_lib åœ¨ç´¢å¼• {i} æœªæ”¶æ•›ï¼Œè·³è¿‡")
            continue
            
        garch_lib_forecast = calc.forecast_volatility(1)
        garch_lib_vol = garch_lib_forecast.volatility
        garch_lib_predictions.append(garch_lib_vol)
        
        # === ä½¿ç”¨ arch åº“è¿›è¡Œé¢„æµ‹ ===
        # å…³é”®ä¿®æ”¹ï¼šä¹Ÿä¸ä½¿ç”¨ç¼©æ”¾ï¼Œä¿æŒä¸€è‡´æ€§
        arch_model_obj = arch_model(window_data, vol='Garch', p=1, q=1, dist='ged', rescale=False)
        arch_result = arch_model_obj.fit(disp='off', show_warning=False)
        arch_forecast = arch_result.forecast(horizon=1, reindex=False)
        arch_predictions = np.sqrt(arch_forecast.variance.values[-1, :])
        arch_lib_predictions.append(arch_predictions[0])
        
        prediction_dates.append(i)
        
        # æ¯50ä¸ªé¢„æµ‹ç‚¹è¾“å‡ºä¸€æ¬¡è¿›åº¦å’Œè°ƒè¯•ä¿¡æ¯
        if (i - window_size + 1) % 50 == 0:
            progress = (i - window_size + 1) / (len(returns) - window_size) * 100
            print(f"è¿›åº¦: {progress:.1f}% ({i - window_size + 1}/{len(returns) - window_size})")
            print(f"  æœ€è¿‘ä¼°è®¡å‚æ•° - æ”¶æ•›: {garch_lib_result.converged}")
            print(f"  omega: {garch_lib_result.parameters.omega:.6f}, alpha: {garch_lib_result.parameters.alpha:.6f}")
            print(f"  beta: {garch_lib_result.parameters.beta:.6f}, nu: {garch_lib_result.parameters.nu:.6f}")
            print(f"  garch_libé¢„æµ‹: {garch_lib_vol:.6f}, archåº“é¢„æµ‹: {arch_predictions[0]:.6f}")
            print(f"  archåº“å‚æ•°: omega={arch_result.params['omega']:.6f}, alpha={arch_result.params['alpha[1]']:.6f}")
            print(f"              beta={arch_result.params['beta[1]']:.6f}, nu={arch_result.params['nu']:.6f}")
            
    except Exception as e:
        print(f"é¢„æµ‹å¤±è´¥ at index {i}: {str(e)}")
        continue

print(f"\nâœ… æ»šåŠ¨é¢„æµ‹å®Œæˆ!")
print(f"   æˆåŠŸé¢„æµ‹: {len(garch_lib_predictions)} ä¸ªç‚¹")

# 5. ç»“æžœå¯¹æ¯”åˆ†æž
if len(garch_lib_predictions) > 0 and len(arch_lib_predictions) > 0:
    garch_lib_arr = np.array(garch_lib_predictions)
    arch_lib_arr = np.array(arch_lib_predictions)
    
    print(f"\nðŸ“Š é¢„æµ‹ç»“æžœç»Ÿè®¡å¯¹æ¯”:")
    print("=" * 60)
    print(f"{'æŒ‡æ ‡':<20} {'garch_lib':<15} {'archåº“':<15} {'å·®å¼‚':<10}")
    print("-" * 60)
    print(f"{'å¹³å‡å€¼':<20} {garch_lib_arr.mean():<15.6f} {arch_lib_arr.mean():<15.6f} {abs(garch_lib_arr.mean() - arch_lib_arr.mean()):<10.6f}")
    print(f"{'æ ‡å‡†å·®':<20} {garch_lib_arr.std():<15.6f} {arch_lib_arr.std():<15.6f} {abs(garch_lib_arr.std() - arch_lib_arr.std()):<10.6f}")
    print(f"{'æœ€å°å€¼':<20} {garch_lib_arr.min():<15.6f} {arch_lib_arr.min():<15.6f} {abs(garch_lib_arr.min() - arch_lib_arr.min()):<10.6f}")
    print(f"{'æœ€å¤§å€¼':<20} {garch_lib_arr.max():<15.6f} {arch_lib_arr.max():<15.6f} {abs(garch_lib_arr.max() - arch_lib_arr.max()):<10.6f}")
    
    # è®¡ç®—ç›¸å…³ç³»æ•°
    correlation = np.corrcoef(garch_lib_arr, arch_lib_arr)[0, 1]
    print(f"{'ç›¸å…³ç³»æ•°':<20} {correlation:<30.6f}")
    
    # è®¡ç®—RMSEå’ŒMAE
    rmse = np.sqrt(np.mean((garch_lib_arr - arch_lib_arr)**2))
    mae = np.mean(np.abs(garch_lib_arr - arch_lib_arr))
    print(f"{'RMSE':<20} {rmse:<30.6f}")
    print(f"{'MAE':<20} {mae:<30.6f}")
    
    # è®¡ç®—ç›¸å¯¹è¯¯å·®
    mape = np.mean(np.abs((garch_lib_arr - arch_lib_arr) / arch_lib_arr)) * 100
    print(f"{'MAPE (%)':<20} {mape:<30.2f}")
    
    # 6. ä¿å­˜é¢„æµ‹ç»“æžœåˆ°CSV
    results_df = pd.DataFrame({
        'prediction_index': prediction_dates,
        'garch_lib_volatility': garch_lib_predictions,
        'arch_lib_volatility': arch_lib_predictions,
        'difference': garch_lib_arr - arch_lib_arr,
        'relative_error': (garch_lib_arr - arch_lib_arr) / arch_lib_arr * 100
    })
    
    results_df.to_csv('volatility_predictions_comparison.csv', index=False)
    print(f"\nðŸ’¾ é¢„æµ‹ç»“æžœå·²ä¿å­˜è‡³: volatility_predictions_comparison.csv")
    
    # 7. æ˜¾ç¤ºæœ€è¿‘å‡ ä¸ªé¢„æµ‹ç»“æžœ
    print(f"\nðŸ” æœ€è¿‘15ä¸ªé¢„æµ‹ç»“æžœ:")
    print("-" * 90)
    print(f"{'ç´¢å¼•':<8} {'garch_lib':<15} {'archåº“':<15} {'å·®å¼‚':<15} {'ç›¸å¯¹è¯¯å·®%':<12}")
    print("-" * 90)
    for i in range(max(0, len(results_df)-15), len(results_df)):
        row = results_df.iloc[i]
        print(f"{int(row['prediction_index']):<8} {row['garch_lib_volatility']:<15.6f} {row['arch_lib_volatility']:<15.6f} {row['difference']:<15.6f} {row['relative_error']:<12.2f}%")

else:
    print("âŒ é¢„æµ‹å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œå¯¹æ¯”åˆ†æž")