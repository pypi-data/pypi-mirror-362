# Supported Providers

`any-llm` supports the following providers:

- [OpenAI](https://platform.openai.com/docs/api-reference)
- [Anthropic](https://docs.anthropic.com/en/home)
- [Google](https://cloud.google.com/vertex-ai/docs)
- [Mistral](https://docs.mistral.ai/)
- [Ollama](https://github.com/ollama/ollama)
- [DeepSeek](https://platform.deepseek.com/)
- [HuggingFace](https://huggingface.co/inference-endpoints)
- [Cohere](https://cohere.com/api)
- [Cerebras](https://docs.cerebras.ai/)
- [Fireworks](https://fireworks.ai/api)
- [Groq](https://groq.com/api)
- [AWS Bedrock](https://aws.amazon.com/bedrock/)
- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)
- [IBM Watsonx](https://www.ibm.com/watsonx)
- [Inception Labs](https://inceptionlabs.ai/)
- [Moonshot AI](https://platform.moonshot.ai/)
- [Nebius AI Studio](https://studio.nebius.ai/)
- [SambaNova](https://sambanova.ai/)
- [Together AI](https://together.ai/)
- [xAI](https://x.ai/)

You can browse the implementations via the providers folder:

[https://github.com/mozilla-ai/any-llm/tree/main/src/any_llm/providers](https://github.com/mozilla-ai/any-llm/tree/main/src/any_llm/providers)
