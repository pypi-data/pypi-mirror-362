[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "opencrawler"
version = "1.0.2"
description = "Production-ready, enterprise-grade web scraping and crawling framework with advanced AI integration"
readme = "README.md"
license = {text = "MIT"}
authors = [
    {name = "Nik Jois", email = "nikjois@llamasearch.ai"}
]
maintainers = [
    {name = "Nik Jois", email = "nikjois@llamasearch.ai"}
]
keywords = [
    "web-scraping", 
    "crawling", 
    "ai", 
    "llm", 
    "automation", 
    "data-extraction",
    "playwright",
    "selenium",
    "fastapi",
    "microservices",
    "enterprise",
    "production"
]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Intended Audience :: Information Technology",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3 :: Only",
    "Topic :: Internet :: WWW/HTTP :: Indexing/Search",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: System :: Distributed Computing",
    "Framework :: FastAPI",
    "Framework :: AsyncIO",
    "Environment :: Web Environment",
    "Typing :: Typed"
]
requires-python = ">=3.8"
dependencies = [
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "pydantic>=2.5.0",
    "aiohttp>=3.9.0",
    "playwright>=1.40.0",
    "selenium>=4.15.0",
    "requests>=2.31.0",
    "cloudscraper>=1.2.71",
    "beautifulsoup4>=4.12.0",
    "lxml>=4.9.0",
    "asyncpg>=0.29.0",
    "redis>=5.0.0",
    "prometheus-client>=0.19.0",
    "psutil>=5.9.0",
    "rich>=13.7.0",
    "typer>=0.9.0",
    "pyyaml>=6.0.1",
    "jinja2>=3.1.0",
    "python-multipart>=0.0.6",
    "httpx>=0.25.0",
    "asyncio-mqtt>=0.13.0",
    "structlog>=23.2.0",
    "tenacity>=8.2.0",
    "python-jose[cryptography]>=3.3.0",
    "passlib[bcrypt]>=1.7.4",
    "python-dotenv>=1.0.0",
    "click>=8.1.0",
    "jsonschema>=4.20.0",
    "markupsafe>=2.1.0",
    "certifi>=2023.11.17"
]

[project.optional-dependencies]
ai = [
    "openai>=1.3.0",
    "anthropic>=0.7.0",
    "tiktoken>=0.5.0",
    "transformers>=4.35.0",
    "torch>=2.1.0",
    "sentence-transformers>=2.2.0"
]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "pytest-mock>=3.12.0",
    "black>=23.11.0",
    "flake8>=6.1.0",
    "mypy>=1.7.0",
    "pre-commit>=3.5.0",
    "coverage>=7.3.0",
    "bandit>=1.7.5",
    "safety>=2.3.0",
    "isort>=5.12.0",
    "pylint>=3.0.0",
    "sphinx>=7.2.0",
    "sphinx-rtd-theme>=1.3.0"
]
database = [
    "asyncpg>=0.29.0",
    "psycopg2-binary>=2.9.9",
    "sqlalchemy[asyncio]>=2.0.0",
    "alembic>=1.13.0",
    "redis>=5.0.0"
]
monitoring = [
    "prometheus-client>=0.19.0",
    "grafana-client>=3.2.0",
    "statsd>=4.0.1",
    "datadog>=0.48.0"
]
cloud = [
    "boto3>=1.34.0",
    "google-cloud-storage>=2.10.0",
    "azure-storage-blob>=12.19.0",
    "kubernetes>=28.1.0"
]
all = [
    "opencrawler[ai,dev,database,monitoring,cloud]"
]

[project.urls]
Homepage = "https://github.com/llamasearch/opencrawler"
Documentation = "https://github.com/llamasearch/opencrawler/docs"
Repository = "https://github.com/llamasearch/opencrawler"
Issues = "https://github.com/llamasearch/opencrawler/issues"
Changelog = "https://github.com/llamasearch/opencrawler/blob/main/CHANGELOG.md"

[project.scripts]
opencrawler = "master_cli:main"
opencrawler-api = "microservice_orchestrator:main"
opencrawler-validate = "webscraper.utils.comprehensive_validator:main"
opencrawler-test = "tests.production_test_suite:main"

[tool.setuptools]
packages = ["webscraper"]
include-package-data = true

[tool.setuptools.package-data]
webscraper = [
    "**/*.yaml",
    "**/*.yml", 
    "**/*.json",
    "**/*.html",
    "**/*.css",
    "**/*.js",
    "**/*.md",
    "**/*.txt"
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-v",
    "--strict-markers",
    "--tb=short",
    "--cov=webscraper",
    "--cov-report=term-missing",
    "--cov-report=html",
    "--cov-report=xml",
    "--cov-fail-under=80"
]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
    "ai: marks tests that require AI/LLM APIs",
    "database: marks tests that require database",
    "docker: marks tests that require Docker",
    "kubernetes: marks tests that require Kubernetes",
    "performance: marks performance benchmark tests",
    "benchmark: marks benchmark tests generated by pytest-benchmark plugin"
]
asyncio_mode = "auto"
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning"
]

[tool.coverage.run]
source = ["webscraper"]
omit = [
    "*/tests/*",
    "*/test_*",
    "*/__pycache__/*",
    "*/migrations/*",
    "*/venv/*",
    "*/.venv/*"
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:",
    "if __name__ == .__main__.:",
    "class .*\\bProtocol\\):",
    "@(abc\\.)?abstractmethod"
]

[tool.black]
line-length = 88
target-version = ["py38", "py39", "py310", "py311", "py312"]
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true
line_length = 88
known_first_party = ["webscraper"]
known_third_party = [
    "fastapi",
    "pydantic",
    "playwright",
    "selenium",
    "requests",
    "aiohttp",
    "openai",
    "anthropic"
]

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true
show_error_codes = true
show_error_context = true
pretty = true

[[tool.mypy.overrides]]
module = [
    "playwright.*",
    "selenium.*",
    "cloudscraper.*",
    "prometheus_client.*",
    "redis.*",
    "asyncpg.*"
]
ignore_missing_imports = true

[tool.flake8]
max-line-length = 88
select = ["E", "W", "F"]
ignore = [
    "E203",  # whitespace before ':'
    "E501",  # line too long
    "W503",  # line break before binary operator
    "F401",  # module imported but unused
    "F403",  # 'from module import *' used
]
exclude = [
    ".git",
    "__pycache__",
    "build",
    "dist",
    ".venv",
    ".eggs",
    "*.egg"
]

[tool.bandit]
exclude_dirs = ["tests", "test_*"]
skips = ["B101", "B601"]

[tool.pylint.messages_control]
disable = [
    "too-many-arguments",
    "too-many-locals",
    "too-many-branches",
    "too-many-statements",
    "too-few-public-methods",
    "import-error",
    "no-member"
]

[tool.pylint.format]
max-line-length = 88
