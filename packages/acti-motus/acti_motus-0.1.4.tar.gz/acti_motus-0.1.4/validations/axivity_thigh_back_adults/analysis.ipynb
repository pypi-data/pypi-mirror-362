{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Prepare dataset\n",
    "\n",
    "Dataset comes originally from https://archive.ics.uci.edu/dataset/779/harth, however a few errors where fixed by authors and up to date dataset can be found here: https://github.com/ntnu-ai-lab/harth-ml-experiments/tree/main/harth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ANNOTATIONS = {\n",
    "    1: 'walking',\n",
    "    2: 'running',\n",
    "    3: 'shuffling',\n",
    "    4: 'stairs (ascending)',\n",
    "    5: 'stairs (descending)',\n",
    "    6: 'standing',\n",
    "    7: 'sitting',\n",
    "    8: 'lying',\n",
    "    13: 'cycling (sit)',\n",
    "    14: 'cycling (stand)',\n",
    "    130: 'cycling (sit, inactive)',\n",
    "    140: 'cycling (stand, inactive)',\n",
    "}\n",
    "\n",
    "\n",
    "def prepare_raw(path: Path) -> dict[str, pd.DataFrame]:\n",
    "    df = pd.read_csv(path, engine='pyarrow', index_col='timestamp')\n",
    "    df.index.name = 'datetime'\n",
    "\n",
    "    ground_truth = df['label']\n",
    "    ground_truth.name = 'ground_truth'\n",
    "    ground_truth = ground_truth.groupby(pd.Grouper(freq='1s')).median().dropna().astype(int)\n",
    "    ground_truth = ground_truth.map(ANNOTATIONS).astype('category').dropna().to_frame()\n",
    "\n",
    "    thigh = df[['thigh_x', 'thigh_y', 'thigh_z']].astype(np.float32)\n",
    "    thigh.columns = ['acc_x', 'acc_y', 'acc_z']\n",
    "    thigh['acc_x'] = -thigh['acc_x']  # Invert x-axis to match the expected orientation\n",
    "    thigh['acc_y'] = -thigh['acc_y']  # Invert y-axis to match the expected orientation\n",
    "\n",
    "    back = df[['back_x', 'back_y', 'back_z']].astype(np.float32)\n",
    "    back.columns = ['acc_x', 'acc_y', 'acc_z']\n",
    "    back['acc_x'] = -back['acc_x']  # Invert x-axis to match the expected orientation\n",
    "    back['acc_y'] = -back['acc_y']  # Invert y-axis to match the expected orientation\n",
    "\n",
    "    return {'ground_truth': ground_truth, 'thigh': thigh, 'trunk': back}\n",
    "\n",
    "\n",
    "folder = Path('origin')\n",
    "files = folder.rglob('*.csv')\n",
    "\n",
    "output = Path('data')\n",
    "output.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "(output / 'ground_truth').mkdir(parents=True, exist_ok=True)\n",
    "(output / 'thigh').mkdir(parents=True, exist_ok=True)\n",
    "(output / 'trunk').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    id = file.stem\n",
    "    data = prepare_raw(file)\n",
    "\n",
    "    for name, df in data.items():\n",
    "        df.to_parquet(output / name / f'{id}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# 2. Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from acti_motus import Features, Activities\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "files = Path('data/thigh').glob('*.parquet')\n",
    "\n",
    "features = Features()\n",
    "activities = Activities(chunks=False, orientation=True)\n",
    "\n",
    "results = []\n",
    "results_trunk = []\n",
    "\n",
    "for thigh in files:\n",
    "    gt = thigh.parent.parent / 'ground_truth' / thigh.name\n",
    "\n",
    "    ground_truth = pd.read_parquet(gt)\n",
    "    df = pd.read_parquet(thigh)\n",
    "\n",
    "    extracted_features = features.extract(df)\n",
    "    activity, references = activities.detect(extracted_features)\n",
    "\n",
    "    df = ground_truth.join(activity, how='left')\n",
    "    df.dropna(subset=['activity'], inplace=True)\n",
    "    results.append(df)\n",
    "\n",
    "    # Add trunk\n",
    "    trunk = thigh.parent.parent / 'trunk' / thigh.name\n",
    "    trunk = pd.read_parquet(trunk)\n",
    "\n",
    "    features_trunk = features.extract(trunk)\n",
    "    activity_trunk, references_trunk = activities.detect(extracted_features, trunk=features_trunk)\n",
    "    trunk_df = ground_truth.join(activity_trunk, how='left')\n",
    "    trunk_df.dropna(subset=['activity'], inplace=True)\n",
    "    results_trunk.append(trunk_df)\n",
    "\n",
    "results = pd.concat(results)\n",
    "results.to_parquet('processed_thigh.parquet', index=True)\n",
    "\n",
    "results_trunk = pd.concat(results_trunk)\n",
    "results_trunk.to_parquet('processed_trunk.parquet', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from functions import get_confusion_matrix, get_validity_metrics\n",
    "import pandas as pd\n",
    "\n",
    "sensor = 'trunk'\n",
    "\n",
    "df = pd.read_parquet(f'processed_{sensor}.parquet')\n",
    "\n",
    "annotations = df['ground_truth'].unique().tolist()\n",
    "\n",
    "# df = df[~df['ground_truth'].isin([\"shuffling\", \"cycling (stand, inactive)\", \"cycling (stand)\"])]\n",
    "\n",
    "rename = {\n",
    "    'standing': 'stand',\n",
    "    'shuffling': 'stand',\n",
    "    'walking': 'walk',\n",
    "    'stairs (descending)': 'stairs',\n",
    "    'stairs (ascending)': 'stairs',\n",
    "    'sitting': 'sit',\n",
    "    'cycling (sit)': 'bicycle',\n",
    "    'lying': 'lie',\n",
    "    'cycling (sit, inactive)': 'bicycle',\n",
    "    'cycling (stand)': 'bicycle',\n",
    "    'running': 'run',\n",
    "    'cycling (stand, inactive)': 'bicycle',\n",
    "}\n",
    "df['ground_truth'] = df['ground_truth'].map(rename)\n",
    "\n",
    "df.loc[df['activity'] == 'move', 'activity'] = 'stand'\n",
    "# df.loc[df['activity'] == 'stairs', 'activity'] = 'walk'\n",
    "\n",
    "plot = get_confusion_matrix(\n",
    "    df['ground_truth'], df['activity'], labels=['lie', 'sit', 'stand', 'walk', 'stairs', 'run', 'bicycle']\n",
    ")  # move, stairs\n",
    "plot.write_image(f'{sensor}.png', scale=2)\n",
    "\n",
    "results = get_validity_metrics(df['ground_truth'], df['activity'])\n",
    "results.to_csv(f'{sensor}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
