Metadata-Version: 2.4
Name: proxy_fetcher
Version: 0.2.0
Summary: Package for fetching and validating working HTTP/HTTPS proxies from multiple sources
Home-page: https://github.com/ilmir-muslim/proxy-fetcher
Author: Ilmir Gilmiiarov
Author-email: ilmir_gf@mail.ru
Project-URL: Bug Reports, https://github.com/ilmir-muslim/proxy-fetcher/issues
Project-URL: Source, https://github.com/ilmir-muslim/proxy-fetcher
Keywords: proxy scraper validator fetcher
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Internet :: Proxy Servers
Classifier: Programming Language :: Python :: 3.13
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.13
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.25.1
Requires-Dist: tqdm>=4.60.0
Requires-Dist: aiohttp>=3.9.0
Requires-Dist: typing_extensions>=4.0.0; python_version < "3.11"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: project-url
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Proxy Fetcher

Python package for fetching and validating HTTP/HTTPS proxies from multiple sources.

## Features
- Automatic proxy validation
- Multiple sources (Geonode, ProxyScrape, etc.)
- Customizable parameters
- Progress bar with `tqdm`

## Installation
```bash
pip install proxy-fetcher
```

# Quick Start

``` python
from proxy_fetcher import get_proxies

# Get 10 working proxies (default)
proxies = get_proxies()
print(f"Found {len(proxies)} working proxies")

# Custom settings
proxies = get_proxies(
    MIN_WORKING_PROXIES=15,
    PROXY_LIMIT=50,
    TIMEOUT=10
)
```

# Advanced Usage

``` python
from proxy_fetcher import ProxyFetcher

# Manual control
fetcher = ProxyFetcher(
    MIN_WORKING_PROXIES=5,
    TEST_URLS=["http://my-site.com/check-ip"]
)

if fetcher.fetch_proxies():
    print(fetcher.working_proxies)
```

# Configuration Options

| Parameter            | Default | Description                          |
|----------------------|---------|--------------------------------------|
| `MIN_WORKING_PROXIES` | 10     | Minimum working proxies to find      |
| `PROXY_LIMIT`        | 100     | Max proxies to fetch per attempt     |
| `TIMEOUT`            | 5       | Timeout for validation (seconds)     |
| `MAX_ATTEMPTS`       | 3       | Max attempts to reach target count   |
| `TEST_URLS`          | See below | URLs for proxy validation           |

## Proxy Storage

### Save proxies to file:
```python
from proxy_fetcher import get_proxies

proxies = get_proxies()
with open('proxies.txt', 'w') as f:
    f.write('\n'.join(proxies))
```

### Load proxies from file:
```python
with open('proxies.txt') as f:
    loaded_proxies = f.read().splitlines()
```

# License

MIT
