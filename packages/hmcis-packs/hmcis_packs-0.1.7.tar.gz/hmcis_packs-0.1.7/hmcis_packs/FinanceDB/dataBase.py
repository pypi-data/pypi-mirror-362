# db_client.py

import os

import pandas as pd
import psycopg2
import yaml
from pandas import PeriodDtype
from psycopg2 import sql
from psycopg2.extras import execute_values

# import logging
from hmcis_packs.logger.logger_config import setup_logger

# ========== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ==========
# –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤ ‚Äî —Å–æ–∑–¥–∞—ë–º, –µ—Å–ª–∏ –Ω–µ—Ç
LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

LOG_FILE = os.path.join(LOG_DIR, 'database_client.log')

# # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥—É–ª—è
# logging.basicConfig(
#     level=logging.INFO,
#     format='%(asctime)s %(levelname)s: %(message)s',
#     handlers=[
#         logging.StreamHandler(sys.stdout),  # –≤ –∫–æ–Ω—Å–æ–ª—å (stdout)
#         logging.FileHandler(LOG_FILE, encoding='utf-8')  # –≤ —Ñ–∞–π–ª
#     ]
# )

logger = setup_logger(__name__)


# ===============================================


class DatabaseClient:
    def __init__(self, config_path=None):
        if config_path is None:
            user_home = os.path.expanduser("~")
            config_path = os.path.join(user_home, "db_config.yaml")

        with open(config_path, 'r', encoding='utf-8') as f:
            self.db_config = yaml.safe_load(f)

    def _map_dtype(self, dtype):
        """
        –ú–∞–ø–ø–∏–Ω–≥ pandas dtype ‚Üí PostgreSQL —Ç–∏–ø.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç PeriodDtype, float, int, bool, datetime, object –∏ fallback BYTEA.
        """
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–∏–æ–¥–æ–≤. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å isinstance —Å PeriodDtype
        if isinstance(dtype, PeriodDtype):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–∏–æ–¥ –∫–∞–∫ –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ TIMESTAMP
            return 'TIMESTAMP'
        if pd.api.types.is_float_dtype(dtype):
            return 'NUMERIC'
        if pd.api.types.is_integer_dtype(dtype):
            return 'INTEGER'
        if pd.api.types.is_bool_dtype(dtype):
            return 'BOOLEAN'
        if pd.api.types.is_datetime64_any_dtype(dtype):
            return 'TIMESTAMP'
        if dtype == 'object':
            return 'VARCHAR'
        return 'BYTEA'

    def save_df_to_db(self,
                      df: pd.DataFrame,
                      table_name: str,
                      schema: str = 'IFRS Reports',
                      binary_columns: list[str] = None):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ PostgreSQL, —Å–æ–∑–¥–∞—ë—Ç —Å—Ö–µ–º—É/—Ç–∞–±–ª–∏—Ü—É –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏,
        –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –ø–∞–∫–µ—Ç–Ω—É—é –≤—Å—Ç–∞–≤–∫—É —á–µ—Ä–µ–∑ execute_values.
        –†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ 2 –∫–æ–º–º–∏—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ —Å—Ö–µ–º–∞, –ø–æ—Ç–æ–º —Ç–∞–±–ª–∏—Ü–∞ + –¥–∞–Ω–Ω—ã–µ.
        """
        if binary_columns is None:
            binary_columns = []

        conn = psycopg2.connect(**self.db_config)
        cursor = conn.cursor()
        try:
            # 1) –°–æ–∑–¥–∞—ë–º —Å—Ö–µ–º—É –∏ –∫–æ–º–º–∏—Ç–∏–º —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã –Ω–µ –æ—Ç–∫–∞—Ç–∏–ª—Å—è –≤–º–µ—Å—Ç–µ —Å –æ—à–∏–±–∫–∞–º–∏ –Ω–∏–∂–µ
            cursor.execute(
                sql.SQL("CREATE SCHEMA IF NOT EXISTS {}")
                .format(sql.Identifier(schema))
            )
            conn.commit()

            # 2) –ì–æ—Ç–æ–≤–∏–º DDL –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
            cols_ddl = []
            for col, dtype in zip(df.columns, df.dtypes):
                if col in binary_columns:
                    pg_type = 'BYTEA'
                else:
                    pg_type = self._map_dtype(dtype)
                cols_ddl.append(f"{sql.Identifier(col).as_string(conn)} {pg_type}")

            create_sql = sql.SQL(
                "CREATE TABLE IF NOT EXISTS {schema}.{table} ({fields})"
            ).format(
                schema=sql.Identifier(schema),
                table=sql.Identifier(table_name),
                fields=sql.SQL(", ").join(sql.SQL(c) for c in cols_ddl),
            )
            cursor.execute(create_sql)

            # 3) –û—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π
            truncate_sql = sql.SQL("TRUNCATE {schema}.{table}").format(
                schema=sql.Identifier(schema),
                table=sql.Identifier(table_name),
            )
            cursor.execute(truncate_sql)

            # 4) –ì–æ—Ç–æ–≤–∏–º –ø–∞–∫–µ—Ç–Ω—É—é –≤—Å—Ç–∞–≤–∫—É
            insert_sql = sql.SQL(
                "INSERT INTO {schema}.{table} ({fields}) VALUES %s"
            ).format(
                schema=sql.Identifier(schema),
                table=sql.Identifier(table_name),
                fields=sql.SQL(', ').join(map(sql.Identifier, df.columns))
            )
            records = []
            for row in df.itertuples(index=False, name=None):
                rec = []
                for val, col in zip(row, df.columns):
                    if col in binary_columns:
                        rec.append(psycopg2.Binary(val))
                    else:
                        rec.append(val)
                records.append(tuple(rec))

            execute_values(cursor, insert_sql.as_string(conn), records, page_size=10000)

            # 5) –§–∏–∫—Å–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∏ –≤—Å—Ç–∞–≤–∫—É –¥–∞–Ω–Ω—ã—Ö
            conn.commit()
            logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ '{schema}.{table_name}'")

        except Exception as e:
            conn.rollback()
            logger.error("üíÄ –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –ë–î: %s", e)
            raise
        finally:
            cursor.close()
            conn.close()
