/****************************************************************************
*   Generated by ACUITY #ACUITY_VERSION#
*   Match timvx #TIMVX_VERSION#
*
*   Neural Network appliction customer source file
****************************************************************************/
#include "vx_utils.h"

#include <cstring>
#include <iostream>
#include <fstream>

using namespace #NAMESPACE#;

namespace utils
{

std::vector<std::vector<char>> load_input_data(char **argv, int input_count,
                                                    std::vector<uint32_t> input_size_bytes)
{
    std::vector<std::vector<char>> Data;
    for (int i = 0; i < input_count; i++)
    {
        std::ifstream fin(argv[i + 2], std::ios::in | std::ios::binary);
        if (fin)
        {
            std::vector<char> input_data;
            fin.seekg(0, std::ios::end);
            int size = fin.tellg();
            fin.seekg(0, std::ios::beg);
            char *buffer = new char[size];
            std::cout<<"File "<<argv[i + 2] <<" size:"<<size<<std::endl;
            fin.read(buffer, size);
            fin.close();
            input_data.assign(buffer, buffer + input_size_bytes[i]);
            Data.push_back(input_data);
            delete[] buffer;
        }
        else
        {
            std::cout<<"Load file "<<argv[i + 2]<<" failed"<<std::endl;
        }
    }
    return Data;
}

void load_input_tensor_data(char** argv, int input_count, std::vector<uint32_t> input_size_bytes,
    std::vector<std::shared_ptr<tim::vx::Tensor>> inputs)
{
    float fval = 0.0;
    uint32_t sz = 1;
    uint32_t stride = 1;
    FILE* tensorFile;
    char filename[128];

    for (int i = 0; i < input_count; i++)
    {
        std::vector<float> fval_v;
        tensorFile = fopen(argv[i + 2], "rb");
        sz = inputs[i]->GetSpec().GetElementNum();
        stride = inputs[i]->GetSpec().GetElementByteSize();
        uint8_t* tensorData = (uint8_t*)malloc(stride * sz * sizeof(uint8_t));
        snprintf(filename, sizeof(filename), "input_%d.txt", i);
        for (uint32_t j = 0; j < sz; j++)
        {
            if (fscanf(tensorFile, "%f ", &fval) != 1)
            {
                std::cout << "Read tensor file fail." << std::endl;
                std::cout << "Please check file lines or if the file contains illegal characters." << std::endl;
                goto error;
            }
            fval_v.push_back(fval);
        }
        tim::vx::utils::Float32ToDtype(inputs[i], fval_v, tensorData);
        inputs[i]->CopyDataToTensor(tensorData, sz);
        inputs[i]->SaveTensorToTextByFp32(filename);
    }
    return;
error:
    if (tensorFile)fclose(tensorFile);
    return;
}

bool get_top
(
    float* pfProb,
    float* pfMaxProb,
    uint32_t* pMaxClass,
    uint32_t outputCount,
    uint32_t topNum
)
{
    uint32_t i, j, k;

#define MAX_TOP_NUM 20
    if (topNum > MAX_TOP_NUM) return false;

    memset(pfMaxProb, 0xfe, sizeof(float) * topNum);
    memset(pMaxClass, 0xff, sizeof(uint32_t) * topNum);

    for (j = 0; j < topNum; j++)
    {
        for (i = 0; i < outputCount; i++)
        {
            for (k = 0; k < topNum; k++)
            {
                if (i == pMaxClass[k])
                    break;
            }

            if (k != topNum)
                continue;

            if (pfProb[i] > * (pfMaxProb + j))
            {
                *(pfMaxProb + j) = pfProb[i];
                *(pMaxClass + j) = i;
            }
        }
    }

    return true;
}

bool show_top5() {
    bool status = false;
    uint32_t i, sz, stride;
    float* buffer = NULL;
    uint8_t* tensor_data = NULL;
    uint32_t MaxClass[5];
    float fMaxProb[5];
    uint32_t topk = 5;
    auto output = #NETWORK_NAME#::outputs_tensor[0];

    sz = output-> GetSpec().GetElementNum();
    if (topk > sz)
        topk = sz;
    stride = output->GetSpec().GetElementByteSize();
    if (stride == 0)
    {
        stride = 1;
    }
    tensor_data = (uint8_t*)output->ConvertTensorToData(tensor_data);
    buffer = (float*)malloc(sizeof(float) * sz);
    for (i = 0; i < sz; i++)
    {
        status = tim::vx::utils::DtypeToFloat32(output, &tensor_data[stride * i], &buffer[i]);
    }

    if (!get_top(buffer, fMaxProb, MaxClass, sz, topk))
    {
        std::cout << "Fail to show result.\n" << std::endl;
        goto final;
    }

    std::cout << " --- Top---" << topk << std::endl;
    for (i = 0; i < topk; i++)
    {
        std::cout << MaxClass[i] << ": " << std::setprecision(6) << fMaxProb[i] << std::endl;
    }

    final:
    if (tensor_data)free(tensor_data);
    if (buffer)free(buffer);
    return status;
}

int postprocess()
{
    /* Print top 5 of neural network output0 (CPP) */
    auto outputs = #NETWORK_NAME#::outputs_tensor;
    uint8_t outputNum = outputs.size();
    char filename[128] = { 0 };
    for (uint32_t i = 0; i < outputNum; i++)
    {
        snprintf(filename, 128, "output%u.txt", i);
        outputs[i]->SaveTensorToTextByFp32(filename);
    }
    show_top5();
    return 0;
}

}  // namespace utils