from collections.abc import Callable
import asyncio
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import Any
import numpy as np
import pandas as pd
import calendar
import requests
from sklearn.neighbors import BallTree
from geopy.distance import geodesic  # For calculating distances
from ..exceptions import DataNotFound, ComponentError, ConfigError
from .flow import FlowComponent


# OSRM base URL for routing requests
OSRM_BASE_URL = "http://router.project-osrm.org"

class SchedulingVisits(FlowComponent):
    """Generating the Schedule of Employee Visits with Market Constraints and Visit Cadence.

    Overview:
        The SchedulingVisits class is a Flowtask component for generating a schedule of employee visits based on
        a set of rules and constraints. This component can be used to optimize the order of visits,
        minimize travel time, and balance workloads across employees.
        The schedule is generated by solving a combinatorial optimization
        problem with support for custom objective functions and constraints.

        Example of row consumed:
        ```
        associate_oid -> object -> G3Q86F5E1JXN1XVM
        corporate_email -> object -> buko@trocglobal.com
        employee_position -> object -> (3442724.8764311927, -10973885.176252203)
        store_id -> object -> BBY0178
        store_position -> object -> (3564143.804984759, -10887222.41833608)
        market -> object -> Market1
        visit_rule -> int64 -> 2
        visit_frequency -> object -> Monthly
        ```

        Example of Row Generated:
        ```

        ```


        Example:

        ```yaml
        SchedulingVisits:
          use_ghost_employees: true
          ghost_employees: 1
          ghost_employees_column: 'ghost_employees'  # Column name in dataframe for dynamic ghost employees count
          ghost_domain: 'company.com'  # Domain for ghost employee emails
          in_store_percentage: 0.6
          in_store_visit: 0.75
          max_stores: 4
          max_distance: 120
          year: 2024
          month: 12
          exception_dates:
          - '2024-12-25'
          exceptions_filename: /home/ubuntu/symbits/Scheduling-Visits-Exceptions.xlsx
        ```

        Note:
        - If 'ghost_employees_column' exists in the dataframe, it will use that value for each market
        - If the column doesn't exist or has null values, it will fall back to the 'ghost_employees' parameter
        - The 'ghost_domain' parameter allows you to customize the email domain for ghost employees
        - Ghost employee emails will be generated as: ghost_1@domain, ghost_2@domain, etc.
    """
    def __init__(
        self,
        loop: asyncio.AbstractEventLoop = None,
        job: Callable = None,
        stat: Callable = None,
        **kwargs,
    ):
        # TODO: add support for Masks
        # total hours worked per day
        self.day_duration: float = kwargs.pop('day_duration', 8.0)
        # 60% of the day in store
        self.in_store_percentage: float = kwargs.pop('in_store_percentage', 0.6)
        # near to 45 minutes in store
        self.in_store_visit: float = kwargs.pop('in_store_visit', 0.75)
        self.max_stores: int = kwargs.pop('max_stores', 4)
        # no more than 600 miles covered at day
        self.max_distance: int = kwargs.pop('max_distance', 600)
        # Average Speed:
        self.average_speed: float = kwargs.pop('average_speed', 40)
        # Objective function: minimize total travel time
        self.use_ghost_employees: bool = kwargs.pop('use_ghost_employees', False)
        # Using 3 ghost employees per market if no employees are available.
        self.ghost_employees: int = kwargs.pop('ghost_employees', 3)
        # Column name for ghost_employees in dataframe (if exists)
        self.ghost_employees_column: str = kwargs.pop('ghost_employees_column', 'ghost_employees')
        # calculate year and month of current day:
        today = date.today()
        self._today = today
        self.year: int = kwargs.pop('year', today.year)
        self.month: int = kwargs.pop('month', today.month)
        super(SchedulingVisits, self).__init__(
            loop=loop,
            job=job,
            stat=stat,
            **kwargs
        )
        # Ghost Domain for email generation
        self.ghost_domain: str = kwargs.pop('ghost_domain', 'company.com')
        # Ghost Account template with configurable domain
        self._ghost_account = kwargs.pop('ghost_account', f'ghost_{{}}@{self.ghost_domain}')
        # exception days:
        self._exception_dates = kwargs.pop('exception_dates', [])

    def _get_ghost_employees_count(self, market_data):
        """Get the number of ghost employees for a market.
        Priority: 1. Column in dataframe, 2. kwarg parameter, 3. default value"""
        if self.ghost_employees_column in market_data.columns:
            # Get the first non-null value from the column
            ghost_count = market_data[self.ghost_employees_column].dropna().iloc[0]
            if pd.isna(ghost_count):
                return self.ghost_employees
            return int(ghost_count)
        return self.ghost_employees

    def get_workdays(self, year: int, month: int, exception_dates: list = None):
        """Get all workdays (Monday to Friday) in a given month, excluding exception dates."""
        first_day = date(year, month, 1)
        last_day = date(year, month, calendar.monthrange(year, month)[1])
        workdays = pd.bdate_range(first_day, last_day)
        if exception_dates:
            # Convert exception_dates to datetime
            exception_dates = pd.to_datetime(exception_dates)
            workdays = workdays.difference(exception_dates)
        return workdays

    def _get_fdom(self, year, month):
        """Function to get the first Monday of a given month
        (which is Labor Day in the US)."""
        cal = calendar.Calendar()
        first_monday = None
        for day in cal.itermonthdays2(year, month):
            if day[0] != 0 and day[1] == 0:  # day[1] == 0 means Monday
                first_monday = day[0]
                break
        return datetime(year, month, first_monday)

    def get_distance(self, coord1, coord2):
        """Function to calculate distance
        between two points (latitude, longitude)."""
        return geodesic(coord1, coord2).miles

    def to_miles(self, distance) -> float:
        return distance * 0.621371  # Convert to miles

    def to_hours(self, minutes) -> float:
        return minutes / 60  # Convert to hours

    def get_labor_days(self, year: int = 2024, month: int = 9):
        """Function to get all workdays (Monday to Friday) in a given month."""
        # Get first Labor Day (first Monday) of the month
        labor_day = self._get_fdom(year, month)
        # Generate list of weekdays (excluding weekends) starting from Labor Day
        workdays = []
        current_day = labor_day
        while current_day.month == month:
            if current_day.weekday() < 5:  # Only Monday to Friday (weekday < 5)
                workdays.append(current_day)
            current_day += timedelta(days=1)
        return workdays

    def get_travel(self, waypoints, transportation: str = 'driving'):
        # Build the request URL for OSRM driving route
        # including all waypoints
        osrm_url = f"{OSRM_BASE_URL}/route/v1/{transportation}/{waypoints}?overview=false"
        # Send the request to OSRM API
        response = requests.get(osrm_url)
        # Check if the request was successful
        if response.status_code == 200:
            route_data = response.json()
            # Extract total travel duration and distance (in seconds and meters)
            # Total duration
            duration_seconds = route_data['routes'][0]['duration']
            # Total distance
            distance_meters = route_data['routes'][0]['distance']
            # Convert to more readable formats
            duration_minutes = duration_seconds / 60
            distance_km = distance_meters / 1000
            return duration_minutes, distance_km
        else:
            return 0, 0

    def get_travel_duration(self, origin, destination):
        """Helper function to get distance and duration between two points.
        """
        waypoints = f"{origin[1]},{origin[0]};{destination[1]},{destination[0]}"
        duration_minutes, distance_km = self.get_travel(waypoints, transportation='driving')
        distance_miles = self.to_miles(distance_km)
        return distance_miles, duration_minutes

    def get_scheduled_dates(
        self,
        cadence: str,
        visit_rule: int,
        visit_frequency: Any,
        workdays: pd.DatetimeIndex,
        store_index: int
    ):
        """Given the visit_rule and visit_frequency,
        return a list of scheduled dates for the visits."""
        scheduled_dates = []

        # Set visit_frequency and visit_rule based on cadence if provided
        if cadence:
            cadence = cadence.lower()
            if 'xweek' in cadence:
                num = int(cadence[0])
                visit_rule = num
                visit_frequency = 'weekly'
            elif 'xmonth' in cadence:
                num = int(cadence[0])
                visit_rule = num
                visit_frequency = 'monthly'
            elif 'xqtr' in cadence:
                num = int(cadence[0])
                visit_rule = num
                visit_frequency = 'quarterly'

        if visit_frequency.lower() == 'quarterly':
            # For simplicity, schedule as monthly with 1 visit per month
            visit_frequency = 'monthly'
            visit_rule = 1

        if visit_frequency.lower() == 'weekly':
            # FIXED: Proper indentation for weekly scheduling
            workdays_df = pd.DataFrame({'date': workdays})
            workdays_df['week'] = workdays_df['date'].dt.isocalendar().week
            weeks = sorted(workdays_df['week'].unique())

            for week in weeks:  # This loop was missing proper indentation
                week_days = workdays_df[workdays_df['week'] == week]['date'].sort_values().reset_index(drop=True)
                num_days = len(week_days)
                if num_days == 0:
                    continue

                # Ensure we don't exceed available days
                num_visits = min(visit_rule, num_days)

                # Distribute visits evenly within the week
                for i in range(num_visits):
                    if i < num_days:
                        # Use store_index to stagger start days for different stores
                        day_index = (store_index + i) % num_days
                        scheduled_date = week_days[day_index]
                        scheduled_dates.append(scheduled_date)

        elif visit_frequency.lower() == 'monthly':
            # Improved monthly scheduling
            total_days = len(workdays)
            if visit_rule == 0:
                visit_rule = 1
            if visit_rule > total_days:
                # If we need more visits than available days, schedule one per day
                scheduled_dates = list(workdays)
            else:
                # Distribute visits evenly across the month
                interval = total_days / visit_rule
                for i in range(visit_rule):
                    # Calculate target day index with small offset based on store
                    target_index = int(i * interval + (store_index % 5))
                    # Ensure we don't exceed array bounds
                    day_index = min(target_index, total_days - 1)
                    # Avoid duplicate dates
                    candidate_date = workdays[day_index]
                    if candidate_date not in scheduled_dates:
                        scheduled_dates.append(candidate_date)
                    else:
                        # Find next available date
                        for offset in range(1, total_days):
                            alt_index = (day_index + offset) % total_days
                            alt_date = workdays[alt_index]
                            if alt_date not in scheduled_dates:
                                scheduled_dates.append(alt_date)
                                break
        else:
            # Default fallback to monthly behavior
            total_days = len(workdays)
            interval = max(1, total_days // max(1, visit_rule))
            for i in range(visit_rule):
                day_index = min(i * interval, total_days - 1)
                scheduled_dates.append(workdays[day_index])

        return sorted(scheduled_dates)

    # Also add this method to better handle market analysis
    def analyze_market_capacity(self, df):
        """Analyze each market's capacity requirements."""
        market_analysis = {}
        total_employees_needed = 0

        self._logger.info("=== MARKET CAPACITY ANALYSIS ===")

        for market in df['market'].unique():
            market_data = df[df['market'] == market]
            store_count = len(market_data)

            # Calculate visits needed per month
            total_visits = 0
            for _, store in market_data.iterrows():
                visit_rule = store.get('visit_rule', 2)
                visit_frequency = store.get('visit_frequency', 'Monthly').lower()

                if visit_frequency == 'weekly':
                    # 4-5 weeks per month
                    monthly_visits = visit_rule * 4.3
                elif visit_frequency == 'monthly':
                    monthly_visits = visit_rule
                else:
                    monthly_visits = visit_rule

                total_visits += monthly_visits

            # Calculate employees needed (assuming 115 visits per employee per month)
            max_visits_per_employee = self.max_stores * len(
                self.get_workdays(self.year, self.month, self._exception_dates)
            )
            employees_needed = np.ceil(total_visits / max_visits_per_employee)
            total_employees_needed += employees_needed

            market_analysis[market] = {
                'store_count': store_count,
                'total_monthly_visits': total_visits,
                'employees_needed': int(employees_needed),
                'current_employees': self._get_ghost_employees_count(market_data)
            }

            self._logger.info(f"Market: {market}")
            self._logger.info(f"  Stores: {store_count}, Visits needed: {int(total_visits)}")
            self._logger.info(
                f"  Employees needed: {int(employees_needed)}, Current: {self._get_ghost_employees_count(market_data)}"
            )

            if employees_needed > self._get_ghost_employees_count(market_data):
                self._logger.warning(f"  ⚠️  Market {market} is UNDER-STAFFED!")

        self._logger.info(
            f"Total employees needed across all markets: {int(total_employees_needed)}"
        )
        return market_analysis

    async def start(self, **kwargs):
        if self.previous:
            self.data: pd.DataFrame = self.input
            if not isinstance(self.data, pd.DataFrame):
                raise ConfigError(
                    "Incompatible Pandas Dataframe", status=404
                )
        else:
            raise DataNotFound(
                "Data Not Found", status=404
            )
        await super().start(**kwargs)
        # if dataframe doesn't have a store_position attribute
        if 'store_position' not in self.data.columns:
            # Create the store_position column
            self.data['store_position'] = self.data.apply(
                lambda row: (row['latitude'], row['longitude']),
                axis=1
            )
        # Exceptions Filename:
        self._exceptions_file = None
        if hasattr(self, 'exceptions_filename'):
            self._exceptions_file = Path(self.exceptions_filename).resolve()
        return True

    async def close(self):
        pass

    def debug_scheduling_progress(self, schedule_df, exception_df):
        """Enhanced debug method with duplicate store visit detection."""
        self._logger.info("=== ENHANCED SCHEDULING DEBUG INFO ===")

        if len(schedule_df) > 0:
            min_date = schedule_df['day'].min()
            max_date = schedule_df['day'].max()
            unique_days = schedule_df['day'].nunique()

            workdays = self.get_workdays(self.year, self.month, self._exception_dates)
            expected_business_days = len(workdays)

            self._logger.info(f"Schedule date range: {min_date.date()} to {max_date.date()}")
            self._logger.info(f"Unique days scheduled: {unique_days}")
            self._logger.info(f"Expected business days in month: {expected_business_days}")

            # ✅ NEW: Check for duplicate store visits
            self._logger.info("\n=== DUPLICATE STORE VISIT ANALYSIS ===")

            # Count visits per store across all employees
            all_store_visits = {}
            employee_store_visits = {}

            for _, row in schedule_df.iterrows():
                employee_id = row['associate_oid']
                day = row['day']

                if 'store_ids' in row and row['store_ids']:
                    for store_id in row['store_ids']:
                        # Track overall visits
                        if store_id not in all_store_visits:
                            all_store_visits[store_id] = []
                        all_store_visits[store_id].append((employee_id, day))

                        # Track per employee
                        if employee_id not in employee_store_visits:
                            employee_store_visits[employee_id] = {}
                        if store_id not in employee_store_visits[employee_id]:
                            employee_store_visits[employee_id][store_id] = []
                        employee_store_visits[employee_id][store_id].append(day)

            # Find stores visited more than their required number of times
            over_visited_stores = []
            for store_id, visits in all_store_visits.items():
                # Get required visits for this store
                store_data = self.data[self.data['store_id'] == store_id]
                if len(store_data) > 0:
                    required_visits = store_data.iloc[0].get('visit_rule', 2)
                    actual_visits = len(visits)

                    if actual_visits > required_visits:
                        over_visited_stores.append({
                            'store_id': store_id,
                            'required': required_visits,
                            'actual': actual_visits,
                            'excess': actual_visits - required_visits,
                            'visits': visits
                        })

            if over_visited_stores:
                self._logger.warning(
                    f"❌ Found {len(over_visited_stores)} over-visited stores:"
                )
                for store_info in over_visited_stores[:10]:  # Show top 10
                    store_id = store_info['store_id']
                    self._logger.warning(
                        f"  Store {store_id}: {store_info['actual']}/{store_info['required']} visits "
                        f"(+{store_info['excess']} excess)"
                    )

                    # Show which days it was visited
                    visit_days = [visit[1].strftime('%Y-%m-%d') for visit in store_info['visits']]
                    self._logger.warning(f"    Visited on: {', '.join(visit_days)}")
            else:
                self._logger.info("✅ No over-visited stores detected")

            # Check for same store visited on same day by same employee
            same_day_duplicates = []
            for employee_id, stores in employee_store_visits.items():
                for store_id, visit_days in stores.items():
                    if len(visit_days) != len(set(visit_days)):
                        # Same store visited multiple times on same day
                        from collections import Counter
                        day_counts = Counter(visit_days)
                        duplicate_days = {day: count for day, count in day_counts.items() if count > 1}
                        same_day_duplicates.append({
                            'employee_id': employee_id,
                            'store_id': store_id,
                            'duplicate_days': duplicate_days
                        })

            if same_day_duplicates:
                self._logger.error(f"❌ Found {len(same_day_duplicates)} same-day duplicate visits:")
                for dup in same_day_duplicates:
                    self._logger.error(
                        f"  Employee {dup['employee_id']}, Store {dup['store_id']}: "
                        f"{dup['duplicate_days']}"
                    )
            else:
                self._logger.info("✅ No same-day duplicate visits detected")

            # Regular capacity analysis
            daily_stats = schedule_df.groupby('day').agg({
                'stores_visited_count': 'sum',
                'total_distance': 'mean',
                'total_time_hours': 'mean'
            }).round(2)

            avg_stores_per_day = daily_stats['stores_visited_count'].mean()
            max_stores_in_day = daily_stats['stores_visited_count'].max()

            self._logger.info("\n=== CAPACITY ANALYSIS ===")
            self._logger.info(f"Average stores per day: {avg_stores_per_day:.1f}")
            self._logger.info(f"Maximum stores in a day: {max_stores_in_day}")
            self._logger.info(f"Average distance per employee per day: {daily_stats['total_distance'].mean():.1f} miles")
            self._logger.info(f"Average hours per employee per day: {daily_stats['total_time_hours'].mean():.1f} hours")

            # Check capacity utilization
            theoretical_max_visits = len(schedule_df) * self.max_stores
            actual_visits = daily_stats['stores_visited_count'].sum()
            utilization = (actual_visits / theoretical_max_visits) * 100

            self._logger.info(f"Capacity utilization: {utilization:.1f}% ({actual_visits:,}/{theoretical_max_visits:,})")

            # Check for missed days
            scheduled_days = set(schedule_df['day'].dt.date)
            missing_days = [day.date() for day in workdays if day.date() not in scheduled_days]

            if missing_days:
                self._logger.warning(f"Days with NO visits: {missing_days}")
            else:
                self._logger.info("✅ All business days utilized")

        else:
            self._logger.error("❌ No visits scheduled!")

        # Exception analysis (existing code)
        if len(exception_df) > 0:
            self._logger.info(f"\n=== EXCEPTION ANALYSIS ===")
            self._logger.info(f"Unscheduled visits: {len(exception_df):,}")

            # Analyze constraint failures
            constraint_analysis = {
                'no_capacity': 0,
                'max_stores': 0,
                'time_limit': 0,
                'distance_limit': 0,
                'already_visited': 0
            }

            for reason in exception_df['reason']:
                if 'No capacity' in reason or 'No more workdays' in reason:
                    constraint_analysis['no_capacity'] += 1
                elif 'store visited' in reason:
                    constraint_analysis['already_visited'] += 1
                elif 'Max stores reached' in reason:
                    constraint_analysis['max_stores'] += 1
                elif 'Time limit exceeded' in reason or 'day duration' in reason:
                    constraint_analysis['time_limit'] += 1
                elif 'Distance limit exceeded' in reason or 'distance' in reason:
                    constraint_analysis['distance_limit'] += 1

            self._logger.info("Exception reason breakdown:")
            for constraint, count in constraint_analysis.items():
                if count > 0:
                    percentage = (count / len(exception_df)) * 100
                    self._logger.info(f"  {constraint.replace('_', ' ').title()}: {count:,} ({percentage:.1f}%)")

        else:
            self._logger.info("✅ All visits successfully scheduled!")

    async def run(self):
        self._logger.debug('=== RUNNING FUNCTION SCHEDULING VISITS ===')

        # STEP 1: Analyze market capacity requirements FIRST
        self._logger.info("Analyzing market capacity requirements...")
        market_analysis = self.analyze_market_capacity(self.data)
        # Check if current configuration can handle the load
        total_employees_needed = sum(
            m['employees_needed'] for m in market_analysis.values()
        )
        total_current_employees = sum(
            m['current_employees'] for m in market_analysis.values()
        )
        if total_employees_needed > total_current_employees:
            self._logger.warning(
                f"CAPACITY WARNING: Need {total_employees_needed} employees but only have {total_current_employees}"
            )
            self._logger.warning(
                "Consider increasing 'ghost_employees' parameter or adjusting constraints"
            )

        # Get workdays
        workdays = self.get_workdays(self.year, self.month, self._exception_dates)
        self._logger.info(
            f"Working with {len(workdays)} business days in {self.year}-{self.month}"
        )

        # Initialize a dictionary to keep track of assignments and exceptions
        schedule_rows = []
        exception_rows = []

        if self.use_ghost_employees or 'associate_oid' not in self.data.columns:
            # Create multiple ghost employees per market
            markets = self.data['market'].unique()
            ghost_employees = {}
            self.data['associate_oid'] = None  # Initialize associate_oid column
            for market in markets:
                market_data = self.data[self.data['market'] == market]
                positions = np.array([pos for pos in market_data['store_position']])
                mean_position = positions.mean(axis=0)

                # Get dynamic ghost employees count for this market
                ghost_employees_count = self._get_ghost_employees_count(market_data)
                if ghost_employees_count < 1:
                    ghost_employees_count = self.ghost_employees

                # Create ghost_employees_count ghost employees per market
                ghost_employee_ids = [f'{market}_ghost_{i+1}' for i in range(ghost_employees_count)]
                # Generate unique emails for ghost employees
                ghost_employee_emails = [self._ghost_account.format(i + 1) for i in range(ghost_employees_count)]
                # Generate positions with small variations
                ghost_employee_positions = []
                for i in range(ghost_employees_count):
                    # Generate small random offsets in degrees (~50 meters variation)
                    # 1 degree latitude ~ 111 km, so 50 meters ~ 0.00045 degrees
                    lat_offset = np.random.uniform(-0.00045, 0.00045)
                    lon_offset = np.random.uniform(-0.00045, 0.00045)
                    ghost_position = (mean_position[0] + lat_offset, mean_position[1] + lon_offset)
                    ghost_employee_positions.append(ghost_position)

                # Assign stores to ghost employees in a round-robin fashion
                market_store_indices = market_data.index
                num_stores = len(market_store_indices)
                for idx, store_idx in enumerate(market_store_indices):
                    try:
                        assigned_employee_index = idx % ghost_employees_count
                    except ZeroDivisionError:
                        assigned_employee_index = idx % self.ghost_employees
                    assigned_employee_id = ghost_employee_ids[assigned_employee_index]
                    self.data.at[store_idx, 'associate_oid'] = assigned_employee_id

                # Store the email and position for each ghost employee
                for i, assigned_employee_id in enumerate(ghost_employee_ids):
                    ghost_employees[assigned_employee_id] = {
                        'position': ghost_employee_positions[i],
                        'email': ghost_employee_emails[i],
                        'market': market
                    }

            # After assigning stores to ghost employees
            store_assignments = self.data.groupby('store_id')['associate_oid'].nunique()
            overlapping_stores = store_assignments[store_assignments > 1]
            if not overlapping_stores.empty:
                print("Stores assigned to multiple employees:")
                print(overlapping_stores)
            else:
                print("All stores uniquely assigned.")

            # Now group by associate_oid
            employee_groups = self.data.groupby('associate_oid')

        # Check if employee information is available
        elif 'associate_oid' in self.data.columns:
            employee_groups = self.data.groupby('associate_oid')
            # Group the data by employee
            ghost_employees = {}  # Not needed but kept for consistency
        else:
            raise ComponentError("No employee information available.")

        # Prepare a list to collect scheduled visits
        self._logger.info("Starting scheduling process...")

        all_required_visits = []

        for employee_id, employee_data in employee_groups:
            # Get employee information
            employee_info = employee_data.iloc[0]
            if 'corporate_email' in employee_info:
                employee_email = employee_info['corporate_email']
            else:
                employee_email = ghost_employees[employee_id]['email']

            if 'employee_position' in employee_info:
                employee_position = employee_info['employee_position']
            else:
                employee_position = ghost_employees[employee_id]['position']

            # Get unique stores for this employee (prevent duplicates)
            unique_stores = employee_data.drop_duplicates('store_id')

            self._logger.notice(f"Employee {employee_email}: processing {len(unique_stores)} stores")

            # For each store, create the required visits
            for _, store_row in unique_stores.iterrows():
                visit_rule = store_row.get('visit_rule', 2)
                visit_frequency = store_row.get('visit_frequency', 'Monthly')
                cadence = store_row.get('cadence', None)

                # Generate scheduled dates for this store
                store_unique_id = hash(store_row['store_id']) % (10 ** 8)
                scheduled_dates = self.get_scheduled_dates(
                    cadence,
                    visit_rule,
                    visit_frequency,
                    workdays,
                    store_index=store_unique_id
                )

                # Create one visit record per scheduled date
                for scheduled_date in scheduled_dates:
                    visit_record = {
                        'associate_oid': employee_id,
                        'corporate_email': employee_email,
                        'employee_position': employee_position,
                        'store_id': store_row['store_id'],
                        'store_name': store_row.get('store_name', 'Unknown'),
                        'market': store_row['market'],
                        'store_position': store_row['store_position'],
                        'scheduled_date': scheduled_date,
                        'visit_rule': visit_rule,
                        'visit_frequency': visit_frequency
                    }
                    all_required_visits.append(visit_record)

        total_required_visits = len(all_required_visits)
        self._logger.info(f"Total visits to schedule: {total_required_visits:,}")

        # Step 2: Group visits by employee and schedule day by day
        schedule_rows = []
        exception_rows = []

        # Group required visits by employee
        visits_by_employee = {}
        for visit in all_required_visits:
            emp_id = visit['associate_oid']
            if emp_id not in visits_by_employee:
                visits_by_employee[emp_id] = []
            visits_by_employee[emp_id].append(visit)

        # Schedule each employee's visits
        for employee_id, employee_visits in visits_by_employee.items():
            self._logger.info(
                f"Scheduling {len(employee_visits)} visits for employee {employee_id}"
            )

            # Get employee info from first visit
            first_visit = employee_visits[0]
            employee_email = first_visit['corporate_email']
            employee_position = first_visit['employee_position']
            market = first_visit['market']

            # Track how many times each store has been visited for this employee
            store_visit_tracker = {}
            for visit in employee_visits:
                store_id = visit['store_id']
                visit_rule = visit['visit_rule']
                if store_id not in store_visit_tracker:
                    store_visit_tracker[store_id] = {
                        'required_visits': visit_rule,
                        'scheduled_visits': 0,
                        'store_info': visit
                    }

            # Sort visits by scheduled date (earliest first)
            employee_visits.sort(key=lambda x: x['scheduled_date'])

            # Schedule visits day by day
            current_workday_index = 0
            visit_index = 0

            while visit_index < len(employee_visits) and current_workday_index < len(workdays):
                current_day = workdays[current_workday_index]

                # Initialize day schedule
                day_schedule = {
                    'associate_oid': employee_id,
                    'corporate_email': employee_email,
                    'start_position': employee_position,
                    'market': market,
                    'day': current_day,
                    'month': self.month,
                    'year': self.year,
                    'total_time_minutes': 0,
                    'total_time_hours': 0,
                    'total_in_store_time': 0,
                    'total_travel_time': 0,
                    'total_distance': 0,
                    'stores_visited_count': 0,
                    'visited_stores': {},
                    'store_ids': []
                }

                current_position = employee_position
                stores_scheduled_today = 0

                # Fill this day up to max_stores
                while stores_scheduled_today < self.max_stores and visit_index < len(employee_visits):
                    visit = employee_visits[visit_index]
                    store_id = visit['store_id']

                    # ✅ CHECK: Has this store already been visited enough times?
                    if store_visit_tracker[store_id]['scheduled_visits'] >= store_visit_tracker[store_id]['required_visits']:
                        # Skip this visit - store already visited enough times
                        visit_index += 1
                        continue

                    # ✅ CHECK: Is this store already scheduled for today?
                    if store_id in day_schedule['store_ids']:
                        # Skip this visit - store already scheduled for today
                        visit_index += 1
                        continue

                    # Calculate travel requirements
                    distance_miles = self.get_distance(current_position, visit['store_position'])
                    travel_time = (distance_miles / self.average_speed) * 60  # minutes
                    time_in_store = self.in_store_visit * 60  # minutes
                    total_time_needed = travel_time + time_in_store

                    # Check if this visit fits in today's constraints
                    fits_time = (day_schedule['total_time_minutes'] + total_time_needed) <= (self.day_duration * 60)
                    fits_distance = (day_schedule['total_distance'] + distance_miles) <= self.max_distance

                    if fits_time and fits_distance:
                        # Schedule this visit today
                        day_schedule['total_time_minutes'] += total_time_needed
                        day_schedule['total_distance'] += distance_miles
                        day_schedule['total_in_store_time'] += time_in_store
                        day_schedule['total_travel_time'] += travel_time
                        day_schedule['stores_visited_count'] += 1

                        day_schedule['visited_stores'][visit['store_id']] = {
                            'store_id': visit['store_id'],
                            'store_name': visit['store_name'],
                            'latitude': visit['store_position'][0],
                            'longitude': visit['store_position'][1],
                            'visit_rule': visit['visit_rule'],
                            'visit_frequency': visit['visit_frequency'],
                            'market': visit['market']
                        }
                        day_schedule['store_ids'].append(visit['store_id'])

                        # ✅ UPDATE: Mark this store as visited
                        store_visit_tracker[store_id]['scheduled_visits'] += 1

                        # Update current position
                        current_position = visit['store_position']
                        stores_scheduled_today += 1
                        visit_index += 1
                    else:
                        # This visit doesn't fit today - move to next day
                        break

                # Add this day's schedule if any visits were scheduled
                if day_schedule['stores_visited_count'] > 0:
                    day_schedule['total_time_hours'] = day_schedule['total_time_minutes'] / 60
                    schedule_rows.append(day_schedule)

                # Move to next workday
                current_workday_index += 1

            # Any remaining visits that couldn't be scheduled
            while visit_index < len(employee_visits):
                if store_visit_tracker[store_id]['scheduled_visits'] < store_visit_tracker[store_id]['required_visits']:
                    visit = employee_visits[visit_index]
                    exception_row = {
                        'associate_oid': employee_id,
                        'corporate_email': employee_email,
                        'market': visit['market'],
                        'year': self.year,
                        'month': self.month,
                        'store_id': visit['store_id'],
                        'store_name': visit['store_name'],
                        'store_position': visit['store_position'],
                        'scheduled_date': visit['scheduled_date'],
                        'reason': 'No more workdays available in month'
                    }
                    exception_rows.append(exception_row)
                visit_index += 1

        self._logger.info(f"Created {len(schedule_rows)} schedule rows")
        self._logger.info(f"Could not schedule {len(exception_rows)} visits")

        # ============
        # Save the schedule and exceptions
        schedule_df = pd.DataFrame(schedule_rows)
        if len(schedule_df) > 0 and 'store_ids' in schedule_df.columns:
            schedule_df['store_count'] = schedule_df['store_ids'].apply(lambda x: len(x) if x is not None else 0)
        else:
            schedule_df['store_count'] = 0

        exception_stores_df = pd.DataFrame(exception_rows)
        self._logger.info("Calculating coverage statistics...")

        # Calculate accurate statistics
        total_scheduled_visits = schedule_df['stores_visited_count'].sum() if len(schedule_df) > 0 else 0
        unscheduled_visits = len(exception_stores_df)

        # Count unique stores that received visits
        all_scheduled_store_ids = []
        if len(schedule_df) > 0:
            for _, row in schedule_df.iterrows():
                if 'store_ids' in row and row['store_ids']:
                    all_scheduled_store_ids.extend(row['store_ids'])

        unique_scheduled_stores = len(set(all_scheduled_store_ids))
        total_unique_stores = len(self.data['store_id'].unique())

        # Count stores with full required visits
        stores_with_full_visits = 0
        store_visit_counts = {}

        # Count visits per store
        for store_id in all_scheduled_store_ids:
            store_visit_counts[store_id] = store_visit_counts.get(store_id, 0) + 1

        # Check which stores got their full required visits
        for store_id in set(all_scheduled_store_ids):
            store_data = self.data[self.data['store_id'] == store_id]
            if len(store_data) > 0:
                required_visits = store_data.iloc[0].get('visit_rule', 2)
                actual_visits = store_visit_counts.get(store_id, 0)
                if actual_visits >= required_visits:
                    stores_with_full_visits += 1

        # Calculate percentages
        partial_coverage = (unique_scheduled_stores / total_unique_stores) * 100 if total_unique_stores > 0 else 0
        full_coverage = (stores_with_full_visits / total_unique_stores) * 100 if total_unique_stores > 0 else 0
        visit_efficiency = (total_scheduled_visits / total_required_visits) * 100 if total_required_visits > 0 else 0

        # Set the final results
        self.schedule_df = schedule_df
        self.exception_stores_df = exception_stores_df

        # Enhanced debug analysis
        self._logger.info("Analyzing scheduling results...")
        self.debug_scheduling_progress(schedule_df, exception_stores_df)

        # Store market analysis for reference
        self.market_analysis = market_analysis

        print("\n" + "=" * 50)
        print("FINAL SUMMARY")
        print("=" * 50)
        print(f"Total unique stores: {total_unique_stores:,}")
        print(f"Total required visits: {total_required_visits:,}")
        print("")
        print(f"✅ Scheduled visits: {total_scheduled_visits:,}")
        print(f"❌ Unscheduled visits: {unscheduled_visits:,}")
        print("")
        print(f"Stores with some visits: {unique_scheduled_stores:,} ({partial_coverage:.1f}%)")
        print(f"Stores with full visits: {stores_with_full_visits:,} ({full_coverage:.1f}%)")
        print("")
        print(f"Visit efficiency: {visit_efficiency:.1f}%")

        if unique_scheduled_stores > 0:
            avg_visits_per_store = total_scheduled_visits / unique_scheduled_stores
            print(f"Average visits per scheduled store: {avg_visits_per_store:.1f}")

        # Verification
        print(f"\nSchedule rows created: {len(schedule_df):,}")
        if total_scheduled_visits <= total_required_visits:
            print("✅ No over-scheduling detected")
        else:
            print(f"⚠️  Over-scheduling: {total_scheduled_visits - total_required_visits:,} extra visits")

        print(' === Visit Schedule Sample === ')
        print(schedule_df.head())
        if len(exception_stores_df) > 0:
            print('=== Exception Stores Sample ====')
            print(exception_stores_df.head())

        # Saving the Exception Stores Dataframe to filesystem:
        if self._exceptions_file:
            if self._exceptions_file.suffix == '.xlsx':
                exception_stores_df.to_excel(self._exceptions_file, index=False)
            else:
                exception_stores_df.to_csv(self._exceptions_file, index=False)

        self._result = schedule_df

        self._print_data_(self._result, 'Schedule')

        return self._result
